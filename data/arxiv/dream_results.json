{
  "metadata": {
    "model": "dream",
    "data_path": "data/arxiv_samples.json",
    "prompt_ids": [
      "easy_general",
      "adult_non_technical",
      "adult_technical"
    ],
    "start_idx": 0,
    "end_idx": 100,
    "max_new_tokens": 512,
    "temperature": 0.2
  },
  "samples": [
    {
      "id": 0,
      "title": "Low-dimensional Supersymmetric Lattice Models",
      "original_text": "We study and simulate N=2 supersymmetric Wess-Zumino models in one and two dimensions. For any choice of the lattice derivative, the theories can be made manifestly supersymmetric by adding appropriate improvement terms corresponding to discretizations of surface integrals. In one dimension, our simulations show that a model with the Wilson derivative and the Stratonovitch prescription for this discretization leads to far better results at finite lattice spacing than other models with Wilson fermions considered in the literature. In particular, we check that fermionic and bosonic masses coincide and the unbroken Ward identities are fulfilled to high accuracy. Equally good results for the effective masses can be obtained in a model with the SLAC derivative (even without improvement terms). In two dimensions we introduce a non-standard Wilson term in such a way that the discretization errors of the kinetic terms are only of order O(a^2). Masses extracted from the corresponding manifestly supersymmetric model prove to approach their continuum values much quicker than those from a model containing the standard Wilson term. Again, a comparable enhancement can be achieved in a theory using the SLAC derivative.",
      "generations": {
        "easy_general": {
          "text": "In this study, we look at two types of models in one and two dimensions. We find that using the Wilson derivative and the Stratonovitch prescription gives better results than other methods. We also find that using the SLAC derivative can give similar results.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this study, we look at two types of mathematical models called N=2 supersymmetric Wess-Zumino models. These models are used to understand the behavior of particles in physics.",
          "error": null
        },
        "adult_technical": {
          "text": "We investigate and simulate N=2 supersymmetric Wess-Zumino models in one and two dimensions. For any choice of the lattice derivative, the theories can be made manifestly supersymmetric by adding appropriate improvement terms corresponding to discretizations of surface integrals. In one dimension, our simulations show that a model with the Wilson derivative and the Stratonovitch prescription for this discretization leads to far better results at finite lattice spacing than other models with Wilson fermions considered in the literature. In particular, we check that fermionic and bosonic masses coincide and the unbroken Ward identities are fulfilled to high accuracy. Equally good results for the effective masses can be obtained in a model with the SLAC derivative (even without improvement terms). In two dimensions, we introduce a non-standard Wilson term in such a way that the discretization errors of the kinetic terms are only of order O(a^2). Masses extracted from the corresponding manifestly supersymmetric model prove to approach their continuum values much quicker than those from a model containing the standard Wilson term. Again, a comparable enhancement can be achieved in a theory using the SLAC derivative.",
          "error": null
        }
      }
    },
    {
      "id": 1,
      "title": "Two-Dimensional Island Shape Determined by Detachment",
      "original_text": "Effect of an anisotropic detachment on a heteroepitaxial island shape is studied by means of a kinetic Monte Carlo simulation of a square lattice gas model. Only with molecular deposition followed by surface diffusion, islands grow in a ramified dendritic shape, similar to DLA. Introduction of molecular detachment from edges makes islands compact. To understand an anisotropic island shape observed in the experiment of pentacene growth on a hydrogen-terminated Si(111) vicinal surface, asymmetry in detachment around the substrate step is assumed. Edge molecules detach more to the higher terrace than to the lower terrace. The island edge from which molecules are easy to detach is smooth and the one hard to detach is dendritic. If islands are close to each other, islands tend to align in a line, since detached molecules from the smooth edge of the right island are fed to the dendritic and fast growing edge of the left island.",
      "generations": {
        "easy_general": {
          "text": "Imagine you're building a structure on a grid, and you want to see how it grows in different ways. Scientists use a method called a \" kinetic Monte Carlo simulation\" to study this. In this case, they look at how molecules grow on a grid called a \"square lattice gas model.\"\n\nWhen molecules are added to the grid, they grow in a shape that looks like a tree with branches. But when molecules leave the edges, the islands become smaller and they don't grow as much.\n\nNow, let's look at a real experiment. Scientists put a molecule called pentacene on a special surface called Si(111) vicinal. They found that the molecules grow in a line. This is because the molecules on the edges leave the island and join another island.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Imagine a grid of molecules on a surface. When molecules are added and move, they form a tree-like shape. But when some molecules fall off the edges, the shape becomes more compact. To understand this, scientists used a computer to simulate how molecules behave on a special surface. They found that molecules are more likely to fall off the higher part of the surface than the lower part. This creates two types of edges: a smooth, easily detached edge and a hard-to-det, dendritic edge. When two islands are close together, the molecules from the smooth edge of the right island feed the growing edge of the left, making the islands line up in a row.",
          "error": null
        },
        "adult_technical": {
          "text": "To investigate the impact of anisotropic detachment on the shape of hetero epitaxial islands, we have employed a kinetic Monte Carlo simulation of a square lattice gas model. When molecular deposition is followed by surface diffusion, islands exhibit a ramified dendritic growth, akin to the Limited Aggregation (DLA) model. However, when molecular detachment from edges is introduced, the islands become more compact. To explain the observed anisotropic island shape in the experiment of pentacene growth on a hydrogen-terminated Si(111) vicinal surface, we assume an asymmetry in detachment around the substrate step. Edge molecules are more likely to detach to the higher terrace than to the lower terrace. The island edge from which molecules are easily detached is smooth, while the one more difficult to detach is dendritic. When islands are close to each other, they tend to align in a line, as detached molecules from the smooth edge of the right island are fed to the dendritic and fast-growing edge of the left island.",
          "error": null
        }
      }
    },
    {
      "id": 2,
      "title": "Black Saturn with dipole ring",
      "original_text": "We present a new stationary, asymptotically flat solution of 5D Einstein-Maxwell gravity describing a Saturn-like black object: a rotating black hole surrounded by a rotating dipole black ring. The solution is generated by combining the vacuum black Saturn solution and the vacuum black ring solution with appropriately chosen parameters. Some basic properties of the solution are analyzed and the basic quantities are calculated.",
      "generations": {
        "easy_general": {
          "text": "Imagine a black hole with a big, spinning ring around it, just like Saturn's rings. Scientists have found a new way to describe this strange object by combining two other types of black holes. They used special numbers to make it work, and now they can understand how this object behaves.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Imagine a black hole with a spinning ring around it, just like Saturn's rings. Scientists have discovered a new type of black hole that looks like this. They found it by combining two other types of black holes, one that looks like a Saturn and one that looks like a ring. They then calculated some basic facts about this new black hole.",
          "error": null
        },
        "adult_technical": {
          "text": "We introduce a novel stationary, asymptotically flat solution in 5D Einstein-Maxwell gravity, representing a Saturn-like black object composed of a rotating black hole surrounded by a rotating dipole black ring. This solution is derived by merging the vacuum black Saturn solution and the vacuum black ring solution, with carefully selected parameters. We examine the fundamental properties of this solution and compute the basic quantities.",
          "error": null
        }
      }
    },
    {
      "id": 3,
      "title": "Hilbert functions of points on Schubert varieties in Orthogonal Grassmannians",
      "original_text": "A solution is given to the following problem: how to compute the multiplicity, or more generally the Hilbert function, at a point on a Schubert variety in an orthogonal Grassmannian. Standard monomial theory is applied to translate the problem from geometry to combinatorics. The solution of the resulting combinatorial problem forms the bulk of the paper. This approach has been followed earlier to solve the same problem for the Grassmannian and the symplectic Grassmannian. As an application, we present an interpretation of the multiplicity as the number of non-intersecting lattice paths of a certain kind. Taking the Schubert variety to be of a special kind and the point to be the \"identity coset,\" our problem specializes to a problem about Pfaffian ideals treatments of which by different methods exist in the literature. Also available in the literature is a geometric solution when the point is a \"generic singularity.\"",
      "generations": {
        "easy_general": {
          "text": "In this paper, we solve a problem about finding the value of a function called the Hilbert function at a specific point on a shape called a Schubert variety in a space called an orthogonal Grassmannian. We use a method called standard monomial theory to change the problem from geometry to counting, or combinatorics. This approach has been used to solve similar problems in other spaces. We also show that the multiplicity can be seen as the number of non-intersecting paths on a grid. This problem has other applications in the field.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this paper, we have found a way to solve a problem in mathematics called \"multiplicity.\" This is a way to measure how many times a certain pattern appears at a specific point on a shape called a \"Schubert variety.\" This shape is a part of a larger space called an \"orthogonal Grassmannian,\" which is a type of space used in geometry and algebra.\n\nThe problem asks us to find the \"multiplicity\" at a point on a Schubert variety. This is also known as the \"Hilbert function,\" which is a way to count how many times a certain pattern appears in a larger space.\n\nTo solve this, we use a method called \"standard monomial theory.\" This method helps us change the problem from a geometric one to a simpler problem called \"combinatorics,\" which is the study of counting and arranging things.\n\nWe then use this method to find the multiplicity as the number of non-intersecting lattice paths, which is a way to count the number of times a certain pattern appears.",
          "error": null
        },
        "adult_technical": {
          "text": "A solution is provided for calculating the multiplicity, or more broadly, the Hilbert function, at a point on a Schubert variety within an orthogonal Grassmannian. Standard monomial theory is employed to transform this geometric problem into a combinatorial one. The resolution of this combinatorial problem constitutes the core of the paper. This method has previously been used to solve similar problems for the Grassmannian and the symplectic Grassmannian. As an application, we offer an interpretation of the multiplicity as the count of non-intersecting lattice paths of a specific type. When the Schubert variety is of a particular type and the point is the \"identity coset,\" the problem simplifies to one involving Pfaffian ideals, for which various solutions exist in the literature. Additionally, a geometric solution is available when the point is a \"generic singularity.\"",
          "error": null
        }
      }
    },
    {
      "id": 4,
      "title": "MMT observations of new extremely metal-poor emission-line galaxies in the Sloan Digital Sky Survey",
      "original_text": "We present 6.5-meter MMT spectrophotometry of 20 H II regions in 13 extremely metal-poor emission-line galaxies selected from the Data Release 5 of the Sloan Digital Sky Survey to have [O III] 4959/Hbeta < 1 and [N II] 6583/Hbeta < 0.05. The electron temperature-sensitive emission line [O III] 4363 is detected in 13 H II regions allowing a direct abundance determination. The oxygen abundance in the remaining H II regions is derived using a semi-empirical method. The oxygen abundance of the galaxies in our sample ranges from 12+logO/H ~ 7.1 to ~ 7.8, with 10 H II regions having an oxygen abundance lower than 7.5. The lowest oxygen abundances, 12+logO/H = 7.14+/-0.03 and 7.13+/-0.07, are found in two H II regions of the blue compact dwarf galaxy SDSSJ0956+2849=DDO 68, making it the second most-metal deficient emission-line galaxy known, after SBS 0335-052W.",
      "generations": {
        "easy_general": {
          "text": "We looked at 20 parts of 13 very metal-poor galaxies using a big telescope called the 6.5-meter MMT. These galaxies are special because they have very few metals in them. We used a special tool called spectrophotometry to study these parts, which are called H II regions. In 13 of these regions, we found a special light called [O III] 4363, which allowed us to directly measure how much oxygen is in them. For the other 7 H regions, we used a special method to figure out the amount of oxygen in them.\n\nThe amount of oxygen in these galaxies ranges from about 7.1 to 7.8, with 10 of them having less than 7.5. The lowest amount of oxygen we found was in two parts of a galaxy called SDSSJ0956+2849=DDO 68. This galaxy is the second most metal-poor one we know about, after SBS 0335-052W.",
          "error": null
        },
        "adult_non_technical": {
          "text": "We used a big telescope to study the light coming from 20 H II regions in 13 very metal-poor galaxies. These galaxies have very little oxygen and nitrogen, which are important elements in the universe. We found a special type of light called [O III] 4363 in 13 of these regions, which helps us know how much oxygen is there. For the other regions, we used a method called semi-empirical to figure out the oxygen levels. \n\nOur study shows that the amount of oxygen in these galaxies ranges from about 7.1 to 7.8, with 10 of the regions having less than 7.5. The lowest oxygen levels were found in two parts of a galaxy called SDSSJ0956+2849=DDO 68, making it the second most metal-poor galaxy we know of, after SBS 0335-052W.",
          "error": null
        },
        "adult_technical": {
          "text": "We present 6.5-meter MMT spectrophotometry of 20 H II regions in 13 extremely metal-poor emission-line galaxies selected from the Sloan Digital Sky Survey to have [O III] 4959/Hbeta < 1 and [N II] 6583/Hbeta < 0.05. The electron temperature-sensitive emission line [O III] 4363 is detected in 13 H II regions, allowing a direct abundance determination. The oxygen abundance in the remaining H II regions is derived using a semi-empirical method. The oxygen abundance of the galaxies in our sample ranges from 12+logO/H ~ 7.1 to ~ 7.8, with 10 H II regions having an oxygen abundance lower than 7.5. The lowest oxygen abundances, 12+logO/H = 7.14+/-0.03 and 7.13+/-0.07, are found in two H II regions of the blue compact dwarf galaxy SDSSJ0956+2849=DDO 68, making it the second most-metal deficient emission-line galaxy known, after SBS 0335-052W.",
          "error": null
        }
      }
    },
    {
      "id": 5,
      "title": "Superluminal Radio Features in the M87 Jet and the Site of Flaring TeV Gamma-ray Emission",
      "original_text": "Superluminal motion is a common feature of radio jets in powerful gamma-ray emitting active galactic nuclei. Conventionally, the variable emission is assumed to originate near the central supermassive black-hole where the jet is launched on parsec scales or smaller. Here, we report the discovery of superluminal radio features within a distinct flaring X-ray emitting region in the jet of the nearby radio galaxy M87 with the Very Long Baseline Array. This shows that these two phenomenological hallmarks -- superluminal motion and high-energy variability -- are associated, and we place this activity much further (>=120 pc) from the ``central engine'' in M87 than previously thought in relativistic jet sources. We argue that the recent excess very high-energy TeV emission from M87 reported by the H.E.S.S. experiment originates from this variable superluminal structure, thus providing crucial insight into the production region of gamma-ray emission in more distant blazars.",
      "generations": {
        "easy_general": {
          "text": "In the heart of the universe, there are powerful objects called active galactic nuclei (AGNs). These AGNs shoot out powerful beams of energy called radio jets. Sometimes, these jets seem to move faster than light, which is called superluminal motion. Before, scientists thought that this motion came from near the supermassive black hole at the center of the AGN. However, they recently discovered that this motion is actually much further away.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In some galaxies, there are powerful jets of energy that move faster than the speed of light. These jets are created by a massive black hole at the center of the galaxy. Scientists thought that the energy came from near the black hole, but they recently found that the energy comes from much further away. This discovery helps us understand how these powerful jets work and how they produce energy.",
          "error": null
        },
        "adult_technical": {
          "text": "Superluminal motion is a common feature of radio jets in powerful gamma-ray emitting active galactic nuclei. Conventionally, the variable emission is assumed to originate near the central supermassive black-hole where the jet is launched on parsec scales or smaller. Here, we report the discovery of superluminal radio features within a distinct flaring X-ray emitting region in the jet of the nearby radio galaxy M87 with the Very Long Baseline Array. This shows that these two phenomenological hallmarks -- superluminal motion and high-energy variability -- are associated, and we place this activity much further (>=120 pc) from the ``central engine'' in M87 than previously thought in relativistic jet sources. We argue that the recent excess very high-energy TeV emission from M87 reported by the H.E.S.S. experiment originates from this variable superluminal structure, thus providing crucial insight into the production region of gamma-ray emission in more distant blazars.\n\nSuperluminal motion is a common feature of radio jets in powerful gamma-ray emitting active galactic nuclei. Conventionally, the variable emission is assumed to originate near the central supermassive black-hole where the jet is launched on parsec scales or smaller. Here, we report the discovery of superluminal radio features within a distinct flaring X-ray emitting region in the jet of the nearby radio galaxy M87 with the Very Long Baseline Array. This shows that these two phenomenological hallmarks -- superluminal motion and high-energy variability -- are associated, and we place this activity much further (>=120 pc) from the ``central engine'' in M87 than previously thought in relativistic jet sources. We argue that the recent excess very high-energy TeV emission from M87 reported by the H.E.S.S. experiment originates from this variable superluminal structure, thus providing crucial insight into the production region of gamma-ray emission in more distant blazars.\n\nSuperluminal motion is a common feature of radio jets in powerful gamma-ray emitting active galactic nuclei. Conventionally, the variable emission is assumed to originate near the central supermassive black-hole where the jet is launched on parsec scales or smaller. Here, we report the discovery of superluminal radio features within a distinct flaring X-ray emitting region in the jet of the nearby radio galaxy M87 with the Very Long Baseline Array. This shows that these two phenomenological hallmarks -- superlum",
          "error": null
        }
      }
    },
    {
      "id": 6,
      "title": "Blow-up in the Parabolic Scalar Curvature Equation",
      "original_text": "The \\textit{parabolic scalar curvature equation} is a reaction-diffusion type equation on an $(n-1)$-manifold $\\Sigma$, the time variable of which shall be denoted by $r$. Given a function $R$ on $[r_0,r_1)\\times\\Sigma$ and a family of metrics $\\gamma(r)$ on $\\Sigma$, when the coefficients of this equation are appropriately defined in terms of $\\gamma$ and $R$, positive solutions give metrics of prescribed scalar curvature $R$ on $[r_0,r_1)\\times\\Sigma$ in the form \\[ g=u^2dr^2+r^2\\gamma.\\] If the area element of $r^2\\gamma$ is expanding for increasing $r$, then the equation is parabolic, and the basic existence problem is to take positive initial data at some $r=r_0$ and solve for $u$ on the maximal interval of existence, which above was implicitly assumed to be $I=[r_0,r_1)$; one often hopes that $r_1=\\infty$. However, the case of greatest physical interest, $R>0$, often leads to blow-up in finite time so that $r_1<\\infty$. It is the purpose of the present work to investigate the situation in which the blow-up nonetheless occurs in such a way that $g$ is continuously extendible to $\\bar M=[r_0,r_1]\\times\\Sigma$ as a manifold with totally geodesic outer boundary at $r=r_1$.",
      "generations": {
        "easy_general": {
          "text": "The parabolic scalar curvature equation is a type of equation that describes how something changes over time in a specific space.",
          "error": null
        },
        "adult_non_technical": {
          "text": "The parabolic scalar curvature equation is a type of equation that describes how something changes over time.",
          "error": null
        },
        "adult_technical": {
          "text": "The parabolic scalar curvature equation is a reaction-diffusion equation on an $(n-1)$-manifold $\\Sigma$, with the time variable denoted by $r$. Given a function $R$ on $[r_0,r_1)\\times\\Sigma$ and a family of metrics $\\gamma(r)$ on $\\Sigma$, the coefficients of this equation are appropriately defined in terms of $\\gamma$ and $R$. Positive solutions give metrics of prescribed scalar curvature $R$ on $[r_0,r_1)\\times\\Sigma$ in the form $g=u^2dr^2+r^2\\gamma$. If the area element of $r^2\\gamma$ is expanding for increasing $r$, the equation is parabolic, and the basic existence problem is to take positive initial data at some $r=r_0$ and solve for $u$ on the maximal interval of existence, which was implicitly assumed to be $I=[r_0,r_1)$; one often hopes that $r_1=\\infty$. However, the case of greatest physical interest, $R>0$, often leads to blow-up in finite time so that $r_1<\\infty$. It is the purpose of the present work to investigate the situation in which the blow-up nonetheless occurs in such a way that $g$ is continuously extendible to $\\bar M=[r_0,r_1]\\times\\Sigma$ as a manifold with totally geodesic outer boundary at $r=r_1$.",
          "error": null
        }
      }
    },
    {
      "id": 7,
      "title": "Oscillation thresholds for \"strinking outwards\" reeds coupled to a resonator",
      "original_text": "This paper considers a \"striking outwards\" reed coupled to a resonator. This expression, due to Helmholtz, is not discussed here : it corresponds to the most common model of a lip-type valve, when the valve is assumed to be a one degree of freedom oscillator. The presented work is an extension of the works done by Wilson and Beavers (1974), Tarnopolsky (2000). The range of the playing frequencies is investigated. The first results are analytical : when no losses are present in the resonator, it is proven that the ratio between the threshold frequency and the reed resonance frequency is found to be necessarily within the interval between unity and the square root of 3. This is a musical sixth. Actually the interval is largely smaller, and this is in accordance with e.g. the results by Cullen et al.. The smallest blowing pressure is found to be directly related to the quality factor of the reed. Numerical results confirm these statements, and are discussed in comparison with previous ones by Cullen et al (2000).",
      "generations": {
        "easy_general": {
          "text": "This paper looks at a type of reed that moves outwards when connected to a resonator. This model, called a \"lip-type valve,\" is often used to understand how instruments like trumpets and clarinets work. The research builds on earlier studies by Wilson and Beavers (1974) and Tarnopolsky (2000).\n\nThe main focus is the range of frequencies that can be played on these instruments. The first findings show that when there are no losses in the resonator, the ratio between the lowest frequency that can be played and the highest frequency the reed can produce is between 1 and the square root of 3. This is similar to a musical sixth. However, the actual range is much smaller, and this is in line with the results found in the work of Cullen et al.\n\nThe research also shows that the smallest blowing pressure needed to play is directly related to the quality factor of the reed. Numerical results support these findings and are compared to previous studies.",
          "error": null
        },
        "adult_non_technical": {
          "text": "This paper looks at a type of reed that moves outwards when connected to a resonator. This model is called a \"striking outwards\" reed, and it's based on a concept developed by Helmholtz. The reed is similar to a lip-type valve, which is a type of valve used in musical instruments. The research builds on the work of Wilson and Beavers from 1974 and Tarnopolsky from 2000.\n\nThe study examines the range of frequencies that can be played using this reed. First, it mathematically proves the relationship between the threshold frequency and the reed's resonance frequency. When there are no losses in the resonator, the ratio of these two frequencies falls within a specific range between unity and the square root of 3, which is equivalent to a musical sixth. However, the actual range is much smaller, and this aligns with the findings of Cullen et al.\n\nThe research also shows that the smallest blowing pressure needed to make the reed move is directly related to the quality factor of the reed. Numerical results support these findings and are compared to previous work by Cullen et al. from 2000.",
          "error": null
        },
        "adult_technical": {
          "text": "This paper examines a \"striking outwards\" reed coupled to a resonator, a concept introduced by Helmholtz. This model represents a typical lip-type valve, where the valve is treated as a single degree of freedom oscillator. The study builds upon the earlier work by Wilson and Beavers (1974) and Tarnopolsky (2000), focusing on the range of playing frequencies. The initial findings are analytical, demonstrating that when there are no losses in the resonator, the ratio of the threshold frequency to the reed resonance frequency falls within the interval between unity and the square root of 3, which corresponds to a musical sixth. However, the actual interval is significantly narrower, consistent with the findings by Cullen et al. The smallest blowing pressure is found to be directly proportional to the quality factor of the reed. Numerical simulations validate these conclusions and are compared with previous results from Cullen et al. (2000).",
          "error": null
        }
      }
    },
    {
      "id": 8,
      "title": "Out-of-equilibrium tricritical point in a system with long-range interactions",
      "original_text": "Systems with long-range interactions display a short-time relaxation towards Quasi Stationary States (QSSs) whose lifetime increases with system size. With reference to the Hamiltonian Mean Field (HMF) model, we here show that a maximum entropy principle, based on Lynden-Bell's pioneering idea of \"violent relaxation\", predicts the presence of out-of-equilibrium phase transitions separating the relaxation towards homogeneous (zero magnetization) or inhomogeneous (non zero magnetization) QSSs. When varying the initial condition within a family of \"water-bags\" with different initial magnetization and energy, first and second order phase transition lines are found that merge at an out--of--equilibrium tricritical point. Metastability is theoretically predicted and numerically checked around the first-order phase transition line.",
      "generations": {
        "easy_general": {
          "text": "Some systems with very long-range interactions quickly settle into stable states. These states last longer as the system gets bigger. We used a model called the Hamiltonian Mean Field (HMF) model to study these systems. We found that these systems can change from one stable state to another in a sudden way, which is called phase transition. This change can happen in different ways.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Imagine a group of people standing in a room, all talking to each other. As they talk, they start to move around and change their positions. After a short time, they all settle into a stable arrangement, with everyone in a specific spot. This is similar to what happens in a system, like particles in a physical system. As the particles move around, they eventually settle into a stable state, called a Quasi Stationary State (QSS). \n\nIn this case, the system has long-range interactions, meaning everyone can affect everyone else. By using a special model, called the Hamiltonian Mean Field (HMF) model, we can understand how these systems behave. This model is based on a principle called \"maximum entropy,\" which was developed by Lynden-Bell. This principle helps us predict how the system will change between different states, called out-of-equilibrium phase transitions.\n\nWhen we look at a group of similar systems, called \"water-bags,\" we can see how they behave under different starting conditions. We find that there are two types of phase transitions: first-order and second-order. These transitions happen when the system changes from one state to another, and we can see them on a graph. The first-order transition happens at a special point, called the out-of-equilibrium tricritical point.",
          "error": null
        },
        "adult_technical": {
          "text": "In systems characterized by long-range interactions, we observe a rapid relaxation towards Quasi Stationary States (QSSs), whose longevity increases with the system size. Utilizing the Hamiltonian Mean Field (HMF) model, we demonstrate that a maximum entropy principle, rooted in Lynden-Bell's concept of \"violent relaxation,\" predicts the occurrence of out-of-equilibrium phase transitions. These transitions distinguish the relaxation towards homogeneous (zero magnetization) or inhomogeneous (non-zero magnetization) QSSs. By adjusting the initial conditions within a family of \"water-bags\" with varying initial magnetization and energy, we identify first and second-order phase transition lines that converge at an out-of-equilibrium tricritical point. Furthermore, we theoretically predict and numerically verify the presence of metastability around the first-order phase transition line.",
          "error": null
        }
      }
    },
    {
      "id": 9,
      "title": "Cobordism, Relative Indices and Stein Fillings",
      "original_text": "In this paper we build on the framework developed in \"Subelliptic Boundary Value Problems for the Spin_C Dirac Operator, I, II, III\" to obtain a more complete understanding of the gluing properties for indices of boundary value problems for the SpinC-Dirac operator with sub-elliptic boundary conditions. We extend our analytic results for sub-elliptic boundary value problems for the SpinC-Dirac operator, and gluing results for the indices of these boundary problems to SpinC-manifolds with several pseudoconvex (pseudoconcave) boundary components. These results are applied to study Stein fillability for compact, 3-dimensional, contact manifolds.",
      "generations": {
        "easy_general": {
          "text": "In this paper, we use the ideas from a study called \"Subelliptic Boundary Value Problems for the SpinC Dirac Operator, I, II, III\" to get a better understanding of how to put together the solutions to problems involving the SpinC-Dirac operator with sub-elliptic boundary conditions. We also apply our findings to SpinC-manifolds with multiple pseudoconvex or pseudoconcave boundary parts. These results help us study a property called Stein fillability for compact, 3-dimensional contact manifolds.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this paper, we expand on the ideas presented in \"Subelliptic Boundary Value Problems for the SpinC Dirac Operator, I, II, III\" to better understand how to combine the solutions of certain problems involving the SpinC-Dirac operator with sub-elliptic boundary conditions. We also apply our findings to a specific type of shape called a SpinC-manifold, which has several different boundary components.",
          "error": null
        },
        "adult_technical": {
          "text": "In this paper, we expand on the framework established in \"Subelliptic Boundary Value Problems for the SpinC Dirac Operator, I, II, III\" to gain a deeper understanding of the gluing properties for indices of boundary value problems for the SpinC-Dirac operator with sub-elliptic boundary conditions. We extend our analytic results for sub-elliptic boundary value problems for the SpinC-Dirac operator, and gluing results for the indices of these boundary problems to SpinC-manifolds with several pseudoconvex (pseudoconcave) boundary components. These results are applied to study Stein fillability for compact, 3-dimensional, contact manifolds.",
          "error": null
        }
      }
    },
    {
      "id": 10,
      "title": "The Rahman Polynomials Are Bispectral",
      "original_text": "In a very recent paper, M. Rahman introduced a remarkable family of polynomials in two variables as the eigenfunctions of the transition matrix for a nontrivial Markov chain due to M. Hoare and M. Rahman. I indicate here that these polynomials are bispectral. This should be just one of the many remarkable properties enjoyed by these polynomials. For several challenges, including finding a general proof of some of the facts displayed here the reader should look at the last section of this paper.",
      "generations": {
        "easy_general": {
          "text": "In a recent paper, M. Rahman discovered a special group of polynomials that are important for understanding a certain type of mathematical system called a Markov chain. These polynomials are based on two variables and have a unique property called spectral. This means they can be used to describe how the system changes in different ways. The paper also includes some challenging problems to help readers understand these ideas better.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In a recent study, M. Rahman discovered a special group of equations that describe how things change over time. These equations are called polynomials, and they have two parts. These equations are connected to a probability model created by M. Hoare and Rahman themselves. One of the interesting things is that these polynomials have a unique feature called \"bispectral.\" This is just one of many interesting properties these polynomials have. If you want to learn more about these polynomials and the way they work, you can look at the last part of the study.",
          "error": null
        },
        "adult_technical": {
          "text": "In a recent publication, M. Rahman introduced a remarkable family of bivariate polynomials that serve as eigenfunctions for the transition matrix of a nontrivial Markov chain developed by M. Hoare and M. Rahman. These polynomials exhibit bispectral properties, which is one of their unique characteristics. However, this is just one aspect of their many remarkable properties. For further exploration, including a general proof of some of the facts presented here, the reader is referred to the concluding section of this paper.",
          "error": null
        }
      }
    },
    {
      "id": 11,
      "title": "Non static Global monopole in Lyra geometry",
      "original_text": "A class of non static solutions around a global monopole resulting from the breaking of a global S0(3) symmetry based on Lyra geometry are obtained. The solutions are obtained using the functional separability of the metric coefficients. We have shown that the monopole exerts attractive gravitational effects on test particles.",
      "generations": {
        "easy_general": {
          "text": "Imagine a universe where there's a special kind of object called a \"global monopole.\" This object is like a giant magnet that changes the shape of space around it. Scientists have discovered that this monopole can pull other objects towards it, like a gravitational force. They used a special math tool called \"functional separability\" to figure this out.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Imagine a universe with a mysterious object called a \"global monopole.\" This object is the result of a special kind of symmetry breaking in a type of geometry called \"Lyra geometry.\" Scientists have discovered that this monopole has gravitational effects on smaller objects called \"test particles.\"",
          "error": null
        },
        "adult_technical": {
          "text": "A set of non-stationary solutions around a global monopole, which arises from the breaking of a global S0(3) symmetry based on Lyra geometry, have been derived. These solutions are obtained by exploiting the separability of the metric coefficients. Our analysis demonstrates that the monopole exerts an attractive gravitational influence on test particles.",
          "error": null
        }
      }
    },
    {
      "id": 12,
      "title": "CPT and Lorentz violation effects in hydrogen-like atoms",
      "original_text": "Within the framework of Lorentz-violating extended electrodynamics, the Dirac equation for a bound electron in an external electromagnetic field is considered assuming the interaction with a CPT-odd axial vector background $b_\\mu$. The quasi-relativistic Hamiltonian is obtained using a $1/c$-series expansion. Relativistic Dirac eigenstates in a spherically-symmetric potential are found accurate up to the second order in $b_0$. $b_0$-induced CPT-odd corrections to the electromagnetic dipole moment operators of a bound electron are calculated that contribute to the anapole moment of the atomic orbital and may cause a specific asymmetry of the angular distribution of the radiation of a hydrogen atom.",
      "generations": {
        "easy_general": {
          "text": "Imagine you have a tiny electron in a magnetic field. Scientists use a special equation called the Dirac equation to understand how the electron behaves. They also consider a special background field that interacts with the magnetic field. This helps them understand how the electron behaves in different situations.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In a special area of physics called \"Lorentz-violating extended electrodynamics,\" scientists look at how electrons behave when they're affected by an electromagnetic field. They use a tool called the \"Dirac equation\" to study this, and they add a special background called \"b_\\mu\" to the mix. This helps them understand how electrons move and interact with each other.",
          "error": null
        },
        "adult_technical": {
          "text": "In the context of Lorentz-violating extended electrodynamics, the Dirac equation for a bound electron in an external electromagnetic field is examined, assuming the interaction with a CPT-odd axial vector background $b_\\mu$. The quasi-relativistic Hamiltonian is derived using a $1/c$-series expansion. Relativistic Dirac eigenstates in a spherically-symmetric potential are determined up to the second order in $b_0$. $b_0$-induced CPT-odd corrections to the electromagnetic dipole moment operators of a bound electron are calculated, which contribute to the anapole moment of the atomic orbital and may induce a specific asymmetry in the angular distribution of the radiation of a hydrogen atom.",
          "error": null
        }
      }
    },
    {
      "id": 13,
      "title": "Lower ground state due to counter-rotating wave interaction in trapped ion system",
      "original_text": "We consider a single ion confined in a trap under radiation of two traveling waves of lasers. In the strong-excitation regime and without the restriction of Lamb-Dicke limit, the Hamiltonian of the system is similar to a driving Jaynes-Cummings model without rotating wave approximation (RWA). The approach we developed enables us to present a complete eigensolutions, which makes it available to compare with the solutions under the RWA. We find that, the ground state in our non-RWA solution is energically lower than the counterpart under the RWA. If we have the ion in the ground state, it is equivalent to a spin dependent force on the trapped ion. Discussion is made for the difference between the solutions with and without the RWA, and for the relevant experimental test, as well as for the possible application in quantum information processing.",
      "generations": {
        "easy_general": {
          "text": "Imagine a single ion trapped in a box with two laser beams shining on it. When the lasers are very strong, we can describe this situation using a model called the Jaynes-Cummings model. This model helps us understand how the ion interacts with the lasers. However, we usually use a trick called the rotating wave approximation (RWA) to make it easier to understand what's going on.\n\nIn this study, we found a way to look at the situation without using the RWA. We discovered that the ground state of the ion has less energy when we don't use the RWA. This means that the ion behaves differently when we don't use the RWA, and it's like having a force that depends on the ion's spin.\n\nWe also compared our results with the ones we get when we use the RWA. We found that there are some differences, and this could be important for experiments and for processing quantum information.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Imagine a single ion trapped in a container and being hit by two laser beams. When the lasers are very strong, we can describe this situation using a model called the Jaynes-Cummings model. However, in this case, we don't use a trick called the rotating wave approximation (RWA), which is usually used to simplify the calculations.\n\nBy using a new approach, we can find all the possible states of the ion and compare them to what we get when we use the RWA. We find that the lowest energy state of the ion is lower when we don't use the RWA. This means that when the ion is in its lowest energy state, it's like having a force that depends on its spin.\n\nWe can also discuss the differences between the solutions with and without the RWA, and how we can test this in an experiment. This could have important implications for quantum information processing, which is a way to process information using quantum mechanics.",
          "error": null
        },
        "adult_technical": {
          "text": "In the context of a single ion confined in a trap and illuminated by two traveling laser waves, we examine the strong-excitation regime without the constraint of the Lamb-Dicke limit. The Hamiltonian of this system is analogous to a driven Jaynes-Cummings model without the rotating wave approximation (RWA). Our approach allows us to derive a complete set of eigensolutions, which can be compared with those obtained under the RWA. We observe that the ground state in our non-RWA solution is energetically lower than its counterpart under the RWA. When the ion is in the ground state, it is equivalent to a spin-dependent force acting on the trapped ion. We discuss the differences between the solutions with and without the RWA, the implications for experimental tests, and the potential applications in quantum information processing.",
          "error": null
        }
      }
    },
    {
      "id": 14,
      "title": "Resonant Kelvin-Helmholtz modes in sheared relativistic flows",
      "original_text": "Qualitatively new aspects of the (linear and non-linear) stability of sheared relativistic (slab) jets are analyzed. The linear problem has been solved for a wide range of jet models well inside the ultrarelativistic domain (flow Lorentz factors up to 20; specific internal energies $\\approx 60c^2$). As a distinct feature of our work, we have combined the analytical linear approach with high-resolution relativistic hydrodynamical simulations, which has allowed us i) to identify, in the linear regime, resonant modes specific to the relativistic shear layer ii) to confirm the result of the linear analysis with numerical simulations and, iii) more interestingly, to follow the instability development through the non-linear regime. We find that very high-order reflection modes with dominant growth rates can modify the global, long-term stability of the relativistic flow. We discuss the dependence of these resonant modes on the jet flow Lorentz factor and specific internal energy, and on the shear layer thickness. The results could have potential applications in the field of extragalactic relativistic jets.",
      "generations": {
        "easy_general": {
          "text": "In this study, we look at some new things about the stability of very fast jets in space. These jets are called \"relativistic jets\" because they move so fast that they follow the laws of relativity. We use special math and computer simulations to understand the changes that happen in these jets. We find that when these changes grow very big and fast, they can change the way the jets behave overall. This could help us understand how these jets work in outer space.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this study, we looked at the stability of very fast-moving jets of gas and particles, called relativistic jets. These jets are found in distant galaxies and can move at nearly the speed of light. We wanted to understand how these jets behave when they are sheared, which means they have different speeds in different parts.\n\nWe started by analyzing the linear stability of these jets, which is like how they behave when they are slightly pushed or disturbed. We did this for a wide range of jet models, focusing on the fastest of these fast jets. What's unique about our work is that we combined this linear analysis with high-resolution computer simulations.\n\nIn the linear analysis, we found some specific types of behavior, called resonant modes. These modes are very important for the stability of the jets, but we didn't know exactly how they worked until now. We confirmed our findings using computer simulations, which helped us understand how these modes affect the stability of the jets.\n\nOur results could be important for understanding how these jets behave in the wider universe, beyond our own galaxy.",
          "error": null
        },
        "adult_technical": {
          "text": "This study examines the linear and non-linear stability of sheared relativistic (slab) jets. The linear stability problem has been solved for a wide range of jet models within the ultrarelativistic domain, with flow Lorentz factors up to 20 and specific internal energies of approximately 60c^2. A unique feature of this work is the combination of analytical linear analysis with high-resolution relativistic hydrodynamical simulations. This approach has enabled the identification of resonant modes specific to the relativistic shear layer, confirmation of the linear analysis results through numerical simulations, and the tracking of the instability development through the non-linear regime. The findings indicate that very high-order reflection modes with dominant growth rates can alter the global, long-term stability of the relativistic flow. We also discuss the dependence of these resonant modes on the jet flow Lorentz factor, specific internal energy, and shear layer thickness. These results have potential applications in the field of extragalactic relativistic jets.",
          "error": null
        }
      }
    },
    {
      "id": 15,
      "title": "Fractional Generalization of Kac Integral",
      "original_text": "Generalization of the Kac integral and Kac method for paths measure based on the Levy distribution has been used to derive fractional diffusion equation. Application to nonlinear fractional Ginzburg-Landau equation is discussed.",
      "generations": {
        "easy_general": {
          "text": "Imagine you're trying to understand how things move in a special kind of space. Scientists used a new way to measure paths, based on something called the Levy distribution, to figure out how things spread out in this space. They also used this idea to study a complex equation.",
          "error": null
        },
        "adult_non_technical": {
          "text": "\"Scientists used a special type of math called the Kac integral to create a new way to describe how things spread out over time. They applied this method to a complex equation called the nonlinear fractional Ginzburg-Landau equation, which helps us understand how certain systems behave.\"",
          "error": null
        },
        "adult_technical": {
          "text": "The generalization of the Kac integral and Kac method for paths measure based on the Levy distribution has been employed to derive the fractional diffusion equation. Its application to the nonlinear fractional Ginzburg-Landau equation is discussed.",
          "error": null
        }
      }
    },
    {
      "id": 16,
      "title": "The fluctuation spectra around a Gaussian classical solution of a tensor model and the general relativity",
      "original_text": "Tensor models can be interpreted as theory of dynamical fuzzy spaces. In this paper, I study numerically the fluctuation spectra around a Gaussian classical solution of a tensor model, which represents a fuzzy flat space in arbitrary dimensions. It is found that the momentum distribution of the low-lying low-momentum spectra is in agreement with that of the metric tensor modulo the general coordinate transformation in the general relativity at least in the dimensions studied numerically, i.e. one to four dimensions. This result suggests that the effective field theory around the solution is described in a similar manner as the general relativity.",
      "generations": {
        "easy_general": {
          "text": "Tensor models can be seen as theories of changing, unclear spaces. In this paper, I look at the changes in a special type of tensor model, which represents a fuzzy, flat space in any number of dimensions. I found that the patterns of these changes are similar to the patterns in general relativity. This means that these changes can be described in a similar way as general relativity.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Tensor models can be seen as theories about changing, unclear spaces. In this paper, I look at the numerical fluctuations around a simple solution of a tensor model, which represents a fuzzy, flat space in any number of dimensions. I found that the distribution of momentum in these low-energy fluctuations is similar to the metric tensor in general relativity, at least in the first four dimensions. This suggests that the effective field theory around the solution behaves a lot like general relativity.",
          "error": null
        },
        "adult_technical": {
          "text": "Tensor models can be interpreted as theories of dynamical fuzzy spaces. In this paper, I numerically study the fluctuation spectra around a Gaussian classical solution of a tensor model, which represents a fuzzy flat space in arbitrary dimensions. It is found that the momentum distribution of the low-lying low-momentum spectra is in agreement with that of the metric tensor modulo the general coordinate transformation in general relativity at least in the dimensions studied numerically, i.e. one to four dimensions. This result suggests that the effective field theory around the solution is described in a similar manner as general relativity.",
          "error": null
        }
      }
    },
    {
      "id": 17,
      "title": "Monge-Amp\\`ere Measures for Convex Bodies and Bernstein-Markov Type Inequalities",
      "original_text": "We use geometric methods to calculate a formula for the complex Monge-Amp\\`ere measure $(dd^cV_K)^n$, for $K \\Subset \\RR^n \\subset \\CC^n$ a convex body and $V_K$ its Siciak-Zaharjuta extremal function. Bedford and Taylor had computed this for symmetric convex bodies $K$. We apply this to show that two methods for deriving Bernstein-Markov-type inequalities, i.e., pointwise estimates of gradients of polynomials, yield the same results for all convex bodies. A key role is played by the geometric result that the extremal inscribed ellipses appearing in approximation theory are the maximal area ellipses determining the complex Monge-Amp\\`ere solution $V_K$.",
      "generations": {
        "easy_general": {
          "text": "We use a special kind of math called geometry to find a formula for the complex Monge-Amp\\`ere measure. This formula helps us understand how different shapes relate to each other. We use this formula to show that two different ways of looking at these shapes give the same answers.",
          "error": null
        },
        "adult_non_technical": {
          "text": "\"We found a new way to calculate a special formula related to geometric shapes called convex bodies. This formula is important because it helps us understand how these shapes behave in different situations. We used this formula to show that two different methods for estimating the gradients of polynomials give the same results for all convex bodies. A key part of our work is a geometric result that connects special ellipses in approximation theory to the complex Monge-Amp\\`ere solution $V_K$.\"",
          "error": null
        },
        "adult_technical": {
          "text": "We employ geometric techniques to derive a formula for the complex Monge-Amp\\`ere measure $(dd^cV_K)^n$, where $K \\Subset \\RR^n \\subset \\CC^n$ is a convex body and $V_K$ is its Siciak-Zaharjuta extremal function. Bedford and Taylor had previously computed this measure for symmetric convex bodies $K$. We utilize this result to demonstrate that two distinct approaches for establishing Bernstein-Markov-type inequalities, which provide pointwise estimates of the gradients of polynomials, produce identical outcomes for all convex bodies. A crucial component is the geometric theorem stating that the extremal inscribed ellipses in approximation theory correspond to the maximal area ellipses that determine the complex Monge-Amp\\`ere solution $V_K$.",
          "error": null
        }
      }
    },
    {
      "id": 18,
      "title": "Construction of type ${\\rm II_1}$ factors with prescribed countable fundamental group",
      "original_text": "In the context of Free Probability Theory, we study two different constructions that provide new examples of factors of type ${\\rm II_1}$ with prescribed fundamental group. First we investigate state-preserving group actions on the almost periodic free Araki-Woods factors satisfying both a condition of mixing and a condition of free malleability in the sense of Popa. Typical examples are given by the free Bogoliubov shifts. Take an ICC $w$-rigid group $G$ such that $\\mathcal{F}(L(G)) = \\{1\\}$ (e.g. $G = \\Z^2 \\rtimes \\SL(2, \\Z)$). For any countable subgroup $S \\subset \\R^*_+$, we show that there exists an action of $G$ on $L(\\F_\\infty)$ such that $L(\\F_\\infty) \\rtimes G$ is a type ${\\rm II_1}$ factor and its fundamental group is $S$. The second construction is based on a free product. Take $(B(H), \\psi)$ any factor of type ${\\rm I}$ endowed with a faithful normal state and denote by $\\Gamma \\subset \\R^*_+$ the subgroup generated by the point spectrum of $\\psi$. We show that the centralizer $(L(G) \\ast B(H))^{\\tau \\ast \\psi}$ is a type ${\\rm II_1}$ factor and its fundamental group is $\\Gamma$. Our proofs rely on Popa's deformation/rigidity strategy using his intertwining-by-bimodules technique.",
      "generations": {
        "easy_general": {
          "text": "In the world of Free Probability Theory, we explore two ways to create new examples of special objects called \"factors of type II_1\" with a specific fundamental group. These objects are like mathematical building blocks that help us understand how different systems work.\n\nFirst, we look at a group of actions called \"state-preserving group actions\" on \"almost periodic free Araki-Woods factors.\" These actions have two important properties: \"mixing\" and \"free malleability.\" These properties are like special rules that make the actions behave in a certain way. An example of these actions is the \"free Bogoliubov shifts.\"\n\nNext, we use a special type of group called an \"ICC $w$-rigid group.\" This group has a unique property: its fundamental group is just the number 1. We show that we can use this group to create a new type of \"factor of type II_1\" with a specific fundamental group.\n\nFinally, we use a technique called \"free product\" to create another type of \"factor of type II_1\" with a specific fundamental group.\n\nThese methods help us understand how different mathematical systems work and how they can be combined to create new ones.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In the field of Free Probability Theory, we explore two ways to create new examples of something called a \"type II1 factor\" with a specific fundamental group. \n\nFirst, we look at a type of group action called \"state-preserving\" on a special kind of factor called \"almost periodic free Araki-Woods factors.\" These factors have two important properties: \"mixing\" and \"free malleability.\" An example of these factors is the \"free Bogoliubov shift.\"\n\nNext, we consider a specific type of group called an \"ICC w-rigid group.\" This group has a unique property: its \"L(G)\" set only contains the number 1. An example of such a group is \"G = Z^2  SL(2, Z).\"\n\nFor any countable group called \"S,\" which is a subgroup of positive real numbers, we show that we can create a new type \"II1 factor\" with \"S\" as its fundamental group.\n\nThe second method involves using something called a \"free product.\" We take a special type of factor called \"type I\" and combine it with the \"L(G)\" set to create a new type II1 factor with a specific fundamental group.",
          "error": null
        },
        "adult_technical": {
          "text": "In the realm of Free Probability Theory, we explore two distinct constructions that yield novel examples of factors of type ${\\rm II_1}$ with a specified fundamental group. Initially, we examine state-preserving group actions on the almost periodic free Araki-Woods factors that fulfill the conditions of mixing and free malleability as defined by Popa. Illustrative examples include the free Bogoliubov shifts. Consider an ICC $w$-rigid group $G$ such that $\\mathcal{F}(L(G)) = \\{1\\}$, such as $G = \\Z^2 \\rtimes \\SL(2, \\Z)$. For any countable subgroup $S \\subset \\R^*_+$, we demonstrate the existence of an action of $G$ on $L(\\F_\\infty)$, resulting in $L(\\F_\\infty) \\rtimes G$ being a type ${\\rm II_1}$ factor with its fundamental group being $S$. The second construction involves a free product. Let $(B(H), \\psi)$ be any factor of type ${\\rm I}$ equipped with a faithful normal state, and let $\\Gamma \\subset \\R^*_+$ be the subgroup generated by the point spectrum of $\\psi$. We establish that the centralizer $(L(G) \\ast B(H))^{\\tau \\ast \\psi}$ is a type ${\\rm II_1}$ factor, and its fundamental group is $\\Gamma$. Our proofs are grounded in Popa's deformation/rigidity strategy, utilizing his intertwining-by-bimodules technique.",
          "error": null
        }
      }
    },
    {
      "id": 19,
      "title": "True and Apparent Scaling: The Proximity of the Markov-Switching Multifractal Model to Long-Range Dependence",
      "original_text": "In this paper, we consider daily financial data of a collection of different stock market indices, exchange rates, and interest rates, and we analyze their multi-scaling properties by estimating a simple specification of the Markov-switching multifractal model (MSM). In order to see how well the estimated models capture the temporal dependence of the data, we estimate and compare the scaling exponents $H(q)$ (for $q = 1, 2$) for both empirical data and simulated data of the estimated MSM models. In most cases the multifractal model appears to generate `apparent' long memory in agreement with the empirical scaling laws.",
      "generations": {
        "easy_general": {
          "text": "In this paper, we look at daily financial data from different stock markets, exchange rates, and interest rates. We use a simple model called the Markov-switching multifractal model (MSM) to understand how these numbers change over time. To see how well our model captures these changes, we compare the scaling exponents of the real data and the simulated data from the MSM model. In most cases, the MSM model seems to show long memory, like the real data.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this study, we look at daily financial data from different stock markets, exchange rates, and interest rates. We use a special model called the Markov-switching multifractal model (MSM) to understand how these numbers change over time. To check how well the model fits the data, we calculate something called scaling exponents, which help us see the patterns in the data. Our results show that the model seems to capture the long-term patterns in the data.",
          "error": null
        },
        "adult_technical": {
          "text": "In this paper, we examine daily financial data from a variety of stock market indices, exchange rates, and interest rates. To analyze their multi-scaling properties, we estimate a Markov-switching multifractal model (MSM). To assess the model's ability to capture temporal dependencies, we estimate and compare the scaling exponents $H(q)$ for $q = 1, 2$ for both empirical and simulated data from the estimated MSM models. In most cases, the multifractal model appears to generate apparent long memory in agreement with empirical scaling laws.",
          "error": null
        }
      }
    },
    {
      "id": 20,
      "title": "Bremsstrahlung Radiation At a Vacuum Bubble Wall",
      "original_text": "When charged particles collide with a vacuum bubble, they can radiate strong electromagnetic waves due to rapid deceleration. Owing to the energy loss of the particles by this bremsstrahlung radiation, there is a non-negligible damping pressure acting on the bubble wall even when thermal equilibrium is maintained. In the non-relativistic region, this pressure is proportional to the velocity of the wall and could have influenced the bubble dynamics in the early universe.",
      "generations": {
        "easy_general": {
          "text": "When charged particles crash into a vacuum bubble, they can release strong electromagnetic waves because they slow down very quickly. This process is called bremsstrahlung radiation. As the particles lose energy through this radiation, they exert a force on the bubble wall. This force is not negligible, even when the temperature is stable. In the non-relativistic region, this force is related to the speed of the bubble wall and could have affected how the bubble moved in the early universe.",
          "error": null
        },
        "adult_non_technical": {
          "text": "When charged particles collide with a vacuum bubble, they can emit strong electromagnetic waves as they slow down quickly. This process is called bremsstrahlung radiation. The energy lost by the particles through this radiation creates a damping pressure on the bubble wall, even when the system is in thermal equilibrium. In the non-relativistic region, this pressure is proportional to the velocity of the bubble wall and could have affected the dynamics of the bubble in the early universe.",
          "error": null
        },
        "adult_technical": {
          "text": "When charged particles collide with a vacuum bubble, they can emit strong electromagnetic waves due to rapid deceleration. This process, known as bremsstrahlung radiation, results in energy loss for the particles, causing a non-negligible damping pressure on the bubble wall, even when thermal equilibrium is maintained. In the non-relativistic region, this pressure is proportional to the velocity of the wall and could have influenced the bubble dynamics in the early universe.",
          "error": null
        }
      }
    },
    {
      "id": 21,
      "title": "The Phase Structure of the Polyakov--Quark-Meson Model",
      "original_text": "The relation between the deconfinement and chiral phase transition is explored in the framework of an Polyakov-loop-extended two-flavor quark-meson (PQM) model. In this model the Polyakov loop dynamics is represented by a background temporal gauge field which also couples to the quarks. As a novelty an explicit quark chemical potential and N_f-dependence in the Polyakov loop potential is proposed by using renormalization group arguments. The behavior of the Polyakov loop as well as the chiral condensate as function of temperature and quark chemical potential is obtained by minimizing the grand canonical thermodynamic potential of the system. The effect of the Polyakov loop dynamics on the chiral phase diagram and on several thermodynamic bulk quantities is presented.",
      "generations": {
        "easy_general": {
          "text": "In this study, we explore the relationship between two processes called deconfinement and chiral phase transition. We use a model called the Polyakov-loop-extended two-flavor quark-meson (PQM) model to understand these processes. In this model, we represent the dynamics of the Polyakov loop using a background temporal gauge field, which also interacts with quarks. We introduce an explicit quark chemical potential and N_f-dependence in the Polyakov loop potential using renormalization group arguments. We then study the behavior of the Polyakov loop and the chiral condensate as a function of temperature and quark chemical potential by minimizing the grand canonical thermodynamic potential of the system. Finally, we present the effect of the Polyakov loop dynamics on the chiral phase diagram and several thermodynamic bulk quantities.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this study, we use a model called Polyakov-loop-extended two-flavor quark-meson (PQM) model to explore the relationship between deconfinement and chiral phase transition. This model uses a background temporal gauge field to represent the dynamics of the Polyakov loop, which couples to the quarks.",
          "error": null
        },
        "adult_technical": {
          "text": "The relationship between deconfinement and the chiral phase transition is investigated within the framework of a Polyakov-loop-extended two-flavor quark-meson (PQM) model. In this model, the dynamics of the Polyakov loop is represented by a background temporal gauge field that also interacts with the quarks. A novel aspect is the introduction of an explicit quark chemical potential and flavor number (N_f) dependence in the Polyakov loop potential, which is justified by renormalization group arguments. The behavior of the Polyakov loop and the chiral condensate as functions of temperature and quark chemical potential is determined by minimizing the grand canonical thermodynamic potential of the system. The impact of the Polyakov loop dynamics on the chiral phase diagram and various thermodynamic bulk quantities is presented.",
          "error": null
        }
      }
    },
    {
      "id": 22,
      "title": "X-ray Microdiffraction Images of Antiferromagnetic Domain Evolution in Chromium",
      "original_text": "Magnetic x-ray diffraction combined with x-ray focusing optics is used to image individual antiferromagnetic spin density wave domains in a chromium single crystal at the micron scale. The cross section for non-resonant magnetic x-ray scattering depends on the antiferromagnetic modulation vector and spin polarization direction and allows these quantities to be extracted independently. The technique is used to show that the broadening of the nominally first order \"spin-flip\" transition at 123 K, at which the spins rotate by 90 deg., originates at the walls between domains with orthogonal modulation vectors. During cooling the transition begins at these walls and progresses inwards. The modulation-vector domains are themselves unchanged.",
      "generations": {
        "easy_general": {
          "text": "Scientists used a special technique to look at tiny parts of a metal called chromium. They used a tool called x-ray diffraction to see small areas called \"antiferromagnetic spin density wave domains\" inside the metal. These areas are like little neighborhoods where the atoms in the metal are arranged in a special way.\n\nThe scientists found that when the metal gets colder, a special change called a \"spin-flip\" transition happens. This change happens at the edges between these little neighborhoods, and it starts at the edges and moves towards the center of the metal. The neighborhoods themselves don't change, but the edges between them do.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Scientists used a technique called magnetic x-ray diffraction to look at tiny areas in a chromium crystal called antiferromagnetic spin density wave domains. They found that these areas change when the crystal is cooled.",
          "error": null
        },
        "adult_technical": {
          "text": "Using magnetic x-ray diffraction and x-ray focusing optics, we can visualize antiferromagnetic spin density wave domains in a chromium single crystal at the micron scale. The non-resonant magnetic x-ray scattering cross section depends on the antiferromagnetic modulation vector and spin polarization direction, allowing us to extract these quantities independently. This technique reveals that the broadening of the nominally first-order \"spin-flip\" transition at 123 K, at which the spins rotate by 90 degrees, originates at the walls between domains with orthogonal modulation vectors. During cooling, the transition begins at these walls and progresses inwards. The modulation-vector domains themselves remain unchanged.",
          "error": null
        }
      }
    },
    {
      "id": 23,
      "title": "Superconducting states of the quasi-2D Holstein model: Effects of vertex and non-local corrections",
      "original_text": "I investigate superconducting states in a quasi-2D Holstein model using the dynamical cluster approximation (DCA). The effects of spatial fluctuations (non-local corrections) are examined and approximations neglecting and incorporating lowest-order vertex corrections are computed. The approximation is expected to be valid for electron-phonon couplings of less than the bandwidth. The phase diagram and superconducting order parameter are calculated. Effects which can only be attributed to theories beyond Migdal--Eliashberg theory are present. In particular, the order parameter shows momentum dependence on the Fermi-surface with a modulated form and s-wave order is suppressed at half-filling. The results are discussed in relation to Hohenberg's theorem and the BCS approximation.",
      "generations": {
        "easy_general": {
          "text": "I look at superconducting states in a quasi-2D Holstein model using a method called the dynamical cluster approximation (DCA). I study how small changes affect the model and compare different approximations. The results show that the approximation is valid for small electron-phonon couplings. I calculate the phase diagram and superconducting order parameter and find effects that cannot be explained by Migdal--Eliashberg theory. These results are related to Hohenberg's theorem and the BCS approximation.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this study, I look at superconducting states in a quasi-2D Holstein model using a method called the dynamical cluster approximation (DCA). This method helps us understand how electrons behave in a material with a two-dimensional structure. I also examine the effects of spatial fluctuations, or non-local corrections, which affect the behavior of electrons. I compute two approximations: one that ignores and includes the lowest-order vertex corrections. The approximation is expected to be accurate when the interaction between electrons and phonons is weaker than the energy range of the material. Additionally, I calculate the phase diagram and superconducting order parameter, which help us understand the behavior of superconducting materials. The results show effects that cannot be explained by Migdal-Eliashberg theory, such as a momentum dependence on the Fermi-surface and the suppression of s-wave order at half-filling. These findings are also related to Hohenberg's theorem and the BCS approximation.",
          "error": null
        },
        "adult_technical": {
          "text": "I investigate the superconducting states in a quasi-2D Holstein model using the dynamical cluster approximation (DCA). The effects of spatial fluctuations (non-local corrections) are examined, and approximations neglecting and incorporating lowest-order vertex corrections are computed. The approximation is expected to be valid for electron-phonon couplings of less than the bandwidth. The phase diagram and superconducting order parameter are calculated. Effects which can only be attributed to theories beyond Migdal-Eliashberg theory are present. In particular, the order parameter shows momentum dependence on the Fermi-surface with a modulated form and s-wave order is suppressed at half-filling. The results are discussed in relation to Hohenberg's theorem and the BCS approximation.",
          "error": null
        }
      }
    },
    {
      "id": 24,
      "title": "Spin coherence of holes in GaAs/AlGaAs quantum wells",
      "original_text": "The carrier spin coherence in a p-doped GaAs/(Al,Ga)As quantum well with a diluted hole gas has been studied by picosecond pump-probe Kerr rotation with an in-plane magnetic field. For resonant optical excitation of the positively charged exciton the spin precession shows two types of oscillations. Fast oscillating electron spin beats decay with the radiative lifetime of the charged exciton of 50 ps. Long lived spin coherence of the holes with dephasing times up to 650 ps. The spin dephasing time as well as the in-plane hole g factor show strong temperature dependence, underlining the importance of hole localization at cryogenic temperatures.",
      "generations": {
        "easy_general": {
          "text": "Scientists studied a special type of material called a \"quantum well\" to understand how particles behave inside it. They used a technique called \"picosecond pump-probe Kerr rotation\" to observe the behavior of these particles. They found that the particles have two types of oscillations, one fast and one slow. The fast oscillations decay quickly, while the slow oscillations last longer. The scientists also discovered that the behavior of these particles changes when the temperature is very low.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Scientists studied a special type of material called a \"quantum well\" to understand the behavior of tiny particles called \"holes\" inside the material. They used a technique called \"picosecond pump-probe Kerr rotation\" to observe how these holes behave when exposed to light. They found that the holes have a unique property called \"spin coherence,\" which helps them stay organized even at very low temperatures.",
          "error": null
        },
        "adult_technical": {
          "text": "The carrier spin coherence in a p-doped GaAs/(Al,Ga)As quantum well with a diluted hole gas has been investigated using picosecond pump-probe Kerr rotation with an in-plane magnetic field. Upon resonant optical excitation of the positively charged exciton, the spin precession exhibits two types of oscillations. The fast oscillating electron spin beats decay with the radiative lifetime of the charged exciton of 50 ps, while the long-lived spin coherence of the holes displays dephasing times up to 650 ps. The spin dephasing time and the in-plane hole g factor exhibit strong temperature dependence, highlighting the significance of hole localization at cryogenic temperatures.",
          "error": null
        }
      }
    },
    {
      "id": 25,
      "title": "Generation of Large Number-Path Entanglement Using Linear Optics and Feed-Forward",
      "original_text": "We show how an idealised measurement procedure can condense photons from two modes into one, and how, by feeding forward the results of the measurement, it is possible to generate efficiently superpositions of components for which only one mode is populated, commonly called ``N00N states''. For the basic procedure, sources of number states leak onto a beam splitter, and the output ports are monitored by photodetectors. We find that detecting a fixed fraction of the input at one output port suffices to direct the remainder to the same port with high probability, however large the initial state. When instead photons are detected at both ports, Schr\\\"{o}dinger cat states are produced. We describe a circuit for making the components of such a state orthogonal, and another for subsequent conversion to a N00N state. Our approach scales exponentially better than existing proposals. Important applications include quantum imaging and metrology.",
      "generations": {
        "easy_general": {
          "text": "Imagine you have two groups of friends, and you want to combine them into one group. You can do this by looking at each groups and making a decision.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Imagine a special technique that can combine light from two sources into one. This technique, called \"N00N states,\" can help improve quantum imaging and metrology. By using a beam splitter and photodetectors, we can measure the light and direct it to a specific output port with high accuracy. This method is more efficient than existing approaches and has important applications in quantum technology.",
          "error": null
        },
        "adult_technical": {
          "text": "\"We demonstrate how an idealized measurement procedure can condense photons from two modes into one, and how, by using the results of the measurement, we can efficiently generate superpositions of components for which only one mode is populated, commonly called 'N00N states'. For the basic procedure, sources of number states leak onto a beam splitter, and the output ports are monitored by photodetectors. We find that detecting a fixed fraction of the input at one output port is sufficient to direct the remainder to the same port with high probability, regardless of the initial state. When instead photons are detected at both ports, Schrdinger cat states are produced. We describe a circuit for making the components of such a state orthogonal, and another for subsequent conversion to a N00N state. Our approach scales exponentially better than existing proposals. Important applications include quantum imaging and metrology.\"",
          "error": null
        }
      }
    },
    {
      "id": 26,
      "title": "Multilayer Perceptron with Functional Inputs: an Inverse Regression Approach",
      "original_text": "Functional data analysis is a growing research field as more and more practical applications involve functional data. In this paper, we focus on the problem of regression and classification with functional predictors: the model suggested combines an efficient dimension reduction procedure [functional sliced inverse regression, first introduced by Ferr\\'e & Yao (Statistics, 37, 2003, 475)], for which we give a regularized version, with the accuracy of a neural network. Some consistency results are given and the method is successfully confronted to real-life data.",
      "generations": {
        "easy_general": {
          "text": "Functional data analysis is becoming more popular, as more and more applications use functional data. In this paper, we look at how to do regression and classification with functional data. We use a method that combines a technique called \"functional sliced inverse regression,\" which was introduced by Ferr & Yao in 2003, with a neural network. This method has been tested and it works well with real-life data.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Functional data analysis is becoming more popular as more and more practical applications involve functional data. In this paper, we focus on regression and classification with functional predictors: the model suggested combines an efficient dimension reduction procedure [functional sliced inverse regression] with the accuracy of a neural network. Some consistency results are given and the method is successfully confronted to real-life data.",
          "error": null
        },
        "adult_technical": {
          "text": "Functional data analysis is an increasingly important area of research, as many practical applications now involve functional data. In this paper, we concentrate on the problem of regression and classification with functional predictors. The proposed model integrates an efficient dimension reduction technique, functional sliced inverse regression, first introduced by Ferr & Yao (Statistics, 37, 2003, 475), with a regularized version and the accuracy of a neural network. We provide consistency results and demonstrate the method's effectiveness with real-life data.",
          "error": null
        }
      }
    },
    {
      "id": 27,
      "title": "Solution of the Dirac equation in presence of an uniform magnetic field",
      "original_text": "In this work we discuss the properties of the solutions of the Dirac equation in presence of an uniform background magnetic field. In particular we focus on the nature of the solutions, their ortho-normality properties and how these solutions depend on the choice of the vector potential giving rise to the magnetic field. We explicitly calculate the spin-sum of the solutions and using it we calculate the propagator of the electron in presence of an uniform background magnetic field.",
      "generations": {
        "easy_general": {
          "text": "In this study, we look at the solutions to an equation called the Dirac equation when there is a strong magnetic field around. We explore how these solutions behave and how they relate to each other and to the magnetic field. We also calculate a special property called the spin-sum and use it to understand how an electron moves in this magnetic field.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this study, we look at the solutions of the Dirac equation when there's a uniform magnetic field present. We focus on the nature of these solutions, how they relate to each other, and how they change depending on how we describe the magnetic field. We also calculate the spin-sum of these solutions and use it to understand how an electron moves in this magnetic field.",
          "error": null
        },
        "adult_technical": {
          "text": "In this work, we delve into the properties of the Dirac equation's solutions when a uniform background magnetic field is present. Specifically, we examine the nature of these solutions, their ortho-normality properties, and how they are influenced by the choice of vector potential that generates the magnetic field. We explicitly compute the spin-sum of the solutions and use it to determine the propagator of the electron in the presence of a uniform background magnetic field.",
          "error": null
        }
      }
    },
    {
      "id": 28,
      "title": "The X-ray Pulse Profile of BG CMi",
      "original_text": "We present an analysis of the X-ray data of a magnetic cataclysmic variable, BG CMi, obtained with ROSAT in March 1992 and with ASCA in April 1996. We show that four peaks clearly exist in the X-ray pulse profile, unlike a single peak found in the optical profile. The fluxes of two major pulses are $\\sim 2 - 5$ times larger than those of two minor pulses. The fraction of the total pulsed flux increases from 51% to 85% with increasing energy in 0.1 $-$ 2.0 keV, whereas it decreases from 96% to 22% in 0.8 $-$ 10 keV. We discuss the implications of our findings for the origin of the pulse profile and its energy dependence.",
      "generations": {
        "easy_general": {
          "text": "We looked at data from a star called BG CMi using two space telescopes. We found that there are four peaks in the X-ray light coming from the star, but only one peak in the visible light. The bigger peaks are much brighter than the smaller ones. We also found that the brightness of the peaks changes depending on the energy of the X-rays. We are thinking about what this means.",
          "error": null
        },
        "adult_non_technical": {
          "text": "We looked at data from a special type of star called a magnetic cataclysmic variable, BG CMi. We found that there are four peaks in the X-ray light coming from this star, but only one peak in the visible light. The bigger peaks are much brighter than the smaller ones. We also noticed that the amount of X-ray light changes depending on the light's strength or energy. These findings help us understand how this star works.",
          "error": null
        },
        "adult_technical": {
          "text": "We present an analysis of the X-ray data of a magnetic cataclysmic variable, BG CMi, obtained with ROSAT in March 1992 and with ASCA in April 1996. We show that four peaks clearly exist in the X-ray pulse profile, unlike a single peak found in the optical profile. The fluxes of two major pulses are $\\sim 2 - 5$ times larger than those of two minor pulses. The fraction of the total pulsed flux increases from 51% to 85% with increasing energy in 0.1 $-$ 2.0 keV, whereas it decreases from 96% to 22% in 0.8 $-$ 10 keV. We discuss the implications of our findings for the origin of the pulse profile and its energy dependence.",
          "error": null
        }
      }
    },
    {
      "id": 29,
      "title": "Gibbs fragmentation trees",
      "original_text": "We study fragmentation trees of Gibbs type. In the binary case, we identify the most general Gibbs-type fragmentation tree with Aldous' beta-splitting model, which has an extended parameter range $\\beta>-2$ with respect to the ${\\rm beta}(\\beta+1,\\beta+1)$ probability distributions on which it is based. In the multifurcating case, we show that Gibbs fragmentation trees are associated with the two-parameter Poisson--Dirichlet models for exchangeable random partitions of $\\mathbb {N}$, with an extended parameter range $0\\le\\alpha\\le1$, $\\theta\\ge-2\\alpha$ and $\\alpha<0$, $\\theta =-m\\alpha$, $m\\in \\mathbb {N}$.",
      "generations": {
        "easy_general": {
          "text": "We are looking at fragmentation trees that follow a pattern called Gibbs type. These are trees that split in a specific way. In the binary case, where each branch has two parts, we connect the most general Gibbs-type fragmentation tree to a model called Aldous' beta-splitting model. This model has a range of values for $\\beta$ that is greater than -2, which is related to the ${\\rm beta}(\\beta+1,\\beta+1)$ probability distributions. \n\nIn the multifurcating case, where branches split into multiple parts, we show that Gibbs fragmentation trees are connected to another model called the two-parameter Poisson--Dirichlet model. This model has a range of values for $\\alpha$ and $\\theta$ that follow certain rules.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this study, we explore a type of fragmentation tree called a Gibbs-type fragmentation tree. In the binary case, we find that the most general form of this tree is related to the Aldous' beta-splitting model. This model has a wider range of parameters compared to the probability distributions it relies on. In the multifurcating case, we show that Gibbs fragmentation trees are connected to the two-parameter Poisson-Dirichlet models, which have a broader range of parameters. These models help us understand how fragmentation trees grow and change in different situations.",
          "error": null
        },
        "adult_technical": {
          "text": "We study fragmentation trees of Gibbs type. In the binary case, we identify the most general Gibbs-type fragmentation tree with Aldous' beta-splitting model, which has an extended parameter range $\\beta>-2$ with respect to the ${\\rm beta}(\\beta+1,\\beta+1)$ probability distributions on which it is based. In the multifurcating case, we show that Gibbs fragmentation trees are associated with the two-parameter Poisson--Dirichlet models for exchangeable random partitions of $\\mathbb {N}$, with an extended parameter range $0\\le\\alpha\\le1$, $\\theta\\ge-2\\alpha$ and $\\alpha<0$, $\\theta =-m\\alpha$, $m\\in \\mathbb {N}$.",
          "error": null
        }
      }
    },
    {
      "id": 30,
      "title": "Sums and products in finite fields: an integral geometric viewpoint",
      "original_text": "We prove that if $A \\subset {\\Bbb F}_q$ is such that $$|A|>q^{{1/2}+\\frac{1}{2d}},$$ then $${\\Bbb F}_q^{*} \\subset dA^2=A^2+...+A^2 d \\text{times},$$ where $$A^2=\\{a \\cdot a': a,a' \\in A\\},$$ and where ${\\Bbb F}_q^{*}$ denotes the multiplicative group of the finite field ${\\Bbb F}_q$. In particular, we cover ${\\Bbb F}_q^{*}$ by $A^2+A^2$ if $|A|>q^{{3/4}}$. Furthermore, we prove that if $$|A| \\ge C_{size}^{\\frac{1}{d}}q^{{1/2}+\\frac{1}{2(2d-1)}},$$ then $$|dA^2| \\ge q \\cdot \\frac{C^2_{size}}{C^2_{size}+1}.$$ Thus $dA^2$ contains a positive proportion of the elements of ${\\Bbb F}_q$ under a considerably weaker size assumption.We use the geometry of ${\\Bbb F}_q^d$, averages over hyper-planes and orthogonality properties of character sums. In particular, we see that using operators that are smoothing on $L^2$ in the Euclidean setting leads to non-trivial arithmetic consequences in the context of finite fields.",
      "generations": {
        "easy_general": {
          "text": "",
          "error": null
        },
        "adult_non_technical": {
          "text": "We present a proof that if a group of numbers, called \"A,\" is large enough, we can create a special set of numbers, called \"dA^2,\" that includes all the numbers in a larger group, called \"F_q^*.\" This larger group is made up of all the numbers in a finite set, called \"F_q,\" that can be multiplied together. We show that if \"A\" is large enough, we can cover all the numbers in this larger group.\n\nIn particular, we show that if \"A\" is large enough, we can create a special set of numbers, called \"A^2 + A^2,\" that includes all the numbers in the larger group. This special set is created by multiplying pairs of numbers from \"A\" together.\n\nWe also show that if \"A\" is large enough, we can create a special set of numbers, called \"dA^2,\" that includes a large proportion of the numbers in the larger group. This special set is created by multiplying pairs of numbers from \"A\" together.\n\nWe use the geometry of",
          "error": null
        },
        "adult_technical": {
          "text": "We demonstrate that for a subset $A$ of the finite field ${\\Bbb F}_q$, if $|A|$ is greater than $q^{{1/2}+\\frac{1}{2d}}$, then the multiplicative group of ${\\Bbb F}_q$, denoted as ${\\Bbb F}_q^*$, is contained within $dA^2$, where $dA^2$ is the sum of $d$ copies of $A^2$. Here, $A^2$ is defined as the set of all products $a \\cdot a'$ where $a$ and $a'$ are elements of $A$. Specifically, if $|A|$ is greater than $q^{{3/4}}$, we can cover ${\\Bbb F}_q^*$ with $A^2 + A^2$.\n\nAdditionally, we show that if $|A|$ is at least $C_{size}^{\\frac{1}{d}}q^{{1/2}+\\frac{1}{2(2d-1)}}$, then the size of $dA^2$ is at least $q \\cdot \\frac{C^2_{size}}{C^2_{size}+1}$. This implies that $dA^2$ contains a positive proportion of the elements of ${\\Bbb F}_q$ under a weaker size assumption.\n\nOur approach relies on the geometry of ${\\Bbb F}_q^d$, averages over hyper-planes, and orthogonality properties of character sums. Notably, we observe that operators with smoothing properties on $L^2$ in the Euclidean setting have non-trivial arithmetic consequences in the context of finite fields.",
          "error": null
        }
      }
    },
    {
      "id": 31,
      "title": "Birationality of \\'etale morphisms via surgery",
      "original_text": "We use a counting argument and surgery theory to show that if $D$ is a sufficiently general algebraic hypersurface in $\\Bbb C^n$, then any local diffeomorphism $F:X \\to \\Bbb C^n$ of simply connected manifolds which is a $d$-sheeted cover away from $D$ has degree $d=1$ or $d=\\infty$ (however all degrees $d > 1$ are possible if $F$ fails to be a local diffeomorphism at even a single point). In particular, any \\'etale morphism $F:X \\to \\Bbb C^n$ of algebraic varieties which covers away from such a hypersurface $D$ must be birational.",
      "generations": {
        "easy_general": {
          "text": "We use a counting argument and surgery theory to show that if $D$ is a sufficiently general algebraic hypersurface in $\\Bbb C^n$, then any local diffeomorphism $F:X \\to \\Bbb C^n$ of simply connected manifolds which is a $d$-sheeted cover away from $D$ has degree $d=1$ or $d=\\infty$ (however all degrees $d > 1$ are possible if $F$ fails to be a local diffeomorphism at even a single point). In particular, any \\'etale morphism $F:X \\to \\Bbb C^n$ of algebraic varieties which covers away from such a hypersurface $D$ must be birational.\n\nRewritten text:\nWe use a counting argument and surgery theory to show that if $D$ is a sufficiently general algebraic hypersurface in $\\Bbb C^n$, then any local diffeomorphism $F:X \\to \\Bbb C^n$ of simply connected manifolds which is a $d$-sheeted cover away from $D$ has degree $d=1$ or $d=\\infty$ (however all degrees $d > 1$ are possible if $F$ fails to be a local diffeomorphism at even a single point). In particular, any \\'etale morphism $F:X \\to \\Bbb C^n$ of algebraic varieties which covers away from such a hypersurface $D$ must be birational.\n\nRewritten text:\nWe use a counting argument and surgery theory to show that if $D$ is a sufficiently general algebraic hypersurface in $\\Bbb C^n$, then any local diffeomorphism $F:X \\to \\Bbb C^n$ of simply connected manifolds which is a $d$-sheeted cover away from $D$ has degree $d=1$ or $d=\\infty$ (however all degrees $d > 1$ are possible if $F$ fails to be a local diffeomorphism at even a single point). In particular, any \\'etale morphism $F:X \\to \\Bbb C^n$ of algebraic varieties which covers away from such a hypersurface $D$ must be birational.\n\nRewritten text:\nWe use a counting argument and surgery theory to show that if $D$ is a sufficiently general algebraic hypersurface in $\\Bbb C^n$, then any local diffeomorphism",
          "error": null
        },
        "adult_non_technical": {
          "text": "We use a counting argument and surgery theory to show that if $D$ is a sufficiently general algebraic hypersurface in $\\Bbb C^n$, then any local diffeomorphism $F:X \\to \\Bbb C^n$ of simply connected manifolds which is a $d$-sheeted cover away from $D$ has degree $d=1$ or $d=\\infty$ (however all degrees $d > 1$ are possible if $F$ fails to be a local diffeomorphism at even a single point). In particular, any \\'etale morphism $F:X \\to \\Bbb C^n$ of algebraic varieties which covers away from such a hypersurface $D$ must be birational.",
          "error": null
        },
        "adult_technical": {
          "text": "We employ a counting argument and surgery theory to demonstrate that if $D$ is a sufficiently general algebraic hypersurface in $\\Bbb C^n$, then any local diffeomorphism $F:X \\to \\Bbb C^n$ of simply connected manifolds that is a $d$-sheeted cover away from $D$ must have degree $d=1$ or $d=\\infty$. However, all degrees $d > 1$ are possible if $F$ fails to be a local diffeomorphism at even a single point. In particular, any tale morphism $F:X \\to \\Bbb C^n$ of algebraic varieties that covers away from such a hypersurface $D$ must be birational.",
          "error": null
        }
      }
    },
    {
      "id": 32,
      "title": "Is there contextuality for a single qubit?",
      "original_text": "It was presented by Cabello and Nakamura [A. Cabello, Phys. Rev. Lett. 90, 190401 (2003)], that the Kochen-Specker theorem applies to two dimensions if one uses Positive Operator-Valued Measures. We show that contextuality in their models is not of the Kochen-Specker type. It is rather the result of not keeping track of the whole system on which the measurement is performed. This is connected to the fact that there is no one-to-one correspondence between POVM elements and projectors on the extended Hilbert space and the same POVM element has to originate from two different projectors when used in Cabello's and Nakamura's models. Moreover, we propose a hidden-variable formulation of the above models.",
      "generations": {
        "easy_general": {
          "text": "A group of scientists named Cabello and Nakamura found a rule called the Kochen-Specker theorem that works in two dimensions when they use a tool called Positive Operator-Valued Measures. However, we found that this rule doesn't always work because they didn't consider the effects of the whole system. We also suggested a new way to look at their models.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Two scientists named Cabello and Nakamura found a way to use Kochen-Specker theorem in two dimensions by using something called Positive Operator-Valued Measures. However, we found that their models have a different kind of contextuality, which is caused by not considering the whole system when making measurements. We also proposed a new way to understand their models.",
          "error": null
        },
        "adult_technical": {
          "text": "Cabello and Nakamura demonstrated that the Kochen-Specker theorem can be extended to two dimensions using Positive Operator-Valued Measures (POVMs). However, we argue that the contextuality in their models is not of the Kochen-Specker type. Instead, it arises from the failure to account for the entire system on which the measurement is performed. This is due to the lack of a one-to-one correspondence between POVM elements and projectors on the extended Hilbert space. Consequently, the same POVM element must be derived from two different projectors when used in Cabello's and Nakamura's models. Additionally, we propose a hidden-variable formulation of these models.",
          "error": null
        }
      }
    },
    {
      "id": 33,
      "title": "A new young stellar cluster embedded in a molecular cloud in the far outer Galaxy",
      "original_text": "We report the discovery of a new young stellar cluster and molecular cloud located in the far outer Galaxy, seen towards IRAS 06361-0142, and we characterise their properties. Near-infrared images were obtained with VLT/ISAAC through JHKs filters, millimetre line observations of CO(1-0) were obtained with SEST, and VLA 6 cm continuum maps obtained from archive data. The cloud and cluster are located at a distance of 7 kpc and a Galactocentric distance of 15 kpc, well in the far outer Galaxy. Morphologically, IRAS 06361-0142 appears as a cluster of several tens of stars surrounded by a nearly spherical nebular cavity centred at the position of the IRAS source. The cluster appears composed of low and intermediate-mass, young reddened stars with a large fraction having cleared the inner regions of their circumstellar discs responsible for (H - Ks) colour excess. The observations are compatible with a 4 Myr cluster with variable spatial extinction between Av = 6 and Av = 13.",
      "generations": {
        "easy_general": {
          "text": "Scientists have found a new group of young stars and a gas cloud in a distant part of our galaxy. They used special telescopes to see the stars and gas, and they are still learning more about them.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Astronomers have found a new group of young stars and a cloud of gas in a far-off part of our galaxy. They made this discovery near IRAS 06361-0142, which is a type of object that emits infrared light. The group of stars is surrounded by a spherical cloud of gas.",
          "error": null
        },
        "adult_technical": {
          "text": "We have discovered a new, young stellar cluster and molecular cloud located in the outer regions of our galaxy, visible in the direction of the IRAS 06361-0142 source. To study their properties, we used near-infrared images from the VLT/ISAAC telescope, millimeter line observations of CO(1-0) from the SEST telescope, and VLA 6 cm continuum maps from the archive data. The cluster and cloud are situated at a distance of 7 kpc and a Galactocentric distance of 15 kpc, placing them in the outer regions of the galaxy. The cluster appears to be composed primarily of low and intermediate-mass, reddened stars, with a significant fraction having cleared the color excess from their circumstellar discs. The observations are consistent with a 4 Myr cluster with variable spatial extinction between Av = 6 and Av = 13.",
          "error": null
        }
      }
    },
    {
      "id": 34,
      "title": "Impurity scattering in strongly correlated metals close to the Mott transition",
      "original_text": "This work explores a simple approximation to describe isolated impurity scattering in a strongly correlated metal. The approximation combines conventional one electron scattering theory and the Dynamic Mean Field Theory to describe strong correlations in the host. It becomes exact in several limits, including those of very weak and very strong impurity potentials. Original electronic structure appears at the impurity site when the impurity potential strength is moderate and the host is close to the Mott transition. Our results may provide useful guidance for interpretation of scanning tunneling microscopy experiments in strongly correlated systems.",
      "generations": {
        "easy_general": {
          "text": "\"This study looks at a simple way to understand how impurities behave in a metal that has strong connections between electrons. We use a mix of two theories: one that looks at how one electron scatters, and another that shows how electrons are strongly connected in the metal. This method works very well when the impurities are very weak or very strong. When the impurities are medium strength and the metal is close to a special point called the Mott transition, the original structure of the electrons in the metal shows up where the impurities are. Our findings can help scientists understand important experiments on these special metals.\"",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this study, we look at a simple way to understand how impurities in a metal affect the movement of electrons. We use a mix of two theories: one that explains how electrons bounce off each other and another that explains how electrons interact in the metal. This method works really well when the impurities are very weak or very strong. When the impurities are moderate, we can see the original structure of the metal where the impurities are. Our findings could help scientists understand important experiments on these metals.",
          "error": null
        },
        "adult_technical": {
          "text": "This study investigates a straightforward approximation to describe isolated impurity scattering in a strongly correlated metal. The approximation integrates conventional one-electron scattering theory and the Dynamic Mean Field Theory to capture strong correlations in the host material. It yields exact results in certain scenarios, such as very weak and very strong impurity potentials. The original electronic structure emerges at the impurity site when the impurity potential strength is moderate and the host is close to the Mott transition. Our findings may offer valuable insights for interpreting scanning tunneling microscopy experiments in strongly correlated systems.",
          "error": null
        }
      }
    },
    {
      "id": 35,
      "title": "An Entropy-Weighted Sum over Non-Perturbative Vacua",
      "original_text": "We discuss how, in a Universe restricted to the causal region connected to the observer, General Relativity implies the quantum nature of physical phenomena and directly leads to a string theory scenario, whose dynamics is ruled by a functional that weights all configurations according to their entropy. The most favoured configurations are those of minimal entropy. Along this class of vacua a four-dimensional space-time is automatically selected; when, at large volume, a description of space-time in terms of classical geometry can be recovered, the entropy-weighted sum reduces to the ordinary Feynman's path integral. What arises is a highly predictive scenario, phenomenologically compatible with the experimental observations and measurements, in which everything is determined in terms of the fundamental constants and the age of the Universe, with no room for freely-adjustable parameters. We discuss how this leads to the known spectrum of particles and interactions. Besides the computation of masses and couplings, CKM matrix elements, cosmological constant, expansion parameters of the Universe etc..., all resulting, within the degree of the approximation we used, in agreement with the experimental observations, we also discuss how this scenario passes the tests provided by cosmology and the constraints imposed by the physics of the primordial Universe.",
      "generations": {
        "easy_general": {
          "text": "Imagine a universe where we can only see the parts that are directly connected to us. In this universe, General Relativity says that everything is connected and quantum. This leads to a theory called string theory, which explains the behavior of particles and forces. The theory",
          "error": null
        },
        "adult_non_technical": {
          "text": "",
          "error": null
        },
        "adult_technical": {
          "text": "We explore the implications of General Relativity on the quantum nature of physical phenomena within the causal region connected to the observer. This leads to a string theory scenario, where the dynamics is governed by a functional that weights configurations based on their entropy. The most favored configurations are those with minimal entropy. Within this class of vacua, a four-dimensional space-time is automatically selected. At large volumes, the entropy-weighted sum reduces to the ordinary Feynman's path integral, resulting in a highly predictive scenario compatible with experimental observations and measurements. Everything is determined by the fundamental constants and the age of the Universe, with no room for freely-adjustable parameters. We discuss how this leads to the known spectrum of particles and interactions, including the computation of masses and couplings, CKM matrix elements, cosmological constant, and expansion parameters of the Universe. Additionally, this scenario passes the tests provided by cosmology and the physics of the primordial Universe.",
          "error": null
        }
      }
    },
    {
      "id": 36,
      "title": "Spontaneous Lorentz Violation: Non-Abelian Gauge Fields as Pseudo-Goldstone Vector Bosons",
      "original_text": "We argue that non-Abelian gauge fields can be treated as the pseudo-Goldstone vector bosons caused by spontaneous Lorentz invariance violation (SLIV). To this end, the SLIV which evolves in a general Yang-Mills type theory with the nonlinear vector field constraint $Tr(% \\boldsymbol{A}_{\\mu }\\boldsymbol{A}^{\\mu})=\\pm M^{2}$ ($M$ is a proposed SLIV scale) imposed is considered in detail. With an internal symmetry group $G$ having $D$ generators not only the pure Lorentz symmetry SO(1,3), but the larger accidental symmetry $SO(D,3D)$ of the SLIV constraint in itself appears to be spontaneously broken as well. As a result, while the pure Lorentz violation still generates only one genuine Goldstone vector boson, the accompanying pseudo-Goldstone vector bosons related to the $SO(D,3D)$ breaking also come into play in the final arrangement of the entire Goldstone vector field multiplet. Remarkably, they remain strictly massless, being protected by gauge invariance of the Yang-Mills theory involved. We show that, although this theory contains a plethora of Lorentz and $CPT$ violating couplings, they do not lead to physical SLIV effects which turn out to be strictly cancelled in all the lowest order processes considered. However, the physical Lorentz violation could appear if the internal gauge invariance were slightly broken at very small distances influenced by gravity. For the SLIV scale comparable with the Planck one the Lorentz violation could become directly observable at low energies.",
      "generations": {
        "easy_general": {
          "text": "We think that certain types of force fields can be seen as a result of a change in the way space and time work. This change is called spontaneous Lorentz invariance violation (SLIV).",
          "error": null
        },
        "adult_non_technical": {
          "text": "\"We argue that certain gauge fields can be seen as a result of a process called spontaneous Lorentz invariance violation (SLIV). To understand this, we look at a specific type of theory called Yang-Mills theory, which has a rule that limits the behavior of vector fields. This rule breaks a symmetry called the Lorentz symmetry, which is related to how space and time are connected. As a result, we get new particles called Goldstone vector bosons.",
          "error": null
        },
        "adult_technical": {
          "text": "We propose that non-Abelian gauge fields can be viewed as pseudo-Goldstone vector bosons resulting from spontaneous Lorentz invariance violation (SLIV). To explore this, we examine the SLIV in a general Yang-Mills theory with a nonlinear vector field constraint, $Tr(\\boldsymbol{A}_{\\mu}\\boldsymbol{A}^{\\mu})=\\pm M^{2}$, where $M$ is the proposed SLIV scale. For an internal symmetry group $G$ with $D$ generators, not only the pure Lorentz symmetry $SO(1,3)$ but also the larger accidental symmetry $SO(D,3D)$ of the SLIV constraint is spontaneously broken. Consequently, the pure Lorentz violation still produces one genuine Goldstone vector boson, while pseudo-Goldstone vector bosons related to the $SO(D,3D)$ breaking also contribute to the overall Goldstone vector field multiplet. Notably, these pseudo-Goldstone vector bosons remain massless due to the gauge invariance of the Yang-Mills theory. We demonstrate that, despite the presence of Lorentz and $CPT$ violating couplings, they do not result in physical SLIV effects, which are strictly canceled in all lowest-order processes. However, physical Lorentz violation could emerge if the internal gauge invariance is slightly broken at very small distances, influenced by gravity. For an SLIV scale comparable to the Planck scale, Lorentz violation could become observable at low energies.",
          "error": null
        }
      }
    },
    {
      "id": 37,
      "title": "Ages for illustrative field stars using gyrochronology: viability, limitations and errors",
      "original_text": "We here develop an improved way of using a rotating star as a clock, set it using the Sun, and demonstrate that it keeps time well. This technique, called gyrochronology, permits the derivation of ages for solar- and late-type main sequence stars using only their rotation periods and colors. The technique is clarified and developed here, and used to derive ages for illustrative groups of nearby, late-type field stars with measured rotation periods. We first demonstrate the reality of the interface sequence, the unifying feature of the rotational observations of cluster and field stars that makes the technique possible, and extends it beyond the proposal of Skumanich by specifying the mass dependence of rotation for these stars. We delineate which stars it cannot currently be used on. We then calibrate the age dependence using the Sun. The errors are propagated to understand their dependence on color and period. Representative age errors associated with the technique are estimated at ~15% (plus possible systematic errors) for late-F, G, K, & early-M stars. Ages derived via gyrochronology for the Mt. Wilson stars are shown to be in good agreement with chromospheric ages for all but the bluest stars, and probably superior. Gyro ages are then calculated for each of the active main sequence field stars studied by Strassmeier and collaborators where other ages are not available. These are shown to be mostly younger than 1Gyr, with a median age of 365Myr. The sample of single, late-type main sequence field stars assembled by Pizzolato and collaborators is then assessed, and shown to have gyro ages ranging from under 100Myr to several Gyr, and a median age of 1.2Gyr. Finally, we demonstrate that the individual components of the three wide binaries XiBooAB, 61CygAB, & AlphaCenAB yield substantially the same gyro ages.",
      "generations": {
        "easy_general": {
          "text": "We have found a new way to measure the age of stars by using their rotation like a clock. This method, called gyrochronology, is set using the Sun and works very well. It can measure the age of stars based on their rotation and color. We used this method to find the ages of some nearby stars and showed that it is accurate. We also found that this method does not work for certain types of stars.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Scientists have developed a new way to measure the age of stars, called gyrochronology. This method uses the rotation of a star as a clock. They set it using the Sun and showed that it keeps time well. With this technique, they can figure out how old stars are by just looking at how fast they spin and their color.\n\nThe scientists used this method to find the ages of some nearby stars. They found that the ages they got using gyrochronology were very close to the ages they found using other methods. They also showed that this method works well for different types of stars.",
          "error": null
        },
        "adult_technical": {
          "text": "We introduce an enhanced method for using a rotating star as a clock, calibrating it using the Sun, and demonstrating its accuracy. This technique, known as gyrochronology, enables the calculation of ages for solar- and late-type main sequence stars based solely on their rotation periods and colors. The technique is refined and expanded here, and applied to determine the ages of representative groups of nearby, late-type field stars with known rotation periods.\n\nFirst, we confirm the existence of the interface sequence, a consistent pattern in the rotational observations of cluster and field stars that underpins gyrochronology. We extend Skumanich's proposal by specifying the mass dependence of rotation for these stars and identify the stars that cannot be used with this technique.\n\nNext, we calibrate the age dependence using the Sun and propagate the errors to understand their dependence on color and period. The estimated age errors associated with the technique are approximately 15% (including possible systematic errors) for late-F, G, K, and early-M stars.\n\nAges derived using gyrochronology for the Mt. Wilson stars are found to agree well with chromospheric ages for all but the bluest stars, and are likely superior. We then calculate gyro ages for the active main sequence field stars studied by Strassmeier and collaborators, where other ages are not available. These stars are shown to be mostly younger than 1 billion years, with a median age of 365 million years.\n\nFurthermore, we assess the sample of single, late-type main sequence field stars compiled by Pizzolato and collaborators, and find that their gyro ages range from under 100 million years to several billion years, with a median age of 1.2 billion years.\n\nFinally, we demonstrate that the individual components of the three wide binaries XiBooAB, 61CygAB, and AlphaCenAB have substantially the same gyro ages.",
          "error": null
        }
      }
    },
    {
      "id": 38,
      "title": "The Magnetic Field of the Solar Corona from Pulsar Observations",
      "original_text": "We present a novel experiment with the capacity to independently measure both the electron density and the magnetic field of the solar corona. We achieve this through measurement of the excess Faraday rotation due to propagation of the polarised emission from a number of pulsars through the magnetic field of the solar corona. This method yields independent measures of the integrated electron density, via dispersion of the pulsed signal and the magnetic field, via the amount of Faraday rotation. In principle this allows the determination of the integrated magnetic field through the solar corona along many lines of sight without any assumptions regarding the electron density distribution. We present a detection of an increase in the rotation measure of the pulsar J1801$-$2304 of approximately 160 \\rad at an elongation of 0.95$^\\circ$ from the centre of the solar disk. This corresponds to a lower limit of the magnetic field strength along this line of sight of $> 393\\mu\\mathrm{G}$. The lack of precision in the integrated electron density measurement restricts this result to a limit, but application of coronal plasma models can further constrain this to approximately 20mG, along a path passing 2.5 solar radii from the solar limb. Which is consistent with predictions obtained using extensions to the Source Surface models published by Wilcox Solar Observatory",
      "generations": {
        "easy_general": {
          "text": "We have created a new experiment that can measure the electron density and magnetic field of the Sun's corona. We do this by looking at how light from pulsars, which are spinning stars, changes as it passes through the Sun's magnetic field. This method allows us to measure the electron density and magnetic field separately, which can help us understand the Sun's corona better.\n\nWe found that the light from a pulsar called J1801-2304 changed as it passed through the Sun's corona. This tells us that the magnetic field in that area is quite strong. Our results help us understand the Sun's corona and are consistent with other studies.",
          "error": null
        },
        "adult_non_technical": {
          "text": "We've developed a new experiment that can measure the electron density and magnetic field of the sun's corona. To do this, we observe the way light from pulsars, which are rapidly spinning stars, changes as it travels through the sun's magnetic field. This method allows us to independently measure both the electron density, by looking at the light's dispersion, and the magnetic field, by measuring the amount of Faraday rotation, which is the bending of light as it passes through magnetic fields.\n\nIn theory, this technique can help us understand the integrated magnetic field through the sun's corona along many lines of sight without making any assumptions about the electron density distribution. We detected an increase in the rotation measure of the pulsar J1801-2304 of about 160 radians at a distance of 0.95 degrees from the center of the sun's disk. This means the magnetic field strength along this line of sight is at least 393 microgauss. However, the lack of precision in the integrated electron density measurement limits this result, but using coronal plasma models, we can further constrain this to approximately 20 milligauss along a path passing 2.5 solar radii from the solar limb.",
          "error": null
        },
        "adult_technical": {
          "text": "We introduce a groundbreaking experiment capable of independently measuring both the electron density and the magnetic field of the solar corona. This is achieved by quantifying the excess Faraday rotation caused by the propagation of polarized emission from multiple pulsars through the solar corona's magnetic field. This method provides independent measurements of the integrated electron density, via the dispersion of the pulsed signal, and the magnetic field, via the degree of Faraday rotation. In theory, this allows for the determination of the integrated magnetic field through the solar corona along various lines of sight without making any assumptions about the electron density distribution. We report a detection of an increase in the rotation measure of the pulsar J1801-2304 of approximately 160 radians at an elongation of 0.95 degrees from the center of the solar disk. This corresponds to a lower limit of the magnetic field strength along this line of sight of greater than 393 microgauss. The lack of precision in the integrated electron density measurement restricts this result to a limit, but applying coronal plasma models can further constrain this to approximately 20 milligauss, along a path passing 2.5 solar radii from the solar limb. This finding is consistent with predictions obtained using extensions to the Source Surface models published by Wilcox Solar Observatory.",
          "error": null
        }
      }
    },
    {
      "id": 39,
      "title": "Uniform Mixing of Antiferromagnetism and High-Tc Superconductivity in Electron-doped Layers in Four-layered Ba2Ca3Cu4O8F2 : A New Phenomenon in an Electron Underdoped RegimePhenomenon in an Electron Underdoped Regime",
      "original_text": "We report Cu- and F-NMR studies on a four-layered high-temperature superconductor Ba2Ca3Cu4O8F2(0234F(2.0)) with apical fluorine (F-1), an undoped 55 K-superconductor with a nominal Cu2+ valence on average. We reveal that this compound exhibits the antiferromagnetism (AFM) with a Neel temperature TN=100 K despite being a Tc= 55 K-superconductor. Through a comparison with a related tri-layered cuprate Ba2Ca2Cu3O6F2 (0223F(2.0)), it is demonstrated that electrons are transferred from the inner plane (IP) to the outer plane (OP) in 0234F(2.0) and 0223F(2.0), confirming the self-doped high-temperature superconductivity (HTSC) having electron and hole doping in a single compound. Remarlably, uniform mixing of AFM and HTSC takes place in both the electron-doped OPs and the hole-doped IPs in 0234F(2.0).",
      "generations": {
        "easy_general": {
          "text": "We studied a special material called a high-temperature superconductor, which can conduct electricity with no resistance at very low temperatures. This material has four layers and a special type of fluorine called F-1. We found that this material has a unique property called antiferromagnetism (AFM), which means it can conduct electricity with no resistance at higher temperatures. We also discovered that electrons move from the inner layers to the outer layers, making the material even more efficient at conducting electricity. This material is special because it can conduct electricity at both high and low temperatures.",
          "error": null
        },
        "adult_non_technical": {
          "text": "We've studied a special material that can conduct electricity with no resistance at high temperatures. This material is made of layers of copper, barium, calcium, oxygen, and fluorine. We found that this material has a unique property called \"antiferromagnetism,\" which means it can conduct electricity at high temperatures. This discovery could lead to new technologies in the future.",
          "error": null
        },
        "adult_technical": {
          "text": "We present Cu- and F-NMR studies on a four-layered high-temperature superconductor, Ba2Ca3Cu4O8F2(0234F(2.0)), with apical fluorine (F-1), an undoped 55 K-superconductor with a nominal Cu2+ valence on average. This compound exhibits antiferromagnetism (AFM) with a Neel temperature of TN=100 K, despite being a Tc= 55 K-superconductor. By comparing it with a related tri-layered cuprate, Ba2Ca2Cu3O6F2 (0223F(2.0)), we demonstrate that electrons are transferred from the inner plane (IP) to the outer plane (OP) in both 0234F(2.0) and 0223F(2.0). This confirms the self-doped high-temperature superconductivity (HTSC) with electron and hole doping in a single compound. Notably, uniform mixing of AFM and HTSC occurs in both the electron-doped OPs and the hole-doped IPs in 0234F(2.0).",
          "error": null
        }
      }
    },
    {
      "id": 40,
      "title": "Modelling Quasicrystals",
      "original_text": "A new kind of aperiodic tiling is introduced. It is shown to underlie a structure obtained as a superposition of waves with incommensurate periods. Its connections to other other tilings and quasicrystals are discussed.",
      "generations": {
        "easy_general": {
          "text": "Imagine a new kind of pattern that doesn't repeat in a regular way, like a grid or a mosaic. This new pattern is called an aperiodic tiling. It's connected to a structure made by combining different waves that don't have the same rhythm. This new pattern is related to other patterns and special materials called quasicrystals.",
          "error": null
        },
        "adult_non_technical": {
          "text": "\"Scientists discovered a new type of pattern that doesn't repeat itself. This pattern is made up of waves that don't match up with each other. They explained how this pattern is related to other patterns and something called quasicrystals.\"",
          "error": null
        },
        "adult_technical": {
          "text": "A novel aperiodic tiling has been introduced, which is demonstrated to underlie a structure composed of a superposition of waves with incommensurate periods. The relationships between this tiling and other tilings and quasicrystals are explored.",
          "error": null
        }
      }
    },
    {
      "id": 41,
      "title": "Rapidly rotating spherical Couette flow in a dipolar magnetic field: an experimental study of the mean axisymmetric flow",
      "original_text": "In order to explore the magnetostrophic regime expected for planetary cores, experiments have been conducted in a rotating sphere filled with liquid sodium, with an imposed dipolar magnetic field (the DTS setup). The field is produced by a permanent magnet enclosed in an inner sphere, which can rotate at a separate rate, producing a spherical Couette flow. The flow properties are investigated by measuring electric potentials on the outer sphere, the induced magnetic field in the laboratory frame, and velocity profiles inside the liquid sodium using ultrasonic Doppler velocimetry. The present article focuses on the time-averaged axisymmetric part of the flow. The Doppler profiles show that the angular velocity of the fluid is relatively uniform in most of the fluid shell, but rises near the inner sphere, revealing the presence of a magnetic wind, and gently drops towards the outer sphere. The transition from a magnetostrophic flow near the inner sphere to a geostrophic flow near the outer sphere is controlled by the local Elsasser number. For Rossby numbers up to order 1, the observed velocity profiles all show a similar shape. Numerical simulations in the linear regime are computed, and synthetic velocity profiles are compared with the measured ones. In the geostrophic region, a torque-balance model provides very good predictions. We find that the induced magnetic field varies in a consistent fashion, and displays a peculiar peak in the counter-rotating regime. This happens when the fluid rotation rate is almost equal and opposite to the outer sphere rotation rate. The fluid is then almost at rest in the laboratory frame, and the Proudman-Taylor constraint vanishes, enabling a strong meridional flow. We suggest that dynamo action might be favored in such a situation.",
      "generations": {
        "easy_general": {
          "text": "To understand how magnetic fields work in the cores of planets, scientists did an experiment with a rotating sphere filled with liquid sodium. They used a special setup called the DTS setup, which creates a magnetic field using a permanent magnet inside a smaller sphere. This setup creates a flow called a spherical Couette flow, which is like a stream of liquid moving inside the sphere.\n\nThe scientists measured the electric potential on the outer sphere, the magnetic field inside the sphere, and the speed of the liquid sodium using a technique called ultrasonic Doppler velocimetry. They found that the speed of the liquid is mostly the same throughout the sphere, but it gets faster near the inner sphere and slows down near the outer sphere. This shows that there is a magnetic wind, which is like a flow of magnetic energy.\n\nThe scientists also found that the flow changes from a magnetostrophic flow near the inner sphere to a geostrophic flow near the outer sphere. This change is controlled by something called the local Elsasser number. When the Rossby number is close to 1, the speed of the liquid looks the same everywhere.\n\nThe scientists then used computer simulations to model the flow and compared the results with what they measured. They found that in the geostrophic region, a model called the torque-balance model works very well. They also found that the magnetic field changes in a consistent way, and there is a special peak when the liquid is rotating in the opposite direction to the outer sphere. When this happens, the liquid is almost at rest, and a constraint called the Proudman-Taylor constraint goes away. This allows a strong flow of magnetic energy, which is called a dynamo action.",
          "error": null
        },
        "adult_non_technical": {
          "text": "To understand how magnetic fields work in planetary cores, scientists have conducted experiments using a rotating sphere filled with liquid sodium. This sphere has a permanent magnet inside that creates a magnetic field. The inner sphere can rotate at a different speed than the outer sphere, creating a flow called a spherical Couette flow. To study the flow, scientists measure electric potentials on the outer sphere, the magnetic field, and the velocity of the liquid sodium using ultrasonic Doppler velocimetry.\n\nThe experiments show that the angular velocity of the fluid is mostly the same throughout the fluid shell, but increases near the inner sphere and decreases towards the outer sphere. This change is due to a magnetic wind, which is a result of the magnetic field. The transition from a magnetostrophic flow near the inner sphere to a geostrophic flow near the outer sphere is controlled by the local Elsasser number. For Rossby numbers up to order 1, the velocity profiles are similar.\n\nScientists also ran numerical simulations in the linear regime and compared the results with the measured velocity profiles. In the geostrophic region, a torque-balance model provides good predictions. They found that the induced magnetic field changes in a consistent way and has a peak in the counter-rotating regime. This happens when the fluid rotation rate is almost equal and opposite to the outer sphere rotation rate. In this situation, the fluid is almost at rest in the laboratory frame, and the Proudman-Taylor constraint is removed, allowing for a strong meridional flow. This could suggest that dynamo action might be favored in such a situation.",
          "error": null
        },
        "adult_technical": {
          "text": "To investigate the magnetostrophic regime expected in planetary cores, experiments have been conducted in a rotating sphere filled with liquid sodium, with an imposed dipolar magnetic field (the DTS setup). The magnetic field is generated by a permanent magnet enclosed in an inner sphere, which can rotate at a separate rate, producing a spherical Couette flow. The flow properties are studied by measuring electric potentials on the outer sphere, the induced magnetic field in the laboratory frame, and velocity profiles inside the liquid sodium using ultrasonic Doppler velocimetry. The present article focuses on the time-averaged axisymmetric part of the flow. The Doppler profiles show that the angular velocity of the fluid is relatively uniform in most of the fluid shell, but rises near the inner sphere, revealing the presence of a magnetic wind, and gently drops towards the outer sphere. The transition from a magnetostrophic flow near the inner sphere to a geostrophic flow near the outer sphere is controlled by the local Elsasser number. For Rossby numbers up to order 1, the observed velocity profiles all show a similar shape. Numerical simulations in the linear regime are computed, and synthetic velocity profiles are compared with the measured ones. In the geostrophic region, a torque-balance model provides very good predictions. We find that the induced magnetic field varies in a consistent fashion, and displays a peculiar peak in the counter-rotating regime. This happens when the fluid rotation rate is almost equal and opposite to the outer sphere rotation rate. The fluid is then almost at rest in the laboratory frame, and the Proudman-Taylor constraint vanishes, enabling a strong meridional flow. We suggest that dynamo action might be favored in such a situation.",
          "error": null
        }
      }
    },
    {
      "id": 42,
      "title": "Polar actions on compact Euclidean hypersurfaces",
      "original_text": "Given an isometric immersion $f\\colon M^n\\to \\R^{n+1}$ of a compact Riemannian manifold of dimension $n\\geq 3$ into Euclidean space of dimension $n+1$, we prove that the identity component $Iso^0(M^n)$ of the isometry group $Iso(M^n)$ of $M^n$ admits an orthogonal representation $\\Phi\\colon Iso^0(M^n)\\to SO(n+1)$ such that $f\\circ g=\\Phi(g)\\circ f$ for every $g\\in Iso^0(M^n)$. If $G$ is a closed connected subgroup of $Iso(M^n)$ acting locally polarly on $M^n$, we prove that $\\Phi(G)$ acts polarly on $\\R^{n+1}$, and we obtain that $f(M^n)$ is given as $\\Phi(G)(L)$, where $L$ is a hypersurface of a section which is invariant under the Weyl group of the $\\Phi(G)$-action. We also find several sufficient conditions for such an $f$ to be a rotation hypersurface. Finally, we show that compact Euclidean rotation hypersurfaces of dimension $n\\geq 3$ are characterized by their underlying warped product structure.",
      "generations": {
        "easy_general": {
          "text": "Imagine you have a shape, like a sphere or a cube, and you want to put it into a bigger space without changing its shape. This is called an \"isometric immersion.\" Now, let's talk about how this works.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Imagine you have a shape called a \"manifold\" that's like a sphere but with more dimensions. This shape is placed in a higher-dimensional space, like a cube but with more dimensions. The text explains that there's a way to describe how this shape moves in the higher space using a special map called an \"isometric immersion.\" This map shows how the shape moves in the higher space based on its movement in the lower space. The text also shows that if the shape moves in a certain way, called \"polarly,\" in one space, it also moves in a similar way in the higher space. Finally, the text gives some conditions for the shape to move in a specific way in the higher space. It also shows that for certain types of shapes, the way they move can be described in a special way.",
          "error": null
        },
        "adult_technical": {
          "text": "Given an isometric immersion $f\\colon M^n\\to \\R^{n+1}$ of a compact Riemannian manifold of dimension $n\\geq 3$ into Euclidean space of dimension $n+1$, we prove that the identity component $Iso^0(M^n)$ of the isometry group $Iso(M^n)$ of $M^n$ admits an orthogonal representation $\\Phi\\colon Iso^0(M^n)\\to SO(n+1)$ such that $f\\circ g=\\Phi(g)\\circ f$ for every $g\\in Iso^0(M^n)$. If $G$ is a closed connected subgroup of $Iso(M^n)$ acting locally polarly on $M^n$, we prove that $\\Phi(G)$ acts polarly on $\\R^{n+1}$, and we obtain that $f(M^n)$ is given as $\\Phi(G)(L)$, where $L$ is a hypersurface of a section which is invariant under the Weyl group of the $\\Phi(G)$-action. We also find several sufficient conditions for such an $f$ to be a rotation hypersurface. Finally, we show that compact Euclidean rotation hypersurfaces of dimension $n\\geq 3$ are characterized by their underlying warped product structure.",
          "error": null
        }
      }
    },
    {
      "id": 43,
      "title": "Higher Order Statistsics of Stokes Parameters in a Random Birefringent Medium",
      "original_text": "We present a new model for the propagation of polarized light in a random birefringent medium. This model is based on a decomposition of the higher order statistics of the reduced Stokes parameters along the irreducible representations of the rotation group. We show how this model allows a detailed description of the propagation, giving analytical expressions for the probability densities of the Mueller matrix and the Stokes vector throughout the propagation. It also allows an exact description of the evolution of averaged quantities, such as the degree of polarization. We will also discuss how this model allows a generalization of the concepts of reduced Stokes parameters and degree of polarization to higher order statistics. We give some notes on how it can be extended to more general random media.",
      "generations": {
        "easy_general": {
          "text": "\"We have created a new model to explain how polarized light moves through a random birefringent medium. This model works by breaking down the complex behavior of the light into simpler parts. By doing this, we can describe exactly how the light moves, including the probability densities of the Mueller matrix and the Stokes vector. We can also see how the degree of polarization changes as the light moves. This model also helps us understand how to apply these concepts to more complex situations. We will discuss how this model can be used for other types of random media.\"",
          "error": null
        },
        "adult_non_technical": {
          "text": "We've developed a new way to understand how polarized light moves through a random birefringent medium, which is a material that affects light differently depending on the direction it's traveling. This model works by breaking down the complex behavior of the light into simpler parts based on the way it can rotate. By doing this, we can describe the movement of the light precisely, including what happens to the probability densities of the Mueller matrix and the Stokes vector as the light travels. We can also see how the degree of polarization changes over time. This model can help us understand more complex situations, like when the light moves through a material that's not perfectly uniform.",
          "error": null
        },
        "adult_technical": {
          "text": "We introduce a novel model for the propagation of polarized light in a random birefringent medium. This model is based on a decomposition of the higher-order statistics of the reduced Stokes parameters along the irreducible representations of the rotation group. We demonstrate how this model enables a detailed description of the propagation, providing analytical expressions for the probability densities of the Mueller matrix and the Stokes vector throughout the propagation. Additionally, it allows for an exact description of the evolution of averaged quantities, such as the degree of polarization. Furthermore, we discuss how this model generalizes the concepts of reduced Stokes parameters and degree of polarization to higher-order statistics. We also provide some notes on how this model can be extended to more general random media.",
          "error": null
        }
      }
    },
    {
      "id": 44,
      "title": "Imaging the Two Gaps of the High-TC Superconductor Pb-Bi2Sr2CuO6+x",
      "original_text": "The nature of the pseudogap state, observed above the superconducting transition temperature TC in many high temperature superconductors, is the center of much debate. Recently, this discussion has focused on the number of energy gaps in these materials. Some experiments indicate a single energy gap, implying that the pseudogap is a precursor state. Others indicate two, suggesting that it is a competing or coexisting phase. Here we report on temperature dependent scanning tunneling spectroscopy of Pb-Bi2Sr2CuO6+x. We have found a new, narrow, homogeneous gap that vanishes near TC, superimposed on the typically observed, inhomogeneous, broad gap, which is only weakly temperature dependent. These results not only support the two gap picture, but also explain previously troubling differences between scanning tunneling microscopy and other experimental measurements.",
      "generations": {
        "easy_general": {
          "text": "There's a debate among scientists about a special state called \"pseudogap\" in certain materials. Some think it's a single state, while others think it's two different states. We used a special tool called scanning tunneling spectroscopy to find a new, narrow gap that disappears at a certain temperature. This helps prove that there are two different states and explains some confusing results from other experiments.",
          "error": null
        },
        "adult_non_technical": {
          "text": "\"Scientists have been arguing about the nature of a state called the pseudogap, which occurs in certain materials when they reach a certain temperature. Some experiments suggest there is only one energy gap, while others suggest there are two.",
          "error": null
        },
        "adult_technical": {
          "text": "The nature of the pseudogap state, observed above the superconducting transition temperature TC in many high-temperature superconductors, is a topic of much debate. Recently, this discussion has centered on the number of energy gaps in these materials. Some experiments suggest a single energy gap, implying that the pseudogap is a precursor state, while others indicate two, suggesting that it is a competing or coexisting phase. Here we report on temperature-dependent scanning tunneling spectroscopy of Pb-Bi2Sr2CuO6+x. We have found a new, narrow, homogeneous gap that vanishes near TC, superimposed on the typically observed, inhomogeneous, broad gap, which is only weakly temperature dependent. These results not only support the two-gap picture but also explain previously troubling differences between scanning tunneling microscopy and other experimental measurements.",
          "error": null
        }
      }
    },
    {
      "id": 45,
      "title": "Algorithm for anisotropic diffusion in hydrogen-bonded networks",
      "original_text": "In this paper I describe a specialized algorithm for anisotropic diffusion determined by a field of transition rates. The algorithm can be used to describe some interesting forms of diffusion that occur in the study of proton motion in a network of hydrogen bonds. The algorithm produces data that require a nonstandard method of spectral analysis which is also developed here. Finally, I apply the algorithm to a simple specific example.",
      "generations": {
        "easy_general": {
          "text": "In this paper, I explain a special method for studying how things move in a certain way. This method can help us understand how protons move in a network of hydrogen bonds. The method also requires a new way to analyze the data it produces. Finally, I show how this method works using a simple example.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this paper, I explain a special method for understanding how things move in a certain way, called \"anisotropic diffusion.\" This method is useful for studying how protons move in a network of hydrogen bonds, which are like tiny bridges that hold molecules together. The method uses a set of numbers called transition rates, which tell us how quickly protons move from one place to another. By using this method, we can learn interesting things about how protons move in these networks. The method also helps us understand a special type of math called spectral analysis, which is used to find patterns in the data. Finally, I show how this method works with a simple example.",
          "error": null
        },
        "adult_technical": {
          "text": "\"In this paper, I present a specialized algorithm for anisotropic diffusion, which is determined by a field of transition rates. This algorithm can be used to describe certain interesting forms of diffusion that occur in the study of proton motion within a network of hydrogen bonds. The algorithm produces data that require a nonstandard method of spectral analysis, which is also developed in this paper. Finally, I apply the algorithm to a simple specific example.\"",
          "error": null
        }
      }
    },
    {
      "id": 46,
      "title": "A method of state-selective transfer of atoms between microtraps based on the Franck-Condon Principle",
      "original_text": "We present a method of transferring a cold atom between spatially separated microtraps by means of a Raman transition between the ground motional states of the two traps. The intermediate states for the Raman transition are the vibrational levels of a third microtrap, and we determine the experimental conditions for which the overlap of the wave functions leads to an efficient transfer. There is a close analogy with the Franck-Condon principle in the spectroscopy of molecules. Spin-dependent manipulation of neutral atoms in microtraps has important applications in quantum information processing. We also show that starting with several atoms, precisely one atom can be transferred to the final potential well hence giving deterministic preparation of single atoms.",
      "generations": {
        "easy_general": {
          "text": "Imagine you have two tiny containers called microtraps, each one holding a cold atom. We want to move the atom from one container to the other without touching it. To do this, we use a special process called a Raman transition, which is like a tiny bridge that helps the atom cross between the two containers. This bridge is made up of vibrational levels from a third container, and we need to find the right conditions to make the atom move efficiently.\n\nThis process is similar to how molecules change in a way called the Franck-Condon principle, which helps us understand how molecules absorb light. By moving atoms in this way, we can do important things in quantum computing, like making sure only one atom ends up in the final container.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Imagine you have a tiny, cold atom that you want to move from one tiny trap to another. To do this, scientists use a process called a Raman transition, which is like a special bridge that helps the atom cross between the two traps. This bridge is made up of vibrational levels from a third trap. The scientists figured out how to make this process work really well, and it's important for building quantum computers and other advanced technologies.",
          "error": null
        },
        "adult_technical": {
          "text": "We introduce a technique for moving a cold atom between two separate microtraps using a Raman transition between the ground motional states of the traps. The intermediate states for this transition are the vibrational levels of a third microtrap. We identify the experimental conditions under which the overlap of the wave functions results in an efficient transfer. This process is similar to the Franck-Condon principle in molecular spectroscopy. Spin-dependent manipulation of neutral atoms in microtraps has significant applications in quantum information processing. Additionally, we demonstrate that starting with multiple atoms, exactly one atom can be transferred to the final potential well, allowing for deterministic preparation of single atoms.",
          "error": null
        }
      }
    },
    {
      "id": 47,
      "title": "Amorphous-amorphous transition and the two-step replica symmetry breaking phase",
      "original_text": "The nature of polyamorphism and amorphous-to-amorphous transition is investigated by means of an exactly solvable model with quenched disorder, the spherical s+p multi-spin interaction model. The analysis is carried out in the framework of Replica Symmetry Breaking theory and leads to the identification of low temperature glass phases of different kinds. Besides the usual `one-step' solution, known to reproduce all basic properties of structural glasses, also a physically consistent `two-step' solution arises. More complicated phases are found as well, as temperature is further decreased, expressing a complex variety of metastable states structures for amorphous systems.",
      "generations": {
        "easy_general": {
          "text": "To study the different forms of glass and how it changes at different temperatures, scientists use a model called the spherical s+p multi-spin interaction model. This model helps them understand the behavior of glass at low temperatures. They found that there are different types of glass phases, including a one-step and a two-step solution. The one-step solution can explain the basic properties of glass, while the two-step solution is more complex. As the temperature gets colder, more complicated forms of glass appear.",
          "error": null
        },
        "adult_non_technical": {
          "text": "\"This study looks at how amorphous materials change shape when they get colder. They found that these materials can take on different forms, depending on the temperature. At lower temperatures, the materials can form different glass phases, which can have different properties and structures.\"",
          "error": null
        },
        "adult_technical": {
          "text": "The nature of polyamorphism and the amorphous-to-amorphous transition is investigated using an exactly solvable model with quenched disorder, the spherical s+p multi-spin interaction model. The analysis is conducted within the Replica Symmetry Breaking theory framework, leading to the identification of various low-temperature glass phases. In addition to the usual 'one-step' solution, which reproduces all basic properties of structural glasses, a physically consistent 'two-step' solution arises. As temperature is further decreased, more complex phases are found, expressing a complex variety of metastable states structures for amorphous systems.",
          "error": null
        }
      }
    },
    {
      "id": 48,
      "title": "Thom polynomials and Schur functions: the singularities I_{2,2}(-)",
      "original_text": "We give the Thom polynomials for the singularities $I_{2,2}$ associated with maps $({\\bf C}^{\\bullet},0) \\to ({\\bf C}^{\\bullet+k},0)$ with parameter $k\\ge 0$. Our computations combine the characterization of Thom polynomials via the ``method of restriction equations'' of Rimanyi et al. with the techniques of Schur functions.",
      "generations": {
        "easy_general": {
          "text": "\"We found some special numbers, called Thom polynomials, for a type of math problem called $I_{2,2}$. We used a method called the 'method of restriction equations' and another method called Schur functions to find these numbers.\"",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this study, we calculate the Thom polynomials for singularities $I_{2,2}$ related to maps from a complex space to a larger complex space. We use a combination of the method of restriction equations developed by Rimanyi et al. and Schur functions to perform these calculations.",
          "error": null
        },
        "adult_technical": {
          "text": "We present the Thom polynomials for the singularities $I_{2,2}$ associated with maps $({\\bf C}^{\\bullet},0) \\to ({\\bf C}^{\\bullet+k},0)$ with parameter $k\\ge 0$. Our calculations integrate the characterization of Thom polynomials using the \"method of restriction equations\" developed by Rimanyi et al. with the techniques of Schur functions.",
          "error": null
        }
      }
    },
    {
      "id": 49,
      "title": "A study of uranium-based multilayers: II. Magnetic properties",
      "original_text": "SQUID magnetometry and polarised neutron reflectivity measurements have been employed to characterise the magnetic properties of U/Fe, U/Co and U/Gd multilayers. The field dependence of the magnetisation was measured at 10K in magnetic fields from -70kOe to 70kOe. A temperature dependent study of the magnetisation evolution was undertaken for a selection of U/Gd samples. PNR was carried out in a field of 4.4kOe for U/Fe and U/Co samples (at room temperature) and for U/Gd samples (at 10K). Magnetic 'dead' layers of about 15 Angstrom were observed for U/Fe and U/Co samples, consistent with a picture of interdiffused interfaces. A large reduction in the magnetic moment, constant over a wide range of Gd layer thicknesses, was found for the U/Gd system (about 4 Bohr magnetons compared with 7.63 for the bulk metal). This could be understood on the basis of a pinning of Gd moments arising from a column-like growth mechanism of the Gd layers. A study of the effective anisotropy suggests that perpendicular magnetic anisotropy could occur in multilayers consisting of thick U and thin Gd layers. A reduction in the Curie temperature was observed as a function of Gd layer thickness, consistent with a finite-size scaling behaviour.",
      "generations": {
        "easy_general": {
          "text": "Scientists used two special tools to study the magnetic properties of some layered materials called U/Fe, U/Co, and U/Gd. These tools are called SQUID magnetometry and polarized neutron reflectivity (PNR). SQUID magnetometry measures how magnetic these materials become when they are in different magnetic fields. PNR helps scientists understand the magnetic properties of these materials when they are in a magnetic field.\n\nAt a very low temperature (10K), scientists used SQUID magnetometry to measure how magnetic these materials became when they were in a magnetic field from -70kOe to 70kOe. They also studied how the magnetic properties of the U/Gd samples changed when the temperature was changed.\n\nAt room temperature, scientists used PNR to study the U/Fe and U/Co samples. They found that these samples had magnetic \"dead\" layers of about 15 Angstrom. This means that some parts of the material were not as magnetic as other parts.\n\nFor the U/Gd samples, scientists used PNR at a very low temperature (10K). They found that the magnetic moment of the Gd layer was much smaller than it would be in the bulk metal. This is because the Gd moments were \"pinned\" or stuck in place due to the way the Gd layers grew.\n\nScientists also found that the magnetic properties of the U/Gd system did not change when the thickness of the Gd layer was changed. This means that the magnetic properties of the Gd layer were not affected by how thick it was.\n\nFinally, scientists found that the Curie temperature, which is the temperature at which a material becomes magnetic, decreased when the Gd layer was thicker. This is consistent with a theory called finite-size scaling, which explains how magnetic properties change when the size of the material changes.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Scientists used special tools to study the magnetic properties of layers made of uranium, iron, cobalt, and gadolinium. They found that the magnetic properties of these layers depend on the thickness of the layers. This discovery could lead to new types of magnetic materials.",
          "error": null
        },
        "adult_technical": {
          "text": "SQUID magnetometry and polarized neutron reflectivity (PNR) measurements have been used to characterize the magnetic properties of U/Fe, U/Co, and U/Gd multilayers. The field dependence of magnetization was measured at 10K in magnetic fields ranging from -70kOe to 70kOe. A temperature-dependent study of magnetization evolution was conducted for a selection of U/Gd samples. PNR was performed in a field of 4.4kOe for U/Fe and U/Co samples at room temperature and for U/Gd samples at 10K. Magnetic 'dead' layers of approximately 15 Angstrom were observed in U/Fe and U/Co samples, consistent with a picture of interdiffused interfaces. A significant reduction in the magnetic moment was observed in the U/Gd system, with a constant value of about 4 Bohr magnetons over a wide range of Gd layer thicknesses, compared to 7.63 for the bulk metal. This could be explained by a pinning of Gd moments resulting from a column-like growth mechanism of the Gd layers. A study of the effective anisotropy suggests that perpendicular magnetic anisotropy could occur in multilayers consisting of thick U and thin Gd layers. A reduction in the Curie temperature was observed as a function of Gd layer thickness, consistent with a finite-size scaling behaviour.",
          "error": null
        }
      }
    },
    {
      "id": 50,
      "title": "Fast Adaptive Algorithms in the Non-Standard Form for Multidimensional Problems",
      "original_text": "We present a fast, adaptive multiresolution algorithm for applying integral operators with a wide class of radially symmetric kernels in dimensions one, two and three. This algorithm is made efficient by the use of separated representations of the kernel. We discuss operators of the class $(-\\Delta+\\mu^{2}I)^{-\\alpha}$, where $\\mu\\geq0$ and $0<\\alpha<3/2$, and illustrate the algorithm for the Poisson and Schr\\\"{o}dinger equations in dimension three. The same algorithm may be used for all operators with radially symmetric kernels approximated as a weighted sum of Gaussians, making it applicable across multiple fields by reusing a single implementation. This fast algorithm provides controllable accuracy at a reasonable cost, comparable to that of the Fast Multipole Method (FMM). It differs from the FMM by the type of approximation used to represent kernels and has an advantage of being easily extendable to higher dimensions.",
      "generations": {
        "easy_general": {
          "text": "Scientists have found a new way to solve certain types of math problems, especially in physics, engineering, and astronomy. This method, called a \"fast, adaptive multiresolution algorithm,\" can solve problems in one, two, or three dimensions. It works by breaking down the problem into smaller, more manageable parts. The algorithm is especially useful for problems with sphere-shaped kernels that can be represented as a weighted sum of Gaussians.\n\nThe scientists tested this algorithm on two specific types of problems: the Poisson and the Schrdinger equations. They found that the algorithm was accurate and efficient compared to other methods.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Scientists have developed a new way to solve complex problems in physics, engineering, and other fields. This method is called a \"fast, adaptive multiresolution algorithm.\" It's designed to work with different types of math problems in one, two, and three dimensions.\n\nThe algorithm works by using a technique called \"separated representations.\" This allows it to solve problems quickly and accurately, even when they are complex. The algorithm is particularly useful for a class of math problems called \"integral operators,\" which are used in physics, engineering, and other fields.\n\nThe scientists tested the algorithm on two specific examples: the Poisson and Schr\\\"dinger equations in three dimensions. The algorithm can also be used for other types of math problems with radially symmetric kernels that are represented as a weighted sum of Gaussians.\n\nThis algorithm is similar to another popular method called the Fast Multipole Method (FMM), but it's more flexible and can be used in higher dimensions.",
          "error": null
        },
        "adult_technical": {
          "text": "We introduce a novel, efficient algorithm for applying integral operators with radially symmetric kernels in dimensions one, two, and three. This algorithm leverages separated representations of the kernel to achieve high performance. We focus on operators of the form $(-\\Delta+\\mu^{2}I)^{-\\alpha}$, where $\\mu\\geq0$ and $0<\\alpha<3/2$, and demonstrate its application to the Poisson and Schrdinger equations in three dimensions. The algorithm is versatile, applicable to all operators with radially symmetric kernels represented as weighted sums of Gaussians, making it suitable for various fields with a single implementation. This method offers controllable accuracy at a competitive cost, comparable to the Fast Multipole Method (FMM). It differs from the FMM in its kernel approximation and is more easily adaptable to higher dimensions.",
          "error": null
        }
      }
    },
    {
      "id": 51,
      "title": "Fifteen Years of High-Resolution Radio Imaging of Supernova 1987A",
      "original_text": "Supernova 1987A in the Large Magellanic Cloud provides a spectacularly detailed view of the aftermath of a core-collapse explosion. The supernova ejecta initially coasted outward at more than 10% of the speed of light, but in 1990 were observed to decelerate rapidly as they began to encounter dense circumstellar material expelled by the progenitor star. The resulting shock has subsequently produced steadily brightening radio synchrotron emission, which is resolved by the Australia Telescope Compact Array (ATCA) into an expanding limb-brightened shell. Here we present 15 years of ATCA imaging of Supernova 1987A, at an effective angular resolution of 0.4 arcsec. We find that the radio remnant has accelerated in its expansion over this period, from approx 3600 km/s in 1992 to approx 5200 km/s at the end of 2006. The published diameters of the evolving X-ray shell have been ~15% smaller than the corresponding radio values, but a simultaneous Fourier analysis of both radio and X-ray data eliminates this discrepancy, and yields a current diameter for the shell in both wave-bands of approx 1.7 arcsec. An asymmetric brightness distribution is seen in radio images at all ATCA epochs: the eastern and western rims have higher fluxes than the northern and southern regions, indicating that most of the radio emission comes from the equatorial plane of the system, where the progenitor star's circumstellar wind is thought to be densest. The eastern lobe is brighter than and further from the supernova site than the western lobe, suggesting an additional asymmetry in the initial distribution of supernova ejecta.",
      "generations": {
        "easy_general": {
          "text": "A big star exploded in 1987 in a nearby galaxy called the Large Magellanic Cloud. This explosion, called Supernova 1987A, is helping us understand what happens when a star dies. The explosion sent out a lot of material",
          "error": null
        },
        "adult_non_technical": {
          "text": "A supernova is a massive explosion that happens when a star runs out of fuel and collapses. In 1987, a supernova occurred in a nearby galaxy called the Large Magellanic Cloud, which is a satellite galaxy of our Milky Way. This supernova, called Supernova 1987A, gave scientists a unique opportunity to study what happens after a star explodes.\n\nWhen a supernova happens, the star's core collapses inward, causing a massive explosion. This explosion expels huge amounts of material into space, and as this material moves outward, it interacts with the material that surrounds the star. After the explosion, the ejecta, or the material that was expelled, initially moved outward at more than 10% of the speed of light. However, as they began to encounter the dense material around the star, they quickly slowed down.\n\nThe material from the supernova created a shockwave, which is a wave of energy that travels through the material. This shockwave produced a type of light called radio synchrotron emission, which is a type of radio wave that can be detected by instruments like the Australia Telescope Compact Array (ATCA). The ATCA has been taking images of the supernova for 15 years, and these images show that the material from the supernova has been expanding faster and faster over time.\n\nIn 1992, the material was moving at about 3600 kilometers per second, but by 2006, it was moving at about 5200 kilometers per second. This means that the material from the supernova has accelerated in its expansion.\n\nScientists also found that the size of the X-ray shell, which is another type of light produced by the supernova, was about 15% smaller than the radio shell. However, when they analyzed both the radio and X-ray data together, they found that the size of the shell in both types of light was about the same, around 1.7 arcseconds.\n\nThe radio images also showed that the material from the supernova was not evenly distributed. The eastern and western parts of the material were brighter than the northern and southern parts. This suggests that most of the radio emission comes from the equatorial plane of the system, where the material around the star was densest. Additionally, the eastern part of the material was brighter and further from the supernova site than the western part, indicating that there was an asymmetry in the initial distribution of the supernova material.",
          "error": null
        },
        "adult_technical": {
          "text": "The Supernova 1987A event in the Large Magellanic Cloud offers a remarkably detailed view of the aftermath of a core-collapse explosion. Initially, the supernova ejecta expanded at a speed exceeding 10% of the speed of light. However, in 1990, they began to decelerate rapidly as they encountered dense circumstellar material expelled by the progenitor star. The resulting shock has since produced increasingly bright radio synchrotron emission, which is resolved by the Australia Telescope Compact Array (ATCA) into an expanding limb-brightened shell.\n\nWe have presented 15 years of ATCA imaging of Supernova 1987A, with an effective angular resolution of 0.4 arcseconds. Our findings reveal that the radio remnant has accelerated in its expansion over this period, from approximately 3600 km/s in 1992 to approximately 5200 km/s at the end of 2006. The published diameters of the evolving X-ray shell have been approximately 15% smaller than the corresponding radio values. However, a simultaneous Fourier analysis of both radio and X-ray data eliminates this discrepancy and yields a current diameter for the shell in both wave-bands of approximately 1.7 arcseconds.\n\nAn asymmetric brightness distribution is observed in radio images at all ATCA epochs. The eastern and western rims have higher fluxes than the northern and southern regions, indicating that most of the radio emission originates from the equatorial plane of the system, where the progenitor star's circumstellar wind is thought to be densest. The eastern lobe is brighter and further from the supernova site than the western lobe, suggesting an additional asymmetry in the initial distribution of supernova ejecta.",
          "error": null
        }
      }
    },
    {
      "id": 52,
      "title": "Absolute measurement of the nitrogen fluorescence yield in air between 300 and 430 nm",
      "original_text": "The nitrogen fluorescence induced in air is used to detect ultra-high energy cosmic rays and to measure their energy. The precise knowledge of the absolute fluorescence yield is the key quantity to improve the accuracy on the cosmic ray energy. The total yield has been measured in dry air using a 90Sr source and a [300-430 nm] filter. The fluorescence yield in air is 4.23 $\\pm$ 0.20 photons per meter when normalized to 760 mmHg, 15 degrees C and with an electron energy of 0.85 MeV. This result is consistent with previous experiments made at various energies, but with an accuracy improved by a factor of about 3. For the first time, the absolute continuous spectrum of nitrogen excited by 90Sr electrons has also been measured with a spectrometer. Details of this experiment are given in one of the author's PhD thesis [32].",
      "generations": {
        "easy_general": {
          "text": "Scientists use a special light called nitrogen fluorescence to find and measure ultra-high-energy cosmic rays from outer space. They need to know exactly how much light is produced to make their measurements more accurate. They used a special source and a filter to measure this light and found that there are 4.23 photons per meter in dry air. This result is similar to other experiments, but it's more precise. They also measured the continuous spectrum of this special light for the first time.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Scientists use a special light called nitrogen fluorescence to detect powerful cosmic rays and figure out their energy. Knowing exactly how much of this light is produced helps them measure the energy more accurately. They used a special source called 90Sr and a filter to measure this light and found that there are about 4.23 photons per meter in dry air. This result is similar to other experiments, but it's much more precise - it's about 3 times more accurate. The scientists also measured the spectrum of this light for the first time.",
          "error": null
        },
        "adult_technical": {
          "text": "The fluorescence of nitrogen in air is employed to detect ultra-high energy cosmic rays and measure their energy. Accurate knowledge of the absolute fluorescence yield is crucial for enhancing the precision of cosmic ray energy measurements. The total yield has been measured in dry air using a 90Sr source and a [300-430 nm] filter. The fluorescence yield in air is 4.23  0.20 photons per meter when normalized to 760 mmHg, 15 degrees C, and an electron energy of 0.85 MeV. This result aligns with previous experiments at various energies, but with an accuracy improved by a factor of about 3. For the first time, the absolute continuous spectrum of nitrogen excited by 90Sr electrons has been measured using a spectrometer. Details of this experiment are provided in one of the author's PhD thesis [32].",
          "error": null
        }
      }
    },
    {
      "id": 53,
      "title": "Polariton-polariton scattering: exact results through a novel approach",
      "original_text": "We present a fully microscopic approach to the transition rate of two exciton-photon polaritons. The non-trivial consequences of the polariton composite nature -- here treated exactly through a development of our composite-exciton many-body theory -- lead to results noticeably different from the ones of the conventional approaches in which polaritons are mapped into elementary bosons. Our work reveals an appealing fundamental scattering which corresponds to a photon-assisted exchange -- in the absence of Coulomb process. This scattering being dominant when one of the scattered polaritons has a strong photon character, it should be directly accessible to experiment. In the case of microcavity polaritons, it produces a significant enhancement of the polariton transition rate when compared to the one coming from Coulomb interaction. This paper also contains the crucial tools to securely tackle the many-body physics of polaritons, in particular towards its possible BEC.",
      "generations": {
        "easy_general": {
          "text": "In this study, we look at how two types of particles called \"exciton\" and \"photon\" come together to form something called \"polaritons.\" Polaritons are a mix of excitons and photons, and they can change from one form to another. We found a new way to understand how these polaritons change, and it's different from the usual way people think about it. This new way can help us understand how polaritons behave in different situations.",
          "error": null
        },
        "adult_non_technical": {
          "text": "We found a new way to understand how tiny particles called polaritons interact with each other. These particles are made up of excitons and photons, and they can behave in ways that are different from what we usually expect. Our research reveals a new type of interaction between these particles, which can be seen in certain experiments. This discovery could help us better understand the behavior of these particles.",
          "error": null
        },
        "adult_technical": {
          "text": "We introduce a comprehensive microscopic approach to study the transition rate of two exciton-photon polaritons. By considering the polariton's composite nature through our composite-exciton many-body theory, we obtain results that differ significantly from conventional methods, where polaritons are treated as elementary bosons. Our findings highlight a fundamental scattering process characterized by a photon-assisted exchange, which is prominent in the absence of Coulomb interactions. This process is particularly relevant when one of the polaritons exhibits a strong photon character, making it accessible for experimental verification. In the context of microcavity polaritons, this scattering leads to a notable enhancement of the polariton transition rate compared to the Coulomb interaction alone. Additionally, this paper provides essential tools to address the many-body physics of polaritons, with a focus on the possibility of Bose-Einstein condensation (BEC).",
          "error": null
        }
      }
    },
    {
      "id": 54,
      "title": "Z boson decay to photon plus Kaluza-Klein graviton in large extra dimensions",
      "original_text": "In the large extra dimensional ADD scenario, Z bosons undergo a one-loop decay into a photon and Kaluza-Klein towers of gravitons/gravi-scalars. We calculate such a decay width, extending previous arguments about the general form of the four-dimensional on-shell amplitude. The amplitudes calculated are relevant to processes in other extra dimensional models where the Standard Model fields are confined to a 4-brane.",
      "generations": {
        "easy_general": {
          "text": "In a theory called the \"large extra dimensional ADD scenario,\" special particles called Z bosons can change into other particles like a photon. Scientists calculated how often this happens, which can help us understand other similar theories.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In a theory called the large extra dimensional ADD scenario, Z bosons can decay into a photon and towers of gravitons and other particles. We calculated this decay rate, building on some previous ideas. These calculations are important for understanding processes in other theories where certain particles are confined to a four-dimensional surface.",
          "error": null
        },
        "adult_technical": {
          "text": "In the large extra-dimensional ADD scenario, Z bosons undergo a one-loop decay into a photon and Kaluza-Klein towers of gravitons/gravi-scalars. We calculate such a decay width, extending previous arguments about the general form of the four-dimensional on-shell amplitude. The amplitudes calculated are relevant to processes in other extra-dimensional models where the Standard Model fields are confined to a 4-brane.",
          "error": null
        }
      }
    },
    {
      "id": 55,
      "title": "Bar-Halo Friction in Galaxies III: Particle Number Requirements for Simulations",
      "original_text": "The question whether the dark matter halo density in the centers of galaxies could be changed through interactions with a rotating bar in the baryonic disk is of considerable current interest. While N-body simulations have been used to address this question, it has also been claimed that results from such simulations cannot be trusted. Based on a perturbative treatment of resonant exchanges between orbits and a rotating perturbation, Weinberg & Katz contend that N-body simulations of this process will not reveal the continuum result unless many more than the usual numbers of particles are employed. Here I report a study designed to examine their contention, finding results that show no dependence on the number of particles over the range usually employed up to that advocated by these authors. I show that my results are independent of all numerical parameters, and that field methods perform equally with grid methods in this respect. I also identify the reasons that the required particle number suggested by Weinberg & Katz is excessive.",
      "generations": {
        "easy_general": {
          "text": "Dark matter is a mysterious substance that makes up a large part of the mass in the universe. It's thought to be concentrated in the centers of galaxies, and scientists are studying how it behaves.",
          "error": null
        },
        "adult_non_technical": {
          "text": "\"Dark matter in the centers of galaxies is a fascinating topic, and scientists are wondering if it could be affected by interactions with a rotating bar in the disk. They use computer models called N-body simulations to study this, but some people argue that these models might not be reliable. Weinberg and Katz suggest that these models won't show the right results unless they use many more particles. I did a study to test this idea, and I found that the number of particles doesn't really affect the results. I also discovered that the number of particles Weinberg and Katz suggested is actually too high.\"",
          "error": null
        },
        "adult_technical": {
          "text": "The question of whether the dark matter halo density at the centers of galaxies can be altered through interactions with a rotating bar in the baryonic disk is of considerable interest. N-body simulations have been used to address this question, but it has also been claimed that results from such simulations cannot be trusted. Based on a perturbative treatment of resonant exchanges between orbits and a rotating perturbation, Weinberg & Katz contend that N-body simulations of this process will not reveal the continuum result unless many more than the usual numbers of particles are employed. Here I report a study designed to examine their contention, finding results that show no dependence on the number of particles over the range usually employed up to that advocated by these authors. I show that my results are independent of all numerical parameters, and that field methods perform equally with grid methods in this respect. I also identify the reasons that the required particle number suggested by Weinberg & Katz is excessive.",
          "error": null
        }
      }
    },
    {
      "id": 56,
      "title": "Three-Year Wilkinson Microwave Anisotropy Probe (WMAP) Observations: Foreground Polarization",
      "original_text": "We present a full-sky model of polarized Galactic microwave emission based on three years of observations by the Wilkinson Microwave Anisotropy Probe (WMAP) at frequencies from 23 to 94 GHz. The model compares maps of the Stokes Q and U components from each of the 5 WMAP frequency bands in order to separate synchrotron from dust emission, taking into account the spatial and frequency dependence of the synchrotron and dust components. This simple two-component model of the interstellar medium accounts for at least 97% of the polarized emission in the WMAP maps of the microwave sky. Synchrotron emission dominates the polarized foregrounds at frequencies below 50 GHz, and is comparable to the dust contribution at 65 GHz. The spectral index of the synchrotron component, derived solely from polarization data, is -3.2 averaged over the full sky, with a modestly flatter index on the Galactic plane. The synchrotron emission has mean polarization fraction 2--4% in the Galactic plane and rising to over 20% at high latitude, with prominent features such as the North Galactic Spur more polarized than the diffuse component. Thermal dust emission has polarization fraction 1% near the Galactic center, rising to 6% at the anti-center. Diffuse emission from high-latitude dust is also polarized with mean fractional polarization 0.036 +/- 0.011.",
      "generations": {
        "easy_general": {
          "text": "We have created a map of the light coming from our galaxy. This map helps us understand the movement of stars and dust in our galaxy.",
          "error": null
        },
        "adult_non_technical": {
          "text": "\"We have created a model of the polarized microwave emissions from our galaxy, based on observations from the Wilkinson Microwave Anisotropy Probe (WMAP). WMAP looked at different frequencies, from 23 to 94 GHz, over three years. Our model compares the maps of the Stokes Q and U components from each of the 5 WMAP frequency bands. This helps separate the emissions from synchrotron and dust in the interstellar medium. The model explains at least 97% of the polarized emissions in the WMAP maps. The synchrotron emissions dominate the polarized foregrounds at frequencies below 50 GHz, and are similar to the dust emissions at 65 GHz. The spectral index of the synchrotron component, calculated from the polarization data, is -3.2 over the entire sky, with a slightly flatter index in the Galactic plane. The synchrotron emissions are about 2-4% polarized in the Galactic plane and up to 20% at high latitudes, with some areas, like the North Galactic Spur, being more polarized than the diffuse emissions. The dust emissions are about 1% polarized near the Galactic center and up to 6% at the anti-center. The diffuse emissions from high-latitude dust are also polarized, with an average polarization of 0.036  0.011.\"",
          "error": null
        },
        "adult_technical": {
          "text": "We introduce a comprehensive model of polarized microwave emission from the Milky Way, utilizing three years of data from the Wilkinson Microwave Anisotropy Probe (WMAP) at frequencies ranging from 23 to 94 GHz. This model examines the Stokes Q and U components from each of the five WMAP frequency bands to distinguish between synchrotron and dust emission, accounting for their spatial and frequency variations. This two-component model of the interstellar medium explains at least 97% of the polarized emission observed in the WMAP maps of the microwave sky. Synchrotron emission is the dominant component at frequencies below 50 GHz, and it becomes comparable to the dust contribution at 65 GHz. The spectral index of the synchrotron component, derived solely from polarization data, averages -3.2 across the entire sky, with a slightly flatter index in the Galactic plane. The synchrotron emission exhibits a mean polarization fraction of 2-4% in the Galactic plane, increasing to over 20% at high latitudes, with prominent features like the North Galactic Spur being more polarized than the diffuse component. Thermal dust emission has a polarization fraction of 1% near the Galactic center, rising to 6% at the anti-center. Diffuse emission from high-latitude dust is also polarized, with a mean fractional polarization of 0.036  0.011.",
          "error": null
        }
      }
    },
    {
      "id": 57,
      "title": "Six New ZZ Ceti Stars from the SPY and the HQS Surveys",
      "original_text": "We report on the discovery of six new ZZ Ceti stars. They were selected as candidates based on preparatory photometric observations of objects from the Hamburg Quasar Survey (HQS), and based on the spectra of the Supernova Ia Progenitor Survey (SPY). Time-series photometry of 19 candidate stars was carried out at the Nordic Optical Telescope (NOT) at Roque de Los Muchachos Observatory, Spain. The new variables are relatively bright, 15.4<B<16.6. Among them is WD1150-153, which is the third ZZ Ceti star that shows photospheric CaII in its spectrum.",
      "generations": {
        "easy_general": {
          "text": "Scientists have found six new ZZ Ceti stars. These stars were identified by looking at data from two different surveys: the Hamburg Quasar Survey (HQS) and the Supernova Ia Progenitor Survey (SPY). They then used a special telescope called the Nordic Optical Telescope (NOT) to look at 19 possible stars. These new ZZ Ceti stars are quite bright, with a brightness between 15.4 and 16.6. One of them, called WD1150-153, is special because it has a certain type of light in its spectrum called photospheric CaII. This is the third ZZ Ceti star to have this feature.",
          "error": null
        },
        "adult_non_technical": {
          "text": "We've found six new ZZ Ceti stars, which are special types of stars that change brightness over time. We found them by looking at data from the Hamburg Quasar Survey and the spectra from the Supernova Ia Progenitor Survey. Then, we used a telescope called the Nordic Optical Telescope (NOT) in Spain to study 19 of these stars. These new stars are pretty bright, with a brightness between 15.4 and 16.6. One of them, WD1150-153, is special because it's the third ZZ Ceti star that shows a certain type of light called photospheric CaII in its spectrum.",
          "error": null
        },
        "adult_technical": {
          "text": "We announce the discovery of six new ZZ Ceti stars. These candidates were identified through preparatory photometric observations from the Hamburg Quasar Survey (HQS) and the Supernova Ia Progenitor Survey (SPY). Time-series photometry of 19 candidate stars was conducted at the Nordic Optical Telescope (NOT) at Roque de Los Muchachos Observatory in Spain. The newly discovered variables are relatively bright, with magnitudes ranging from 15.4 to 16.6. Notably, WD1150-153 is the third ZZ Ceti star to exhibit photospheric calcium II (CaII) in its spectrum.",
          "error": null
        }
      }
    },
    {
      "id": 58,
      "title": "Melting tungsten nanoparticles: a molecular dynamics study",
      "original_text": "We report a molecular dynamics simulation of melting of tungsten (W) nanoparticles. The modified embedded atom method (MEAM) interatomic potentials are used to describe the interaction between tungsten atoms. The melting temperature of unsupported tungsten nanoparticles of different sizes are found to decrease as the size of the particles decreases. The melting temperature obtained in the present study is approximately a decreasing function of inverse radius, in a good agreement with the predictions of thermodynamic models. We also observed that the melting of a W nanoparticle is preceded by the premelting of its outer skin at a temperature lower than its melting temperature.",
      "generations": {
        "easy_general": {
          "text": "We did a computer simulation to see how tungsten nanoparticles melt. We used a special method called MEAM to understand how the tungsten atoms interact. We found that when the nanoparticles get smaller, they melt at a lower temperature. This is similar to what we would expect from a theory called thermodynamics. Also, we noticed that the outer layer of the nanoparticles starts to melt before the whole particle.",
          "error": null
        },
        "adult_non_technical": {
          "text": "We used a computer simulation to study how tiny tungsten particles melt. We used a special method called MEAM to understand how the tungsten atoms interact. We found that as the particles get smaller, they melt at a lower temperature. This matches what scientists predicted using other models. We also saw that the outer layer of the particles starts to melt before the whole particle, at a lower temperature.",
          "error": null
        },
        "adult_technical": {
          "text": "We present a molecular dynamics simulation of the melting of tungsten (W) nanoparticles, employing the modified embedded atom method (MEAM) interatomic potentials to describe the interactions between tungsten atoms. The melting temperature of unsupported tungsten nanoparticles of varying sizes is observed to decrease as the particle size decreases. The melting temperature obtained in this study is approximately a decreasing function of inverse radius, in good agreement with thermodynamic models. Additionally, we observe that the melting of a W nanoparticle is preceded by the premelting of its outer skin at a temperature lower than its melting temperature.",
          "error": null
        }
      }
    },
    {
      "id": 59,
      "title": "Detection of exchange interaction in STM measurements through Fanolike interference effects",
      "original_text": "We address Fano-like interference effects in scanning tunneling microscopy (STM) measurements of nanoscale systems, e.g. two-level systems. Common for these systems is that second order tunneling contributions give rise to interference effects that cause suppressed transmission through the system for certain energies. The suppressed transmission is measurable either in the differential conductance or in the bias voltage derivative thereof.",
      "generations": {
        "easy_general": {
          "text": "\"We look at interference effects in scanning tunneling microscopy (STM) measurements of nanoscale systems, like two-level systems. These effects happen when second-order tunneling contributions cause reduced transmission through the system for certain energies. We can measure this reduced transmission using the differential conductance or the bias voltage derivative.\"",
          "error": null
        },
        "adult_non_technical": {
          "text": "\"We look at Fano-like interference effects in scanning tunneling microscopy (STM) measurements of nanoscale systems, like two-level systems. In these systems, second-order tunneling effects can cause reduced transmission for certain energies. This reduced transmission can be measured using the differential conductance or the bias voltage derivative.\"",
          "error": null
        },
        "adult_technical": {
          "text": "We discuss Fano-like interference effects in scanning tunneling microscopy (STM) measurements of nanoscale systems, such as two-level systems. In these systems, second-order tunneling contributions lead to interference effects that result in suppressed transmission through the system for certain energies. This suppressed transmission can be measured either in the differential conductance or in the bias voltage derivative thereof.",
          "error": null
        }
      }
    },
    {
      "id": 60,
      "title": "Gamma-ray albedo of the moon",
      "original_text": "We use the GEANT4 Monte Carlo framework to calculate the gamma-ray albedo of the Moon due to interactions of cosmic ray (CR) nuclei with moon rock. Our calculation of the albedo spectrum agrees with the EGRET data. We show that the spectrum of gamma rays from the Moon is very steep with an effective cutoff around 4 GeV (600 MeV for the inner part of the Moon disc). Apart from other astrophysical sources, the albedo spectrum of the Moon is well understood, including its absolute normalisation; this makes it a useful \"standard candle\" for gamma-ray telescopes, such as the forthcoming Gamma Ray Large Area Space Telescope (GLAST). The albedo flux depends on the incident CR spectrum which changes over the solar cycle. Therefore, it is possible to monitor the CR spectrum using the albedo gamma-ray flux. Simultaneous measurements of CR proton and helium spectra by the Payload for Antimatter Matter Exploration and Light-nuclei Astrophysics (PAMELA), and observations of the albedo gamma rays by the GLAST Large Area Telescope (LAT), can be used to test the model predictions and will enable the GLAST LAT to monitor the CR spectrum near the Earth beyond the lifetime of PAMELA.",
      "generations": {
        "easy_general": {
          "text": "We used a special tool called GEANT4 to study how cosmic rays hit the Moon's surface and create gamma rays. We found that these gamma rays have a specific pattern, called a spectrum, which matches data from the EGRET experiment. The spectrum of the Moon's gamma rays is very steep, with a natural cutoff around 4 GeV (600 MeV for the inner part of the Moon). This spectrum is well understood, making it a useful reference for gamma-ray telescopes, like the Gamma Ray Large Area Space Telescope (GLAST).\n\nThe amount of gamma rays produced by the Moon depends on the cosmic ray spectrum, which changes the way the sun does. This means we can use the Moon's gamma rays to monitor the cosmic ray spectrum. By comparing the gamma rays from the Moon with measurements of cosmic rays from the PAMELA satellite, we can test our models and use the GLAST LAT to study the cosmic ray spectrum beyond the lifetime of PAMELA.",
          "error": null
        },
        "adult_non_technical": {
          "text": "We used a special tool called the GEANT4 Monte Carlo framework to study how cosmic rays hitting the Moon's surface create gamma rays. These gamma rays are like a special light that helps us understand how cosmic rays change over time. We can use this information to study how cosmic rays affect the Earth and other space objects.",
          "error": null
        },
        "adult_technical": {
          "text": "Using the GEANT4 Monte Carlo framework, we calculate the gamma-ray albedo of the Moon resulting from interactions between cosmic ray (CR) nuclei and lunar rock. Our calculations align with EGRET data, revealing that the Moon's gamma-ray spectrum is steep, with an effective cutoff around 4 GeV (600 MeV for the inner part of the Moon disc). Unlike other astrophysical sources, the Moon's albedo spectrum is well understood, including its absolute normalization, making it a valuable \"standard candle\" for gamma-ray telescopes, such as the upcoming Gamma Ray Large Area Space Telescope (GLAST). The albedo flux depends on the incident CR spectrum, which varies over the solar cycle. Consequently, it is possible to monitor the CR spectrum using the albedo gamma-ray flux. Simultaneous measurements of CR proton and helium spectra by the Payload for Antimatter Matter Exploration and Light-nuclei Astrophysics (PAMELA) and observations of the albedo gamma rays by the GLAST Large Area Telescope (LAT) will validate the model predictions and enable the GLAST LAT to monitor the CR spectrum near the Earth beyond the lifetime of PAMELA.",
          "error": null
        }
      }
    },
    {
      "id": 61,
      "title": "Manipulating the rotational properties of a two-component Bose gas",
      "original_text": "A rotating, two-component Bose-Einstein condensate is shown to exhibit vortices of multiple quantization, which are possible due to the interatomic interactions between the two species. Also, persistent currents are absent in this system. Finally, the order parameter has a very simple structure for a range of angular momenta.",
      "generations": {
        "easy_general": {
          "text": "Imagine a special gas with two types of atoms that spins around. This gas is called a Bose-Einstein condensate. When it spins, it creates special patterns called vortices. These vortices can happen because of how the two types of atoms work together. Also, there aren't any things called persistent currents in this gas. Finally, there's a way to describe the gas's behavior that's very simple.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Imagine a special kind of gas, called a Bose-Einstein condensate, made up of two different parts. When this gas spins around, it creates strange patterns called vortices. These vortices happen because of the way the two parts interact with each other. Also, this gas doesn't have something called persistent currents. Finally, the gas has a very simple structure when it's spinning.",
          "error": null
        },
        "adult_technical": {
          "text": "A rotating, two-component Bose-Einstein condensate displays vortices of multiple quantization, which arise due to the interatomic interactions between the two species. Additionally, persistent currents are absent in this system. Furthermore, the order parameter exhibits a simple structure for a range of angular momenta.",
          "error": null
        }
      }
    },
    {
      "id": 62,
      "title": "Entanglement in the quantum Ising model",
      "original_text": "We study the asymptotic scaling of the entanglement of a block of spins for the ground state of the one-dimensional quantum Ising model with transverse field. When the field is sufficiently strong, the entanglement grows at most logarithmically in the number of spins. The proof utilises a transformation to a model of classical probability called the continuum random-cluster model, and is based on a property of the latter model termed ratio weak-mixing. Our proof applies equally to a large class of disordered interactions.",
      "generations": {
        "easy_general": {
          "text": "Imagine you have a line of tiny magnets, each pointing either up or down. These magnets are called \"spins.\" When you apply a strong magnetic field to this line, the spins start to align in a certain way.",
          "error": null
        },
        "adult_non_technical": {
          "text": "\"We looked at how the entanglement of a group of spins changes in a certain type of quantum system. When the field is strong, the entanglement grows slowly, like a logarithm. We proved this by changing the problem into a different type of model called the continuum random-cluster model. This proof also works for other types of disordered interactions.\"",
          "error": null
        },
        "adult_technical": {
          "text": "We investigate the asymptotic scaling of the entanglement of a block of spins for the ground state of the one-dimensional quantum Ising model with a transverse field. When the field is sufficiently strong, the entanglement grows at most logarithmically in the number of spins. The proof employs a transformation to a model of classical probability called the continuum random-cluster model, and is based on a property of the latter model termed ratio weak-mixing. Our proof applies equally to a large class of disordered interactions.",
          "error": null
        }
      }
    },
    {
      "id": 63,
      "title": "The effect of the solar corona on the attenuation of small-amplitude prominence oscillations. I. Longitudinal magnetic field",
      "original_text": "Context. One of the typical features shown by observations of solar prominence oscillations is that they are damped in time and that the values of the damping times are usually between one and three times the corresponding oscillatory period. However, the mechanism responsible for the attenuation is still not well-known. Aims. Thermal conduction, optically thin or thick radiation and heating are taken into account in the energy equation, and their role on the attenuation of prominence oscillations is evaluated. Methods. The dispersion relation for linear non-adiabatic magnetoacoustic waves is derived considering an equilibrium made of a prominence plasma slab embedded in an unbounded corona. The magnetic field is orientated along the direction parallel to the slab axis and has the same strength in all regions. By solving the dispersion relation for a fixed wavenumber, a complex oscillatory frequency is obtained, and the period and the damping time are computed. Results. The effect of conduction and radiation losses is different for each magnetoacoustic mode and depends on the wavenumber. In the observed range of wavelengths the internal slow mode is attenuated by radiation from the prominence plasma, the fast mode by the combination of prominence radiation and coronal conduction and the external slow mode by coronal conduction. The consideration of the external corona is of paramount importance in the case of the fast and external slow modes, whereas it does not affect the internal slow modes at all. Conclusions. Non-adiabatic effects are efficient damping mechanisms for magnetoacoustic modes, and the values of the obtained damping times are compatible with those observed.",
      "generations": {
        "easy_general": {
          "text": "Context: When we look at pictures of the sun, we often see big, loopy structures called solar prominences. These prominences can move and change shape, but they usually slow down and stop moving over time. The time it takes for them to stop moving is usually between one and three times the time it takes for them to move back and forth once. But the reason they slow down is not well-known.\n\nAims: We want to understand why these prominences slow down. We will look at how heat moves, how light travels, and how heating happens to see if these things affect how fast the prominences slow down.\n\nMethods: We made a model of a prominence that is a slab of hot gas called plasma. This slab is floating in a larger area called the corona. The magnetic field is parallel to the axis of the slab and is the same strength everywhere. We used a special equation to describe how sound waves move in this model. We then solved this equation to find out how fast the waves move and how long it takes for them to slow down.\n\nResults: We found that different types of sound waves in the prominences slow down for different reasons. The slowest waves are slowed down by light from the plasma. The fastest waves are slowed down by a combination of light from the plasma and heat moving through the corona. The slowest waves on the outside are slowed down by heat moving through the corona.\n\nConclusions: We think that non-adiabatic effects are important for slowing down these sound waves. The times we calculated for the waves to slow down match what we see in pictures.",
          "error": null
        },
        "adult_non_technical": {
          "text": "When you look at the sun, you might see some cool features called prominences. These prominences can vibrate and move, but eventually, they slow down and stop. Scientists want to understand why this happens. They think that",
          "error": null
        },
        "adult_technical": {
          "text": "Context: Observations of solar prominence oscillations reveal that they typically decay over time, with damping times usually ranging from one to three times the oscillation period. However, the underlying mechanism responsible for this attenuation remains unclear. Aims: In this study, we consider the roles of thermal conduction, optically thin or thick radiation, and heating in the energy equation to assess their impact on the damping of prominence oscillations. Methods: We derive the dispersion relation for linear non-adiabatic magnetoacoustic waves in an equilibrium consisting of a prominence plasma slab embedded in an unbounded corona. The magnetic field is aligned with the slab axis and has the same strength throughout all regions. By solving the dispersion relation for a fixed wavenumber, we obtain a complex oscillatory frequency and compute the period and damping time. Results: The effects of conduction and radiation losses vary among magnetoacoustic modes and depend on the wavenumber. In the observed wavelength range, the internal slow mode is damped by radiation from the prominence plasma, the fast mode by a combination of prominence radiation and coronal conduction, and the external slow mode by coronal conduction. The external corona plays a crucial role in the fast and external slow modes, whereas it does not affect the internal slow modes. Conclusions: Non-adiabatic effects are effective damping mechanisms for magnetoacoustic modes, and the calculated damping times align with those observed.",
          "error": null
        }
      }
    },
    {
      "id": 64,
      "title": "van der Waals-like phase separation instability of a driven granular gas in three dimensions",
      "original_text": "We show that the van der Waals-like phase separation instability of a driven granular gas at zero gravity, previously investigated in two-dimensional settings, persists in three dimensions. We consider a monodisperse granular gas driven by a thermal wall of a three-dimensional rectangular container at zero gravity. The basic steady state of this system, as described by granular hydrodynamic equations, involves a denser and colder layer of granulate located at the wall opposite to the driving wall. When the inelastic energy loss is sufficiently high, the driven granular gas exhibits, in some range of average densities, negative compressibility in the directions parallel to the driving wall. When the lateral dimensions of the container are sufficiently large, the negative compressibility causes spontaneous symmetry breaking of the basic steady state and a phase separation instability. Event-driven molecular dynamics simulations confirm and complement our theoretical predictions.",
      "generations": {
        "easy_general": {
          "text": "",
          "error": null
        },
        "adult_non_technical": {
          "text": "",
          "error": null
        },
        "adult_technical": {
          "text": "We demonstrate that the van der Waals-like phase separation instability of a driven granular gas at zero gravity, previously studied in two-dimensional settings, persists in three dimensions. We consider a monodisperse granular gas driven by a thermal wall of a three-dimensional rectangular container at zero gravity. The basic steady state of this system, as described by granular hydrodynamic equations, involves a denser and colder layer of granulate located at the wall opposite to the driving wall. When the inelastic energy loss is sufficiently high, the driven granular gas exhibits, in some range of average densities, negative compressibility in the directions parallel to the driving wall. When the lateral dimensions of the container are sufficiently large, the negative compressibility causes spontaneous symmetry breaking of the basic steady state and a phase separation instability. Event-driven molecular dynamics simulations confirm and complement our theoretical predictions.",
          "error": null
        }
      }
    },
    {
      "id": 65,
      "title": "Experimental Challenges Involved in Searches for Axion-Like Particles and Nonlinear Quantum Electrodynamic Effects by Sensitive Optical Techniques",
      "original_text": "We discuss the experimental techniques used to date for measuring the changes in polarization state of a laser produced by a strong transverse magnetic field acting in a vacuum. We point out the likely artifacts that can arise in such experiments, with particular reference to the recent PVLAS observations and the previous findings of the BFRT collaboration. Our observations are based on studies with a photon-noise limited coherent homodyne interferometer with a polarization sensitivity of 2x10^-8 rad Hz^(1/2) mW^(-1/2).",
      "generations": {
        "easy_general": {
          "text": "We talk about the different methods used to measure how a laser's light changes when there's a strong magnetic field pushing on it in space. We also mention some problems that can come up in these experiments, like the recent findings from PVLAS and the BFRT collaboration. Our results come from using a special tool that can measure these changes very accurately.",
          "error": null
        },
        "adult_non_technical": {
          "text": "\"We talk about the methods scientists use to measure how a special laser light changes when it goes through a strong magnetic field in a vacuum. We also mention some problems that can happen in these experiments, like the ones found by the PVLAS team and the BFRT group. Our findings come from using a special machine that can measure these changes very accurately.\"",
          "error": null
        },
        "adult_technical": {
          "text": "We examine the experimental methods employed to measure the changes in the polarization state of a laser beam subjected to a strong transverse magnetic field in a vacuum. We highlight the potential artifacts that can occur in these experiments, particularly focusing on the recent PVLAS observations and the previous results from the BFRT collaboration. Our findings are derived from experiments utilizing a photon-noise-limited coherent homodyne interferometer with a polarization sensitivity of 2x10^-8 rad Hz^(1/2) mW^(-1/2).",
          "error": null
        }
      }
    },
    {
      "id": 66,
      "title": "Exact Activation Energy of Magnetic Single Domain Particles",
      "original_text": "I present the exact analytical expression for the activation energy as a function of externally applied magnetic fields for a single--domain magnetic particle with uniaxial anisotropy (Stoner--Wohlfahrt model), and investigate the scaling behavior of the activation energy close to the switching boundary.",
      "generations": {
        "easy_general": {
          "text": "I show the exact formula for the activation energy of a single magnetic particle in response to external magnetic fields. I also study how this energy changes near the switching boundary.",
          "error": null
        },
        "adult_non_technical": {
          "text": "I found an exact formula for calculating the energy needed to change the direction of a single, small magnetic particle when an external magnetic field is applied. This formula helps us understand what happens when the particle is near its switching point.",
          "error": null
        },
        "adult_technical": {
          "text": "I present the precise analytical expression for the activation energy as a function of externally applied magnetic fields for a single-domain magnetic particle with uniaxial anisotropy (Stoner-Wohlfahrt model), and investigate the scaling behavior of the activation energy close to the switching boundary.",
          "error": null
        }
      }
    },
    {
      "id": 67,
      "title": "Irrationality of motivic series of Chow varieties",
      "original_text": "The Euler characteristic of all the Chow varieties, of a fixed projective variety, can be collected in a formal power series called the Euler-Chow series. This series coincides with the Hilbert series when the Picard group is a finite generated free abelian group. It is an interesting open problem to find for which varieties this series is rational. A few cases have been computed, and it is suspected that the series is not rational for the blow up of P^2 at nine points in general position. It is very natural to extend this series to Chow motives and ask the question if the series is rational or to find a counterexample. In this short paper we generalized the series and show by an example that the series is not rational. This opens the question of what is the geometrical meaning of the Euler-Chow series.",
      "generations": {
        "easy_general": {
          "text": "Imagine you have a group of shapes, and you want to find a special pattern that connects them all. This pattern is called the Euler-Chow series. It's interesting to know if this pattern works for all types of shapes. In this paper, we show that the pattern doesn't always work, and we ask a new question about what this pattern means.",
          "error": null
        },
        "adult_non_technical": {
          "text": "The Euler characteristic of all the Chow varieties, of a fixed projective variety, can be collected in a formal power series, called the Euler-Chow series. This series is similar to another series called the Hilbert series when the Picard group is a finite free abelian group. It is an interesting problem to find when the Euler-Chow series is rational. A few cases have been computed, and it is suspected that the series is not rational for a specific case. It is natural to extend the Euler-Chow series to Chow motives and ask if the series is rational or to find a counterexample. In this short paper, we generalized the series and showed by an example that the series is not rational. This opens the question of what is the geometrical meaning of the Euler-Chow series.",
          "error": null
        },
        "adult_technical": {
          "text": "The Euler characteristic of all Chow varieties of a fixed projective variety can be collected into a formal power series known as the Euler-Chow series. This series coincides with the Hilbert series when the Picard group is a finite generated free abelian group. It is an interesting open problem to determine for which varieties this series is rational. A few cases have been computed, and it is suspected that the series is not rational for the blow-up of P^2 at nine points in general position. It is natural to extend this series to Chow motives and ask if the series is rational or to find a counterexample. In this short paper, we generalize the series and show by an example that the series is not rational. This opens the question of what is the geometrical meaning of the Euler-Chow series.",
          "error": null
        }
      }
    },
    {
      "id": 68,
      "title": "Atmospheric dynamics of Pegasi planets",
      "original_text": "We present three-dimensional numerical simulations of the atmospheric dynamics of close-orbiting planets such as HD209458b. Our simulations show that winds of several km/sec and day-night temperature differences reaching 500-1000 K are possible at and above the photosphere. The circulation takes the form of a broad superrotating (eastward) equatorial jet. At 0.1-1 bar, the superrotation blows the hottest regions of the atmosphere downwind by 60 degrees of longitude, but at lower pressures the temperature pattern tracks the stellar illumination. We predict factors of several variation in the infrared flux received at Earth throughout an orbital cycle; if the photosphere is deep enough (>50-100 mbar pressure), the peak infrared emission should lead the time of secondary eclipse by 10 hours or more. Dynamics plays a key role in shaping the spectrum, clouds, chemistry, and long-term planetary evolution.",
      "generations": {
        "easy_general": {
          "text": "\"We have created computer models to study the atmosphere of planets that orbit very close to their stars. These models show that these planets can have very strong winds and huge temperature differences between day and night, reaching 500-1000 degrees Celsius. The atmosphere of these planets has a strong eastward wind that moves the hottest parts of the atmosphere by 60 degrees. However, at lower pressures, the temperature of the atmosphere follows the light from the star. We predict that the amount of infrared light we receive from these planets can change significantly during their orbit. If the atmosphere is thick enough, the strongest infrared light will come before the planet passes in front of its star. These dynamics play a crucial role in shaping the atmosphere, clouds, and chemistry of these planets, as well as their long-term evolution.\"",
          "error": null
        },
        "adult_non_technical": {
          "text": "\"We have created computer models to study the atmosphere of planets that orbit very close to their stars, like HD209458b. These models show that these planets can have very strong winds and huge temperature differences between the day and night sides. The winds can be as fast as several kilometers per second, and the temperature difference can reach 500 to 1000 degrees Celsius. The atmosphere of these planets has a strong eastward wind that blows heat around the equator. At higher altitudes, the wind moves the hottest parts of the atmosphere by 60 degrees of longitude, but at lower altitudes, the temperature pattern follows the light from the star. Our models predict that the amount of infrared light we receive from these planets can change significantly during their orbit. If the atmosphere of the planet is thick enough, the strongest infrared light will come before the planet passes in front of its star. The dynamics of the atmosphere play a crucial role in shaping the planet's spectrum, clouds, chemistry, and long-term evolution.\"",
          "error": null
        },
        "adult_technical": {
          "text": "We have conducted three-dimensional numerical simulations of the atmospheric dynamics of close-orbiting planets, such as HD209458b. These simulations reveal that winds of several kilometers per second and day-night temperature differences of 500-1000 Kelvin are possible at and above the photosphere. The circulation pattern is characterized by a broad superrotating (eastward) equatorial jet. At pressures of 0.1-1 bar, this superrotation shifts the hottest regions of the atmosphere downwind by 60 degrees of longitude. However, at lower pressures, the temperature pattern closely follows the stellar illumination. We predict significant variations in the infrared flux received at Earth throughout an orbital cycle. If the photosphere is deep enough (greater than 50-100 mbar pressure), the peak infrared emission should precede the time of secondary eclipse by 10 hours or more. Dynamics plays a crucial role in shaping the spectrum, clouds, chemistry, and long-term planetary evolution.",
          "error": null
        }
      }
    },
    {
      "id": 69,
      "title": "Optimizing Scrip Systems: Efficiency, Crashes, Hoarders, and Altruists",
      "original_text": "We discuss the design of efficient scrip systems and develop tools for empirically analyzing them. For those interested in the empirical study of scrip systems, we demonstrate how characteristics of agents in a system can be inferred from the equilibrium distribution of money. From the perspective of a system designer, we examine the effect of the money supply on social welfare and show that social welfare is maximized by increasing the money supply up to the point that the system experiences a ``monetary crash,'' where money is sufficiently devalued that no agent is willing to perform a service. We also examine the implications of the presence of altruists and hoarders on the performance of the system. While a small number of altruists may improve social welfare, too many can also cause the system to experience a monetary crash, which may be bad for social welfare. Hoarders generally decrease social welfare but, surprisingly, they also promote system stability by helping prevent monetary crashes. In addition, we provide new technical tools for analyzing and computing equilibria by showing that our model exhibits strategic complementarities, which implies that there exist equilibria in pure strategies that can be computed efficiently.",
      "generations": {
        "easy_general": {
          "text": "Let's talk about how to make money systems work well and how to study them. We'll make some tools to help us understand how these systems work. If you're interested in studying these systems, we'll show you how you can learn about people in them by looking at how money is spread out.\n\nWhen we want to make a good system, we look at how much money is in it. We found that if we put more money into the system, it can make things better for everyone. But if we put too much money in, it can crash and make things worse for everyone.\n\nWe also looked at how some people called altruists and hoarders affect the system. Altruists are people who want to help others, but if there are too many, it can make the system crash. Hoarders are people who save money. While hoarders can make things worse, they can also help keep the system from crashing.\n\nFinally, we made some new tools to help us understand how these systems work. These tools help us find the best way to make the system work well.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this article, we explore the design of scrip systems, which are a type of economic system where scrip, a form of money, is used to exchange goods and services. We also develop tools to analyze these systems empirically, meaning we use real-world data to understand how they work and what can be learned from the behavior of the scrip system. For those interested in the empirical study of scrip systems, we demonstrate how the characteristics of agents in the system can be inferred from the distribution of scrip.\n\nFrom the perspective of the designer of the system, we examine how the amount of scrip in the system affects social welfare. We show that social welfare is maximized by increasing the amount of scrip up to the point where the system experiences a \"monetary crash.\" This happens when the value of scrip becomes so low that no one is willing to perform a service in exchange for it.\n\nWe also explore the impact of altruists and hoarders on the system's performance. While a small number of altruists may improve social welfare, too many can also lead to a monetary crash, which can be bad for social welfare. Hoarders generally decrease social welfare but, surprisingly, they also promote system stability by helping prevent monetary crashes.\n\nIn addition, we provide new technical tools for analyzing and computing equilibria by showing that our model exhibits strategic complementarities, which implies that there exist equilibria in pure strategies that can be computed efficiently.",
          "error": null
        },
        "adult_technical": {
          "text": "We explore the design of efficient scrip systems and develop tools for empirical analysis. For those interested in the empirical study of scrip systems, we demonstrate how the characteristics of agents within a system can be inferred from the equilibrium distribution of money. From the perspective of a system designer, we examine the impact of the money supply on social welfare and show that social welfare is maximized by increasing the money supply up to the point where the system experiences a \"monetary crash,\" where money is sufficiently devalued that no agent is willing to perform a service. We also examine the implications of the presence of altruists and hoarders on the performance of the system. While a small number of altruists may improve social welfare, too many can also cause the system to experience a monetary crash, which may be bad for social welfare. Hoarders generally decrease social welfare but, surprisingly, they also promote system stability by helping prevent monetary crashes. In addition, we provide new technical tools for analyzing and computing equilibria by showing that our model exhibits strategic complementarities, which implies that there exist equilibria in pure strategies that can be computed efficiently.",
          "error": null
        }
      }
    },
    {
      "id": 70,
      "title": "Product Formulae for Ozsvath-Szabo 4-manifold Invariants",
      "original_text": "We give formulae for the Ozsvath-Szabo invariants of 4-manifolds X obtained by fiber sum of two manifolds M_1, M_2 along surfaces S_1, S_2 having trivial normal bundle and genus g>0. The formulae follow from a general theorem on the Ozsvath-Szabo invariants of the result of gluing two 4-manifolds along a common boundary, which is phrased in terms of relative invariants of the pieces. These relative invariants take values in a version of Heegaard Floer homology with coefficients in modules over certain Novikov rings; the fiber sum formula follows from the theorem that this \"perturbed\" version of Heegaard Floer theory recovers the usual Ozsvath-Szabo invariants, when the 4-manifold in question has b^+>1. The construction allows an extension of the definition of the Ozsvath-Szabo invariants to 4-manifolds having b^+ = 1 depending on certain choices, in close analogy with Seiberg-Witten theory. The product formulae lead quickly to calculations of the Ozsvath-Szabo invariants of various 4-manifolds; in all cases the results are in accord with the conjectured equivalence between the Ozsvath-Szabo and Seiberg-Witten invariants.",
      "generations": {
        "easy_general": {
          "text": "Imagine you have two 4-dimensional shapes, M_1 and M_2, and you want to glue them together to make a new shape, X. To do this, you use two surfaces, S_1 and S_2, which are like the boundaries of the shapes. These surfaces have a special property called trivial normal bundle, which means they don't have any twists or turns, and they have a genus greater than zero, which is like the number of holes in a doughnut.\n\nWhen you glue these shapes together, you can calculate some special numbers called the Ozsvath-Szabo invariants. These numbers are like a way to describe the properties of the new shape, X. The formula for calculating these invariants comes from a general theorem that tells you how to combine the invariants of the original shapes into the new shape.\n\nThis theorem is like a recipe that helps you understand the properties of the new shape, X.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this article, we'll explore a type of mathematical object called a 4-manifold, which is a four-dimensional version of a surface. We'll focus on a specific type of 4-manifold called the Ozsvath-Szabo invariants, which are a way to describe the properties of these 4-manifolds.\n\nImagine taking two 4-manifolds, M1 and M2, and gluing them together along two surfaces, S1 and S2. These surfaces have a special property called trivial normal bundle, which means they don't have any \"twist\" or \"twistiness.\" They also have a genus, which is a measure of their complexity, called g.\n\nNow, we'll look at how the Ozsvath-Szabo invariants change when we glue these two 4-manifolds together. To do this, we use something called relative invariants, which are like a way to compare the properties of the two 4-manifolds being glued.\n\nThe relative invariants and the Ozsvath-Szabo invariants are connected to a more general theory called Heegaard Floer homology. Heegaard Floer homology is a way to describe the properties of a 4-manifold using a type of ring called a Novikov ring.\n\nThe formulae for the Ozsvath-Szabo invariants come from a theorem that says that this \"perturbed\" version of Heegaard Floer homology recovers the usual Ozsvath-Szabo invariants when the 4-manifold has a property called b^+ > 1.\n\nThis theorem also allows us to extend the definition of the Ozsvath-Szabo invariants to certain 4-manifolds with b^+ = 1, which is similar to another type of theory called Seiberg-Witten theory.\n\nUsing these formulae, we can quickly calculate the Ozsvath-Szabo invariants of various 4-manifolds, and the results agree with the conjectured equivalence between the Ozsvath-Szabo and Seiberg-Witten invariants.\n\nIn summary, this article provides a way to calculate the Ozsvath-Szabo invariants of 4-manifolds obtained by gluing two 4-manifolds together along special surfaces, and it connects this to a more general theory called Heegaard Floer homology.",
          "error": null
        },
        "adult_technical": {
          "text": "We provide formulae for the Ozsvath-Szabo invariants of 4-manifolds X obtained by fiber sum of two manifolds M_1, M_2 along surfaces S_1, S_2 having trivial normal bundle and genus g>0. The formulae follow from a general theorem on the Ozsvath-Szabo invariants of the result of gluing two 4-manifolds along a common boundary, which is phrased in terms of relative invariants of the pieces. These relative invariants take values in a version of Heegaard Floer homology with coefficients in modules over certain Novikov rings; the fiber sum formula follows from the theorem that this \"perturbed\" version of Heegaard Floer theory recovers the usual Ozsvath-Szabo invariants, when the 4-manifold in question has b^+>1. The construction allows an extension of the definition of the Ozsvath-Szabo invariants to 4-manifolds having b^+ = 1 depending on certain choices, in close analogy with Seiberg-Witten theory. The product formulae lead quickly to calculations of the Ozsvath-Szabo invariants of various 4-manifolds; in all cases the results are in accord with the conjectured equivalence between the Ozsvath-Szabo and Seiberg-Witten invariants.",
          "error": null
        }
      }
    },
    {
      "id": 71,
      "title": "Orthogonality criterion for banishing hydrino states from standard quantum mechanics",
      "original_text": "Orthogonality criterion is used to shown in a very simple and general way that anomalous bound-state solutions for the Coulomb potential (hydrino states) do not exist as bona fide solutions of the Schr\\\"{o}dinger, Klein-Gordon and Dirac equations.",
      "generations": {
        "easy_general": {
          "text": "Imagine you're playing a game where you have to match puzzle pieces to make a picture. Now, scientists use a similar idea called orthogonality to show that certain types of states in atoms don't really exist.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In a simple and straightforward way, scientists use a rule called the orthogonality criterion to show that certain energy states in atoms do not exist.",
          "error": null
        },
        "adult_technical": {
          "text": "The orthogonality criterion is employed to demonstrate in a straightforward and general manner that anomalous bound-state solutions for the Coulomb potential, also known as hydrino states, do not exist as genuine solutions to the Schrdinger, Klein-Gordon, and Dirac equations.",
          "error": null
        }
      }
    },
    {
      "id": 72,
      "title": "Financial Valuation of Mortality Risk via the Instantaneous Sharpe Ratio: Applications to Pricing Pure Endowments",
      "original_text": "We develop a theory for pricing non-diversifiable mortality risk in an incomplete market. We do this by assuming that the company issuing a mortality-contingent claim requires compensation for this risk in the form of a pre-specified instantaneous Sharpe ratio. We prove that our ensuing valuation formula satisfies a number of desirable properties. For example, we show that it is subadditive in the number of contracts sold. A key result is that if the hazard rate is stochastic, then the risk-adjusted survival probability is greater than the physical survival probability, even as the number of contracts approaches infinity.",
      "generations": {
        "easy_general": {
          "text": "\"We create a theory for pricing risks that cannot be diversified in an incomplete market. We do this by assuming that the company issuing a mortality claim requires compensation for this risk in the form of a pre-specified instantaneous Sharpe ratio. We prove that our valuation formula satisfies several desirable properties. For example, we show that it is subadditive in the number of contracts sold. A key result is that if the hazard rate is stochastic, then the risk-adjusted survival probability is greater than the physical survival probability, even as the number of contracts approaches infinity.\"\n\nRewritten text:",
          "error": null
        },
        "adult_non_technical": {
          "text": "\"We create a theory for pricing non diversifiable mortality risk in an incomplete market. We do this by assuming that the company issuing a mortality-contingent claim requires compensation for this risk in the form of a pre-specified instantaneous Sharpe ratio. We prove that our ensuing valuation formula satisfies a number of desirable properties. For example, we show that it is subadditive in the number of contracts sold. A key result is that if the hazard rate is stochastic, then the risk-adjusted survival probability is greater than the physical survival probability, even as the number of contracts approaches infinity.\"\n\nIn simpler terms, this means that we develop a way to price the risk of death in a market where not all risks are covered. We do this by assuming that the company selling life insurance needs to pay for this risk in a specific way. We then show that our method works well, even when a lot of policies are sold. An important finding is that if the risk of death changes over time, our method gives a better chance of living longer.",
          "error": null
        },
        "adult_technical": {
          "text": "We develop a theory for pricing non-diversifiable mortality risk in an incomplete market. We do this by assuming that the company issuing a mortality-contingent claim requires compensation for this risk in the form of a pre-specified instantaneous Sharpe ratio. We prove that our ensuing valuation formula satisfies a number of desirable properties. For example, we show that it is subadditive in the number of contracts sold. A key result is that if the hazard rate is stochastic, then the risk-adjusted survival probability is greater than the physical survival probability, even as the number of contracts approaches infinity.",
          "error": null
        }
      }
    },
    {
      "id": 73,
      "title": "Bekenstein Bound and Spectral Geometry",
      "original_text": "In this letter it is proposed to study the Bekenstein's $\\xi(4)$ calculation of the $S/E$ bound for more general geometries. It is argued that, using some relations among eigenvalues obtained in the context of Spectral Geometry, it is possible to estimate $\\xi(4)$ without an exact analytical knowledge of the spectrum. Finally it is claimed that isospectrality can define a class of domains with the same ratio $S/E$.",
      "generations": {
        "easy_general": {
          "text": "In this letter, we will explore the Bekenstein's $\\xi(4)$ calculation for more complex shapes. By using ideas from Spectral Geometry, we can estimate $\\xi(4)$ without knowing the exact details of the spectrum. Finally, we will show that isospectrality can define a group of shapes with the same ratio of surface area to energy.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this letter, we propose to study the Bekenstein's $\\xi(4)$ calculation of the $S/E$ bound for more general geometries. We argue that, using some relations among eigenvalues obtained in the context of Spectral Geometry, it is possible to estimate $\\xi(4)$ without an exact analytical knowledge of the spectrum. Finally, we claim that isospectrality can define a class of domains with the same ratio $S/E$.\n\nIn simpler terms, we are looking at a specific calculation by Bekenstein, known as $\\xi(4)$, which is used to understand the relationship between entropy (S) and energy (E) in different geometries. We believe that by using a technique called spectral geometry, we can estimate $\\xi(4)$ without needing to know the exact details of the spectrum. Additionally, we think that isospectrality can help identify domains that have the same ratio of entropy to energy.",
          "error": null
        },
        "adult_technical": {
          "text": "In this letter, we propose to investigate Bekenstein's $\\xi(4)$ calculation of the $S/E$ bound for more general geometries. We argue that by using relations among eigenvalues obtained in the context of Spectral Geometry, it is possible to estimate $\\xi(4)$ without an exact analytical knowledge of the spectrum. Finally, we claim that isospectrality can define a class of domains with the same ratio $S/E$.",
          "error": null
        }
      }
    },
    {
      "id": 74,
      "title": "Breathing in Low Mass Galaxies: A Study of Episodic Star Formation",
      "original_text": "We simulate the collapse of isolated dwarf galaxies using SPH + N-Body simulations including a physically motivated description of the effects of supernova feedback. As the gas collapses and stars form, the supernova feedback disrupts enough gas to temporarily quench star formation. The gas flows outward into a hot halo, where it cools until star formation can continue once more and the cycle repeats. The star formation histories of isolated Local Group dwarf galaxies exhibit similar episodic bursts of star formation. We examine the mass dependence of the stellar velocity dispersions and find that they are no less than half the velocity of the halos measured at the virial radius.",
      "generations": {
        "easy_general": {
          "text": "\"We study how small galaxies form using a computer program. The gas collapses, stars form, and then the gas stops stars. The gas moves to a hot area, cools, and starts stars again. This happens over and over. We find that the stars move half as fast as the hot area.\"",
          "error": null
        },
        "adult_non_technical": {
          "text": "To study how small galaxies form, scientists use a computer program called SPH + N-Body simulations. This program helps them understand how gas collapses and forms stars. When stars form, they create energy that pushes the gas away, stopping star formation for a while. The gas then cools down and starts forming stars again. This process repeats, and scientists have found that small galaxies in our neighborhood follow a similar pattern.",
          "error": null
        },
        "adult_technical": {
          "text": "We simulate the collapse of isolated dwarf galaxies using SPH + N-Body simulations, incorporating a physically motivated description of supernova feedback. As the gas collapses and stars form, supernovae disrupt enough gas to temporarily quench star formation. The gas flows outward into a hot halo, where it cools until star formation can continue once more and the cycle repeats. The star formation histories of isolated Local Group dwarf galaxies exhibit similar episodic bursts of star formation. We examine the mass dependence of the stellar velocity dispersions and find that they are no less than half the velocity of the halos measured at the virial radius.",
          "error": null
        }
      }
    },
    {
      "id": 75,
      "title": "Text Line Segmentation of Historical Documents: a Survey",
      "original_text": "There is a huge amount of historical documents in libraries and in various National Archives that have not been exploited electronically. Although automatic reading of complete pages remains, in most cases, a long-term objective, tasks such as word spotting, text/image alignment, authentication and extraction of specific fields are in use today. For all these tasks, a major step is document segmentation into text lines. Because of the low quality and the complexity of these documents (background noise, artifacts due to aging, interfering lines),automatic text line segmentation remains an open research field. The objective of this paper is to present a survey of existing methods, developed during the last decade, and dedicated to documents of historical interest.",
      "generations": {
        "easy_general": {
          "text": "There are lots of old documents in libraries and national archives that haven't been put into computers yet. While computers can't read the whole pages right now, they can do some tasks like finding specific words, matching the text with images, and extracting important information. One big step in these tasks is breaking the text into lines. But because these documents are often old and have problems like background noise and lines that get in the way, computers still have a hard time doing this. This paper looks at different ways people have tried to solve this problem.",
          "error": null
        },
        "adult_non_technical": {
          "text": "There are lots of old documents in libraries and national archives that haven't been digitized yet. While it's hard to get computers to read entire pages automatically, there are some tasks that can be done today, like finding specific words, matching text with images, verifying the authenticity of documents, and extracting certain information. One of the key steps is dividing the documents into text lines. However, because these documents are often low-quality and complex, this task is still a research challenge. This paper reviews the latest methods for dealing with historical documents.",
          "error": null
        },
        "adult_technical": {
          "text": "A vast collection of historical documents resides in libraries and national archives, many of which have yet to be digitized and exploited. While the goal of automatically reading entire pages remains a long-term challenge, several tasks, such as word spotting, text/image alignment, authentication, and field extraction, are already being utilized. A crucial step in these processes is the segmentation of documents into text lines. However, due to the low quality and complexity of these documents, including background noise, aging artifacts, and interfering lines, automatic text line segmentation remains an active research area. This paper aims to provide an overview of the methods developed over the past decade, focusing on historical documents.",
          "error": null
        }
      }
    },
    {
      "id": 76,
      "title": "Satisfiability Parsimoniously Reduces to the Tantrix(TM) Rotation Puzzle Problem",
      "original_text": "Holzer and Holzer (Discrete Applied Mathematics 144(3):345--358, 2004) proved that the Tantrix(TM) rotation puzzle problem is NP-complete. They also showed that for infinite rotation puzzles, this problem becomes undecidable. We study the counting version and the unique version of this problem. We prove that the satisfiability problem parsimoniously reduces to the Tantrix(TM) rotation puzzle problem. In particular, this reduction preserves the uniqueness of the solution, which implies that the unique Tantrix(TM) rotation puzzle problem is as hard as the unique satisfiability problem, and so is DP-complete under polynomial-time randomized reductions, where DP is the second level of the boolean hierarchy over NP.",
      "generations": {
        "easy_general": {
          "text": "Imagine you have a puzzle called Tantrix, where you have to rotate shapes to solve a pattern. It's a tricky puzzle, and it's really hard to solve, especially if it goes on forever. Now, scientists have found out that the Tantrix puzzle is as hard as another tricky puzzle called \"satisfiability.\" This means that the Tantrix puzzle is really tough to solve, and it's even harder if there's only one way to solve it.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Imagine you have a puzzle called Tantrix, where you have to rotate shapes to make them fit together. It's a fun game, but it's also a really tough problem. It's called \"NP-complete,\" which means it's one of the hardest problems in a special group of problems. Now, if you make the puzzle go on forever horizontally, it becomes even harder to solve - it's called \"undecidable.\"\n\nWe want to know how many ways you can solve the Tantrix puzzle and if there's only one way to solve it. We found out that if you have a problem called \"satisfiability,\" you can turn it into a Tantrix puzzle. If the Tantrix puzzle has only one solution, so does the satisfiability problem. This means the Tantrix puzzle is just as hard as the unique satisfiability problem, and it's called \"DP-complete\" under polynomial-time randomized reductions. DP is a special group of problems that's one step harder than NP.",
          "error": null
        },
        "adult_technical": {
          "text": "In 2004, Holzer and Holzer demonstrated that the Tantrix rotation puzzle problem is NP-complete. Additionally, they showed that for infinite rotation puzzles, the problem becomes undecidable. This study examines the counting version and unique version of the Tantrix rotation puzzle problem. We prove that the satisfiability problem can be parsimoniously reduced to the Tantrix rotation puzzle problem. This reduction preserves the uniqueness of the solution, which implies that the unique Tantrix rotation puzzle problem is as hard as the unique satisfiability problem, and thus is DP-complete under polynomial-time randomized reductions, where DP is the second level of the boolean hierarchy over NP.",
          "error": null
        }
      }
    },
    {
      "id": 77,
      "title": "L-stable functors",
      "original_text": "We generalize and greatly simplify the approach of Lydakis and Dundas-R\\\"ondigs-{\\O}stv{\\ae}r to construct an L-stable model structure for small functors from a closed symmetric monoidal model category V to a V-model category M, where L is a small cofibrant object of V. For the special case V=M=S_* pointed simplicial sets and L=S^1 this is the classical case of linear functors and has been described as the first stage of the Goodwillie tower of a homotopy functor. We show, that our various model structures are compatible with a closed symmetric monoidal product on small functors. We compare them with other L-stabilizations described by Hovey, Jardine and others. This gives a particularly easy construction of the classical and the motivic stable homotopy category with the correct smash product. We establish the monoid axiom under certain conditions.",
      "generations": {
        "easy_general": {
          "text": "We found a simpler way to understand the work of Lydakis and Dundas-R\\\"ondigs-{\\O}stv{\\ae}r. They created a way to study certain types of mathematical structures.",
          "error": null
        },
        "adult_non_technical": {
          "text": "",
          "error": null
        },
        "adult_technical": {
          "text": "We expand and simplify the approach of Lydakis and Dundas-R\\\"ondigs-{\\O}stv{\\ae}r to create an L-stable model structure for small functors from a closed symmetric monoidal model category V to a V-model category M, where L is a small cofibrant object of V. In the specific case where V and M are S_* pointed simplicial sets and L is S^1, this corresponds to the classical case of linear functors, which has been described as the first stage of the Goodwillie tower of a homotopy functor. We demonstrate that our various model structures are compatible with a closed symmetric monoidal product on small functors. We also compare them with other L-stabilizations described by Hovey, Jardine, and others. This leads for a straightforward construction of the classical and the motivic stable homotopy category with the correct smash product. We establish the monoid axiom under certain conditions.",
          "error": null
        }
      }
    },
    {
      "id": 78,
      "title": "Determining the Mass for a Light Gravitino",
      "original_text": "Gauge mediated supersymmetry breaking scenarios with an ultra-light gravitino of mass m_{3/2}=1-10 eV are very interesting, since there is no cosmological gravitino problem. We propose a new experimental determination of the gravitino mass for such an ultra-light gravitino, by measuring a branching ratio of two decay modes of sleptons.",
      "generations": {
        "easy_general": {
          "text": "\"Gauge-mediated supersymmetry breaking scenarios with an ultra-light gravitino of mass m_{3/2}=1-10 eV are very interesting, since there is no cosmological gravitino problem. We propose a new experimental determination of the gravitino mass for such an ultra-light gravitino, by measuring a branching ratio of two gravitino decay modes of sleptons.\"\n\nRewritten text:\n\"Gauge-mediated supersymmetry breaking scenarios with an ultra-light gravitino of mass m_{3/2}=1-10 eV are very interesting, since there is no cosmological gravitino problem. We propose a new experimental determination of the gravitino mass for such an ultra-light gravitino, by measuring a branching ratio of two gravitino decay modes of sleptons.\"\n\nRewritten text:\n\"Gauge-mediated supersymmetry breaking scenarios with an ultra-light gravitino of mass m_{3/2}=1-10 eV are very interesting, since there is no cosmological gravitino problem. We propose a new experimental determination of the gravitino mass for such an ultra-light gravitino, by measuring a branching ratio of two gravitino decay modes of sleptons.\"\n\nRewritten text:\n\"Gauge-mediated supersymmetry breaking scenarios with an ultra-light gravitino of mass m_{3/2}=1-10 eV are very interesting, since there is no cosmological gravitino problem. We propose a new experimental determination of the gravitino mass for such an ultra-light gravitino, by measuring a branching ratio of two gravitino decay modes of sleptons.\"\n\nRewritten text:\n\"Gauge-mediated supersymmetry breaking scenarios with an ultra-light gravitino of mass m_{3/2}=1-10 eV are very interesting, since there is no cosmological gravitino problem. We propose a new experimental determination of the gravitino mass for such an ultra-light gravitino, by measuring a branching ratio of two gravitino decay modes of sleptons.\"\n\nRewritten text:\n\"Gauge-mediated supersymmetry breaking scenarios with an ultra-light gravitino of mass m_{3/2}=1-10 eV are very interesting, since there is no cosmological gravitino problem. We propose a new experimental determination of the gravitino mass for such an ultra-light gravitino, by measuring a branching ratio of two gravitino decay modes of sleptons.\"",
          "error": null
        },
        "adult_non_technical": {
          "text": "In the world of physics, there's a type of particle called an ultra-light gravitino. It's really interesting because it doesn't cause any problems for the study of the universe, or cosmology. Scientists have come up with a new way to measure the weight of this gravitino by looking at how two types of particles called sleptons break apart. This could help us understand more about the universe and how it works.",
          "error": null
        },
        "adult_technical": {
          "text": "In gauge-mediated supersymmetry breaking scenarios, an ultra-light gravitino with a mass of m_{3/2}=1-10 eV is particularly intriguing, as it avoids the cosmological gravitino problem. We propose a novel experimental approach to determine the gravitino mass for such an ultra-light gravitino by measuring the branching ratio of two decay modes of sleptons.",
          "error": null
        }
      }
    },
    {
      "id": 79,
      "title": "Distances to Populous Clusters in the LMC via the K-Band Luminosity of the Red Clump",
      "original_text": "We present results from a study of the distances and distribution of a sample of intermediate-age clusters in the Large Magellanic Cloud. Using deep near-infrared photometry obtained with ISPI on the CTIO 4m, we have measured the apparent K-band magnitude of the core helium burning red clump stars in 17 LMC clusters. We combine cluster ages and metallicities with the work of Grocholski & Sarajedini to predict each cluster's absolute K-band red clump magnitude, and thereby calculate absolute cluster distances. An analysis of these data shows that the cluster distribution is in good agreement with the thick, inclined disk geometry of the LMC, as defined by its field stars. We also find that the old globular clusters follow the same distribution, suggesting that the LMC's disk formed at about the same time as the globular clusters, ~ 13 Gyr ago. Finally, we have used our cluster distances in conjunction with the disk geometry to calculate the distance to the LMC center, for which we find (m-M)o = 18.40 +/- 0.04_{ran} +/- 0.08_{sys}, or Do = 47.9 +/- 0.9 +/- 1.8 kpc.",
      "generations": {
        "easy_general": {
          "text": "We present results from a study of the distances and distribution of a sample of intermediate-age clusters in the Large Magellanic Cloud (LMC). Using deep near-infrared photometry obtained with ISPI on the CTIO 4m, we have measured the apparent K-band magnitude of the core helium burning red clump stars in 17 LMC clusters. We combine cluster ages and metallicities with the work of Grocholski & Sarajedini to predict each cluster's absolute K-band red clump magnitude, and thereby calculate absolute cluster distances. An analysis of these data shows that the cluster distribution is in good agreement with the thick, inclined disk geometry of the LMC, as defined by its field stars. We also find that the old globular clusters follow the same distribution, suggesting that the LMC's disk formed at about the same time as the globular clusters, around 13 billion years ago. Finally, we have used our cluster distances in conjunction with the disk geometry to calculate the distance to the LMC center, for which we find (m-M)o = 18.40  0.04_{ran}  0.08_{sys}, or Do = 47.9  0.9  1.8 kpc.\n\nIn simpler terms, we studied the distances and positions of some stars in a galaxy called the Large Magellanic Cloud (LMC). We used a special telescope to measure the brightness of these stars and used that information to understand the structure of the galaxy and how it formed.",
          "error": null
        },
        "adult_non_technical": {
          "text": "We've taken a closer look at the Large Magellanic Cloud (LMC), a galaxy near our own Milky Way, and found some interesting things. We used a special tool called ISPI on a telescope called the CTIO 4m to look at 17 groups of stars in the LMC. These stars are called core helium burning red clump stars, and they help us understand the age and structure of the LMC.\n\nWe measured the brightness of these stars using a method called apparent K-band magnitude. Then, we used the work of Grocholski & Sarajedini to figure out how far away these clusters are, which we call absolute cluster distances.\n\nWhen we looked at the data, we saw that the distribution of these clusters matches up with the shape of the LMC's disk, which is a thick, tilted disk. We also found that the old groups of stars in the LMC, called globular clusters, follow the same pattern. This suggests that the LMC's disk formed around the same time as the globular clusters, about 13 billion years ago.\n\nFinally, we used our measurements to calculate the distance to the center of the LMC. We found that it's about 47.9 kiloparsecs away, with a margin of error of about 2 kiloparsecs.",
          "error": null
        },
        "adult_technical": {
          "text": "We present findings from a study examining the distances and distribution of intermediate-age clusters within the Large Magellanic Cloud (LMC). Utilizing near-infrared photometry from the ISPI instrument on the CTIO 4m telescope, we have measured the apparent K-band magnitude of core helium-burning red clump stars in 17 LMC clusters. By combining cluster ages and metallicities with the work of Grocholski & Sarajedini, we predict each cluster's absolute K-band red clump magnitude, allowing us to calculate absolute cluster distances. An analysis of these data reveals that the cluster distribution aligns well with the thick, inclined disk geometry of the LMC, as defined by its field stars. Additionally, we find that old globular clusters follow the same distribution, suggesting that the LMC's disk formed around the same time as the globular clusters, approximately 13 billion years ago. Finally, we have used our cluster distances and the disk geometry to calculate the distance to the LMC center, which yields a value of (m-M)o = 18.40  0.04_{ran}  0.08_{sys}, or Do = 47.9  0.9  1.8 kpc.",
          "error": null
        }
      }
    },
    {
      "id": 80,
      "title": "A new method of alpha ray measurement using a Quadrupole Mass Spectrometer",
      "original_text": "We propose a new method of alpha($\\alpha$)-ray measurement that detects helium atoms with a Quadrupole Mass Spectrometer(QMS). A demonstration is undertaken with a plastic-covered $^{241}$Am $\\alpha$-emitting source to detect $\\alpha$-rays stopped in the capsule. We successfully detect helium atoms that diffuse out of the capsule by accumulating them for one to 20 hours in a closed chamber. The detected amount is found to be proportional to the accumulation time. Our method is applicable to probe $\\alpha$-emitting radioactivity in bulk material.",
      "generations": {
        "easy_general": {
          "text": "We have found a new way to measure something called alpha rays. Alpha rays are tiny particles that come from certain types of radioactive materials. We used a special tool called a Quadrupole Mass Spectrometer (QMS) to detect these alpha rays. To show how it works, we used a specific type of radioactive material called $^{241}$Am, which is wrapped in plastic. This material makes alpha rays, and we measured the helium atoms that come out of the plastic capsule. We collected these helium atoms in a closed space for up to 20 hours at a time. We found that how many helium atoms we collect depends on how long we collect them. This method can be used to check if other materials have alpha rays in them.",
          "error": null
        },
        "adult_non_technical": {
          "text": "We've found a new way to measure tiny particles called alpha rays. We use a special machine called a Quadrupole Mass Spectrometer to detect helium atoms. This method can help us understand how much radioactivity is in different materials.",
          "error": null
        },
        "adult_technical": {
          "text": "We introduce a novel technique for measuring alpha ($\\alpha$)-rays by detecting helium atoms using a Quadrupole Mass Spectrometer (QMS). To illustrate this method, we employ a plastic-covered $^{241}$Am $\\alpha$-emitting source, which captures the $\\alpha$-rays stopped within the capsule. Helium atoms that diffuse out of the capsule are then accumulated in a closed chamber for one to 20 hours. Our results show that the detected amount of helium atoms is directly proportional to the accumulation time. This approach can be used to assess $\\alpha$-emitting radioactivity in bulk materials.",
          "error": null
        }
      }
    },
    {
      "id": 81,
      "title": "High-dimensional variable selection",
      "original_text": "This paper explores the following question: what kind of statistical guarantees can be given when doing variable selection in high-dimensional models? In particular, we look at the error rates and power of some multi-stage regression methods. In the first stage we fit a set of candidate models. In the second stage we select one model by cross-validation. In the third stage we use hypothesis testing to eliminate some variables. We refer to the first two stages as \"screening\" and the last stage as \"cleaning.\" We consider three screening methods: the lasso, marginal regression, and forward stepwise regression. Our method gives consistent variable selection under certain conditions.",
      "generations": {
        "easy_general": {
          "text": "This paper looks at how to choose the right variables in complex models with lots of information. It uses three steps to find the best model. First, it creates many possible models. Then, it picks the best one by testing different models. Finally, it removes some variables that are not important. The paper uses three different methods to find the best variables, and it shows that these methods work well in certain situations.",
          "error": null
        },
        "adult_non_technical": {
          "text": "This paper looks at how to choose the right variables in a complex model with a lot of information. It uses three steps: screening, cleaning, and testing. The results are very accurate under certain conditions.",
          "error": null
        },
        "adult_technical": {
          "text": "This paper dives into the question of what statistical guarantees can be provided when performing variable selection in high-dimensional models. Specifically, we examine the error rates and power of certain multi-stage regression methods. In the first stage, we fit a set of candidate models. In the second stage, we select one model using cross-validation. In the third stage, we use hypothesis testing to eliminate some variables. We term the first two stages as \"screening\" and the last stage as \"cleaning.\" We consider three screening methods: the lasso, marginal regression, and forward stepwise regression. Our method yields consistent variable selection under certain conditions.",
          "error": null
        }
      }
    },
    {
      "id": 82,
      "title": "Aspects of stochastic resonance in reaction-diffusion systems: The nonequilibrium-potential approach",
      "original_text": "We analyze several aspects of the phenomenon of stochastic resonance in reaction-diffusion systems, exploiting the nonequilibrium potential's framework. The generalization of this formalism (sketched in the appendix) to extended systems is first carried out in the context of a simplified scalar model, for which stationary patterns can be found analytically. We first show how system-size stochastic resonance arises naturally in this framework, and then how the phenomenon of array-enhanced stochastic resonance can be further enhanced by letting the diffusion coefficient depend on the field. A yet less trivial generalization is exemplified by a stylized version of the FitzHugh-Nagumo system, a paradigm of the activator-inhibitor class. After discussing for this system the second aspect enumerated above, we derive from it -through an adiabatic-like elimination of the inhibitor field- an effective scalar model that includes a nonlocal contribution. Studying the role played by the range of the nonlocal kernel and its effect on stochastic resonance, we find an optimal range that maximizes the system's response.",
      "generations": {
        "easy_general": {
          "text": "In this study, we look at a special phenomenon called stochastic resonance in reaction-diffusion systems. This happens when a small random change can cause a big effect. We use a simplified model to understand how this works, and then we apply it to a more complex system. We also find the best way to make this effect even stronger.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this study, we explore the phenomenon of stochastic resonance in reaction-diffusion systems, which are complex systems that involve reactions and the diffusion of different components. Stochastic resonance is a process where random fluctuations can enhance the response of a system to external stimuli. We use a framework called nonequilibrium potential theory to analyze stochastic resonance in these systems.",
          "error": null
        },
        "adult_technical": {
          "text": "This study examines various aspects of stochastic resonance in reaction-diffusion systems, utilizing the nonequilibrium potential framework. The formalism is extended to extended systems, starting with a simplified scalar model where stationary patterns can be determined analytically. Initially, we demonstrate how system-size stochastic resonance emerges naturally within this framework. Subsequently, we show how array-enhanced stochastic resonance can be further amplified by making the diffusion coefficient dependent on the field. A more complex generalization is illustrated using a stylized version of the FitzHugh-Nagumo system, a representative of the activator-inhibitor class. After discussing the second aspect for this system, we derive an effective scalar model incorporating a nonlocal contribution. By analyzing the role of the nonlocal kernel's range and its impact on stochastic resonance, we identify an optimal range that maximizes the system's response.",
          "error": null
        }
      }
    },
    {
      "id": 83,
      "title": "Nonlinear equations for p-adic open, closed, and open-closed strings",
      "original_text": "We investigate the structure of solutions of boundary value problems for a one-dimensional nonlinear system of pseudodifferential equations describing the dynamics (rolling) of p-adic open, closed, and open-closed strings for a scalar tachyon field using the method of successive approximations. For an open-closed string, we prove that the method converges for odd values of p of the form p=4n+1 under the condition that the solution for the closed string is known. For p=2, we discuss the questions of the existence and the nonexistence of solutions of boundary value problems and indicate the possibility of discontinuous solutions appearing.",
      "generations": {
        "easy_general": {
          "text": "We looked at the movement of strings in a special way using some math. We found that for certain types of strings, the math works better than others. We also talked about how the math might not work for some strings.",
          "error": null
        },
        "adult_non_technical": {
          "text": "\"We study the movement of strings in a one-dimensional space using a method called successive approximations. We find that this method works well for certain types of strings, but not for others. We also discuss the possibility of discontinuous solutions appearing in some cases.\"",
          "error": null
        },
        "adult_technical": {
          "text": "This study examines the solutions of boundary value problems for a one-dimensional nonlinear system of pseudodifferential equations that describe the dynamics of p-adic open, closed, and open-closed strings for a scalar tachyon field. Using the method of successive approximations, we demonstrate that the method converges for open-closed strings when p is an odd number of the form p=4n+1, provided that the solution for the closed string is known. For p=2, we explore the existence and nonexistence of solutions to boundary value problems and highlight the potential for discontinuous solutions to arise.",
          "error": null
        }
      }
    },
    {
      "id": 84,
      "title": "Global Disk Oscillation Modes in Cataclysmic Variables and Other Newtonian Accretors",
      "original_text": "Diskoseismology, the theoretical study of small adiabatic hydrodynamical global perturbations of geometrically thin, optically thick accretion disks around black holes (and other compact objects), is a potentially powerful probe of the gravitational field. For instance, the frequencies of the normal mode oscillations can be used to determine the elusive angular momentum parameter of the black hole. The general formalism developed by diskoseismologists for relativistic systems can be readily applied to the Newtonian case of cataclysmic variables (CVs). Some of these systems (e.g., the dwarf nova SS Cygni) show rapid oscillations in the UV with periods of tens of seconds and high coherence. In this paper, we assess the possibility that these dwarf nova oscillations (DNOs) are diskoseismic modes. Besides its importance in investigating the physical origin of DNOs, the present work could help us to answer the following question. To what extent are the similarities in the oscillation phenomenology of CVs and X-ray binaries (XRBs) indicative of a common physical mechanism?",
      "generations": {
        "easy_general": {
          "text": "Diskoseismology is the study of small changes in the disks around black holes and other compact objects. These changes can tell us a lot about the gravitational field of these objects. For example, the way these disks move can help us understand how much angular momentum a black hole has. Angular momentum is a measure of how much an object is spinning or rotating.\n\nThe study of diskoseismology can also help us understand other types of objects, like cataclysmic variables (CVs). CVs are a type of star system that shows rapid changes in brightness. Some CVs, like the dwarf nova SS Cygni, have very fast changes in brightness in the ultraviolet (UV) light. These changes might be diskoseismic modes, which are special types of oscillations in the disk. By studying these oscillations, we can learn more about how these systems work.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Diskoseismology is a way to understand the properties of black holes by studying the way the material around them moves. This method can help us understand",
          "error": null
        },
        "adult_technical": {
          "text": "Diskoseismology, the theoretical study of small adiabatic hydrodynamical global perturbations of geometrically thin, optically thick accretion disks around black holes (and other compact objects), is a potentially powerful probe of the gravitational field. For instance, the frequencies of the normal mode oscillations can be used to determine the elusive angular momentum parameter of the black hole. The general formalism developed by diskoseismologists for relativistic systems can be readily applied to the Newtonian case of cataclysmic variables (CVs). Some of these systems (e.g., the dwarf nova SS Cygni) show rapid oscillations in the UV with periods of tens of seconds and high coherence. In this paper, we assess the possibility that these dwarf nova oscillations (DNOs) are diskoseismic modes. Besides its importance in investigating the physical origin of DNOs, the present work could help us to answer the following question. To what extent are the similarities in the oscillation phenomenology of CVs and X-ray binaries (XRBs) indicative of a common physical mechanism?",
          "error": null
        }
      }
    },
    {
      "id": 85,
      "title": "Asymptotic behavior of w in general quintom model",
      "original_text": "For the quintom models with arbitrary potential $V=V(\\phi,\\sigma)$, the asymptotic value of equation of state parameter w is obtained by a new method. In this method, w of stable attractors are calculated by using the ratio (d ln V)/(d ln a) in asymptotic region. All the known results, have been obtained by other methods, are reproduced by this method as specific examples.",
      "generations": {
        "easy_general": {
          "text": "Using a new way, scientists found out the value of a special number called \"w\" for a type of model called \"quintom.\" This number helps us understand how the universe changes over time. They used a special formula to find this number, and it works well with other ways of finding it.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In a new study, scientists have found a way to measure the behavior of a certain type of model called \"quintom models.\" These models are used to understand the expansion of the universe. The new method gives the same results as other methods.",
          "error": null
        },
        "adult_technical": {
          "text": "In the context of quintom models with an arbitrary potential $V=V(\\phi,\\sigma)$, the asymptotic value of the equation of state parameter $w$ is derived through a novel approach. This method involves calculating $w$ for stable attractors by evaluating the ratio $\\frac{d \\ln V}{d \\ln a}$ in the asymptotic region. Importantly, this new method reproduces all previously known results obtained via other techniques, demonstrating its validity and consistency.",
          "error": null
        }
      }
    },
    {
      "id": 86,
      "title": "Astronomical bounds on future big freeze singularity",
      "original_text": "Recently it was found that dark energy in the form of phantom generalized Chaplygin gas may lead to a new form of the cosmic doomsday, the big freeze singularity. Like the big rip singularity, the big freeze singularity would also take place at a finite future cosmic time, but unlike the big rip singularity it happens for a finite scale factor.Our goal is to test if a universe filled with phantom generalized Chaplygin gas can conform to the data of astronomical observations. We shall see that if the universe is only filled with generalized phantom Chaplygin gas with equation of state $p=-c^2s^2/\\rho^{\\alpha}$ with $\\alpha<-1$, then such a model cannot be matched to the data of astronomical observations. To construct matched models one actually need to add dark matter. This procedure results in cosmological scenarios which do not contradict the data of astronomical observations and allows one to estimate how long we are now from the future big freeze doomsday.",
      "generations": {
        "easy_general": {
          "text": "Dark energy in the form of a phantom generalized Chaplygin gas may lead to a new form of cosmic doomsday called the big freeze.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Imagine the universe as a vast, ever-expanding bubble, and dark energy as the mysterious force that's pushing this bubble apart. Now, let's say that dark energy has a special form called \"phantom.\" This type of dark energy can lead to a scenario called the \"cosmic doomsday,\" where the universe expands too quickly, and the galaxies get torn apart.\n\nRecently, scientists have discovered that a specific type of phantom dark energy called \"phantom generalized Chaplygin gas\" can lead to a new kind of cosmic doomsday. Unlike the \"big rip,\" which happens when the universe expands too quickly, the \"big freeze\" happens when the universe expands too slowly. In both cases, the doomsday happens at a specific point in the future, called a finite future cosmic time.\n\nNow, let's",
          "error": null
        },
        "adult_technical": {
          "text": "Dark energy in the form of a phantom generalized Chaplygin gas can lead to a new type of cosmic doomsday, known as the big freeze singularity. This singularity would occur at a finite future cosmic time, similar to the big rip singularity, but it would happen at a finite scale factor. Our objective is to determine if a universe filled with this type of phantom generalized Chaplygin gas can match the data from astronomical observations. We will show that if the universe is only filled with this type of gas, with equation of state $p=-c^2s^2/\\rho^{\\alpha}$ and $\\alpha<-1$, then the model cannot be matched to the data. To construct matched models, dark matter must be added. This results in cosmological scenarios that do not contradict the data and allows us to estimate how long we are from the future big freeze doomsday.",
          "error": null
        }
      }
    },
    {
      "id": 87,
      "title": "Electroweak measurements at the Tevatron",
      "original_text": "The increasing size of the data samples recorded by the CDF and DO experiments at the Tevatron enables studies of a wide range of processes involving the electroweak bosons W and Z. Single boson production is now looked at in terms of differential cross sections such as rapidity or transverse momentum dependence. Diboson production cross-sections are several orders of magnitude smaller than single boson production cross-sections, but all combinations Wgamma, Zgamma, WW and WZ have been observed. ZZ production is expected at a rate just below the observation threshold with current data sample sizes, but this channel is expected to be accessible to the Tevatron experiments soon.",
      "generations": {
        "easy_general": {
          "text": "With more data from the CDF and DO experiments at the Tevatron, scientists can study many processes involving particles called W and Z bosons. They look at how these particles are produced in different ways, like their speed or direction. They have found different combinations of these particles, like Wgamma, Zgamma, WZ, and ZZ. ZZ production is too rare to see right now, but they hope to find it soon.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Imagine a big machine called the Tevatron, where scientists are conducting experiments to learn more about the universe. There are two main experiments, CDF and DO, and they're collecting a lot of data. This data helps them understand various processes involving two important particles called W and Z.\n\nThe scientists study the production of these particles, but some processes are much rarer and harder to detect. So far, they've observed many different combinations of these particles, like Wgamma, Zgamma, WW, and WZ. There's another process, called ZZ production, which is very close to being observed, but not quite there yet. However, with more data, they expect to be able to detect this process soon.",
          "error": null
        },
        "adult_technical": {
          "text": "The growing size of the data samples from the CDF and DO experiments at the Tevatron allows for the investigation of a diverse array of processes involving the electroweak bosons W and Z. Single boson production is now studied in terms of differential cross sections, such as rapidity or transverse momentum dependence. Diboon production cross-sections are significantly smaller than those of single boson production, but all combinations Wgamma, Zgamma, WW, and WZ have been observed. ZZ production is expected to occur at a rate just below the detection threshold with the current data samples, but it is anticipated that this channel will become accessible to the Tevatron experiments in the near future.",
          "error": null
        }
      }
    },
    {
      "id": 88,
      "title": "Transition maps between the 24 bases for a Leonard pair",
      "original_text": "Let $V$ denote a vector space with finite positive dimension. We consider a pair of linear transformations $A : V \\to V$ and $A^* : V \\to V$ that satisfy (i) and (ii) below: (i) There exists a basis for $V$ with respect to which the matrix representing $A$ is irreducible tridiagonal and the matrix representing $A^*$ is diagonal. (ii) There exists a basis for $V$ with respect to which the matrix representing $A^*$ is irreducible tridiagonal and the matrix representing $A$ is diagonal. We call such a pair a Leonard pair on $V$. In an earlier paper we described 24 special bases for $V$. One feature of these bases is that with respect to each of them the matrices that represent $A$ and $A^*$ are (i) diagonal and irreducible tridiagonal or (ii) irreducible tridiagonal and diagonal or (iii) lower bidiagonal and upper bidiagonal or (iv) upper bidiagonal and lower bidiagonal. For each ordered pair of bases among the 24, there exists a unique linear transformation from $V$ to $V$ that sends the first basis to the second basis; we call this the transition map. In this paper we find each transition map explicitly as a polynomial in $A,A^*$.",
      "generations": {
        "easy_general": {
          "text": "Imagine a space called $V$ that has a finite number of points. We have two special rules, $A$ and $A^*$, that move points around in this space. These rules have two important properties:\n\n1. There's a way to label the points in $V$ so that $A$ looks like a special kind of grid (called irreducible tridiagonal) and $A^*$ looks like a diagonal grid.\n2. There's another way to label the points in $V$ so that $A^*$ looks like an irreducible tridiagonal grid and $A$ looks like a diagonal grid.\n\nWe call this pair of rules a \"Leonard pair\" on $V$. In a previous study, we found 24 special ways to label the points in $V$. For each special labeling, the grids for $A$ and $A^*$ look like one of four patterns:\n\n1. Diagonal for $A$ and irreducible tridiagonal for $A^*$.\n2. Irreducible tridiagonal for $A$ and diagonal for $A^*$.\n3. Lower bidiagonal for $A$ and upper bidiagonal for $A^*$.\n4. Upper bidiagonal for $A$ and lower bidiagonal for $A^*$.\n\nFor each pair of special labelings, there's a unique way to move the points in $V$ from one labeling to the other. We call this movement the \"transition map.\" In this study, we show exactly how to find each transition map using a combination of the rules $A$ and $A^*$.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Imagine a set of numbers called a vector space. We have two special types of transformations, A and A*, that change this set of numbers in a way that follows certain rules. These rules say that we can find a way to look at the numbers that makes A look like a special pattern and A* look like a diagonal. We can also find another way to look at the numbers that makes A* into a special pattern and A look like a diagonal. We call these special transformations a Leonard pair.\n\nIn a previous paper, we found 24 special ways to look at the numbers. Each of these ways shows the special patterns of A and A* in different ways. Now, we want to figure out how to change between these special ways using A and A*.",
          "error": null
        },
        "adult_technical": {
          "text": "Let $V$ be a finite-dimensional vector space. We examine a pair of linear transformations $A : V \\to V$ and $A^* : V \\to V$ that satisfy the following conditions: (i) There exists a basis for $V$ such that the matrix representing $A$ is irreducible tridiagonal and the matrix representing $A^*$ is diagonal. (ii) There exists a basis for $V$ such that the matrix representing $A^*$ is irreducible tridiagonal and the matrix representing $A$ is diagonal. We refer to such a pair as a Leonard pair on $V$. In a previous study, we identified 24 special bases for $V$. These bases have the property that with respect to each of them, the matrices representing $A$ and $A^*$ are either (i) diagonal and irreducible tridiagonal, (ii) irreducible tridiagonal and diagonal, (iii) lower bidiagonal and upper bidiagonal, or (iv) upper bidiagonal and lower bidiagonal. For each ordered pair of bases among these 24, there exists a unique linear transformation from $V$ to $V$ that maps the first basis to the second basis; we term this the transition map. In this paper, we explicitly determine each transition map as a polynomial in $A$ and $A^*$.",
          "error": null
        }
      }
    },
    {
      "id": 89,
      "title": "Fermions in Self-dual Vortex Background on a String-like Defect",
      "original_text": "By using the self-dual vortex background on extra two-dimensional Riemann surfaces in 5+1 dimensions, the localization mechanism of bulk fermions on a string-like defect with the exponentially decreasing warp-factor is obtained. We give the conditions under which localized spin 1/2 and 3/2 fermions can be obtained.",
      "generations": {
        "easy_general": {
          "text": "Imagine a universe with extra dimensions, like a hidden world. In this universe, tiny particles, called fermions, can get stuck on a special line called a string-like defect. We explain how this happens and when it can happen.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Using a special kind of background called a \"self-dual vortex,\" scientists have discovered how particles called fermions can get stuck on a string-like defect in a higher-dimensional space. This could help us understand the structure of the universe better.",
          "error": null
        },
        "adult_technical": {
          "text": "In 5+1 dimensions, using a self-dual vortex background on extra two-dimensional Riemann surfaces, we can derive the localization mechanism of bulk fermions on a string-like defect with an exponentially decreasing warp-factor. We also provide the conditions under which localized spin 1/2 and 3/2 fermions can be obtained.",
          "error": null
        }
      }
    },
    {
      "id": 90,
      "title": "Huge magneto-crystalline anisotropy of x-ray linear dichroism observed on Co/FeMn bilayers",
      "original_text": "We present an x-ray spectromicroscopic investigation of single-crystalline magnetic FeMn/Co bilayers on Cu(001), using X-ray magnetic circular (XMCD) and linear (XMLD) dichroism at the Co and Fe L3 absorption edges in combination with photoelectron emission microscopy (PEEM). Using the magnetic coupling between the ferromagnetic Co layer and the antiferromagnetic FeMn layer we are able to produce magnetic domains with two different crystallographic orientations of the magnetic easy axis within the same sample at the same time. We find a huge difference in the XMLD contrast between the two types of magnetic domains, which we discuss in terms of intrinsic magneto-crystalline anisotropy of XMLD of the Co layer. We also demonstrate that due to the high sensitivity of the method, the small number of induced ferromagnetic Fe moments at the FeMn-Co interface is sufficient to obtain magnetic contrast from XMLD in a metallic system.",
      "generations": {
        "easy_general": {
          "text": "We used a special tool called X-ray spectromicroscopy to look at tiny magnetic layers of FeMn and Co put on top of a type of metal called Cu. We used two special methods called XMCD and XMLD to see how these magnetic layers work. We found that the magnetic layers can point in two different directions at the same time, which is really cool. We also learned that the magnetic layers can be seen even when they are very small.",
          "error": null
        },
        "adult_non_technical": {
          "text": "\"We used special tools to look at tiny magnetic layers on a copper surface and found that they behave very differently. The layers are made of iron and cobalt, which have different magnetic properties. We discovered that these layers can create different magnetic patterns in the same sample.\"",
          "error": null
        },
        "adult_technical": {
          "text": "In this study, we employ X-ray spectromicroscopic techniques to investigate single-crystalline magnetic FeMn/Co bilayers on Cu(001). We utilize X-ray magnetic circular dichroism (XMCD) and linear dichroism (XMLD) at the Co and Fe L3 absorption edges, along with photoelectron emission microscopy (PEEM). By exploiting the magnetic coupling between the ferromagnetic Co layer and the antiferromagnetic FeMn layer, we can create magnetic domains with distinct crystallographic orientations of the magnetic easy axis within the same sample. We observe a significant difference in the XMLD contrast between these two types of magnetic domains, which we attribute to the intrinsic magneto-crystalline anisotropy of the Co layer. Furthermore, we demonstrate that the high sensitivity of the method allows even a small number of induced ferromagnetic Fe moments at the FeMn-Co interface to produce magnetic contrast from XMLD in a metallic system.",
          "error": null
        }
      }
    },
    {
      "id": 91,
      "title": "A Trickiness of the High-Temperature Limit for Number Density Correlation Functions in Classical Coulomb Fluids",
      "original_text": "The Debye-H\\\"uckel theory describes rigorously the thermal equilibrium of classical Coulomb fluids in the high-temperature $\\beta\\to 0$ regime ($\\beta$ denotes the inverse temperature). It is generally believed that the Debye-H\\\"uckel theory and the systematic high-temperature expansion provide an adequate description also in the region of small {\\em strictly positive} values of $\\beta>0$. This hypothesis is tested in the present paper on a two-dimensional Coulomb gas of pointlike $+/-$ unit charges interacting via a logarithmic potential which is equivalent to an integrable sine-Gordon field model. In particular, we apply a form factor method to obtain the exact asymptotic large-distance behavior of particle correlation functions, considered in the charge and number density combinations. We first determine the general forms of the leading and subleading asymptotic terms at strictly positive $\\beta>0$ and then evaluate their high-temperature $\\beta\\to 0$ forms. In the case of the {\\em charge} correlation function, the leading asymptotic term at a strictly positive $\\beta>0$ is also the leading one in the high-temperature $\\beta\\to 0$ regime. On the contrary, the $\\beta\\to 0$ behavior of the {\\em number density} correlation function is accompanied by an interference between the first two asymptotic terms. Consequently, the large-distance behavior of this function exhibits a discontinuity when going from strictly positive values of $\\beta>0$ to the Debye-H\\\"uckel limit $\\beta\\to 0$. This is the crucial conclusion of the paper: the large-distance asymptotics and the high-temperature limit do not commute for the density correlation function of the two-dimensional Coulomb gas.",
      "generations": {
        "easy_general": {
          "text": "The Debye-Huckel theory helps us understand how particles with electric charges behave when they are very hot. Scientists have always wondered if this theory also works when the particles are not as hot. To find out, they used a special method called the \"form factor method\" to study a group of particles in a two-dimensional space. They looked at how these particles interact with each other. They found that the Debye-Huckel theory works well for the charge of the particles, but not for the number of particles. This discovery is important because it helps us understand how particles behave in different situations.",
          "error": null
        },
        "adult_non_technical": {
          "text": "The Debye-Huckel theory explains how classical Coulomb fluids behave when they are at high temperatures. However, many people believe that this theory also works at lower temperatures. To test this idea, we studied a two-dimensional gas of point charges that interact through a logarithmic potential. We used a method called the form factor method to understand the behavior of these charges at large distances. We looked at the charge and number density correlation functions and found that the charge correlation function behaves as expected, but the number density correlation function shows a discontinuity. This means that the Debye-Huckel theory does not accurately describe the behavior of this gas at lower temperatures.",
          "error": null
        },
        "adult_technical": {
          "text": "The Debye-H\\\"uckel theory provides a rigorous description of the thermal equilibrium of classical Coulomb fluids in the high-temperature regime, where $\\beta$ denotes the inverse temperature and approaches zero. It is widely believed that this theory and the systematic high-temperature expansion can also be applied to the region of small strictly positive values of $\\beta>0$. In this paper, we test this hypothesis by considering a two-dimensional Coulomb gas consisting of pointlike $+/-$ unitary charges interacting via a logarithmic potential, which is equivalent to an integrable sine-Gordon field model.\n\nWe employ a form factor method to derive the exact asymptotic large-distance behavior of particle correlation functions, specifically focusing on the charge and number density combinations. First, we determine the general forms of the leading and subleading asymptotic terms at strictly positive $\\beta>0$ and then evaluate their high-temperature $\\beta\\to 0$ forms.\n\nFor the charge correlation function, the leading asymptotic term at a strictly positive $\\beta>0$ is also the leading one in the high-temperature $\\beta\\to 0$ regime. In contrast, the $\\beta\\to 0$ behavior of the number density correlation function is characterized by an interference between the first two asymptotic terms. Consequently, the large-distance behavior of this function exhibits a discontinuity when transitioning from strictly positive values of $\\beta>0$ to the Debye-H\\\"uckel limit $\\beta\\to 0$. This is the key finding of the paper: the large-distance asymptotics and the high-temperature limit do not commute for the density correlation function of the two-dimensional Coulomb gas.",
          "error": null
        }
      }
    },
    {
      "id": 92,
      "title": "Thermal equilibrium and statistical thermometers in special relativity",
      "original_text": "There is an intense debate in the recent literature about the correct generalization of Maxwell's velocity distribution in special relativity. The most frequently discussed candidate distributions include the Juettner function as well as modifications thereof. Here, we report results from fully relativistic one-dimensional (1D) molecular dynamics (MD) simulations that resolve the ambiguity. The numerical evidence unequivocally favors the Juettner distribution. Moreover, our simulations illustrate that the concept of 'thermal equilibrium' extends naturally to special relativity only if a many-particle system is spatially confined. They make evident that 'temperature' can be statistically defined and measured in an observer frame independent way.",
      "generations": {
        "easy_general": {
          "text": "\"Scientists have been busy arguing about the best way to describe the way particles move in special relativity. They've been looking at different ways to do this, including something called the Juettner function. Now, researchers have done some computer simulations and found that the Juettner function is the way to go. They also showed that the idea of 'thermal equilibrium' only works if the particles are confined in a certain way. This helps us understand how temperature works in special relativity.\"",
          "error": null
        },
        "adult_non_technical": {
          "text": "There's a lot of discussion in the scientific community about the right way to apply Maxwell's velocity distribution in special relativity. People have suggested different options, like the Juettner function and its variations. Now, we have evidence from computer simulations that shows that the Juettner distribution is the best. These simulations also show that the idea of temperature in special relativity only makes sense when particles are confined in a certain space. Plus, we can now measure temperature in a way that doesn't depend on the observer's perspective.",
          "error": null
        },
        "adult_technical": {
          "text": "In recent years, the debate surrounding the generalization of Maxwell's velocity distribution in the context of special relativity has been intense. Among the proposed distributions, the Juettner function and its modifications have garnered significant attention. To address this, we have conducted fully relativistic one-dimensional (1D) molecular dynamics (MD) simulations, which have clearly resolved the ambiguity. The numerical evidence overwhelmingly supports the Juettner distribution. Furthermore, our simulations demonstrate that the concept of thermal equilibrium extends naturally to special relativity only when a many-particle system is spatially confined. They also show that temperature can be statistically defined and measured in an observer frame-independent manner.",
          "error": null
        }
      }
    },
    {
      "id": 93,
      "title": "On Asymptotic Proximity of Distributions",
      "original_text": "We consider some general facts concerning convergence P_{n}-Q_{n}\\to 0 as n\\to \\infty, where P_{n} and Q_{n} are probability measures in a complete separable metric space. The main point is that the sequences {P_{n}} and {Q_{n}} are not assumed to be tight. We compare different possible definitions of the above convergence, and establish some general properties.",
      "generations": {
        "easy_general": {
          "text": "\"We are looking at how two groups of numbers get closer over time. These groups are called probability measures. We are comparing different ways to measure this and finding general rules.\"",
          "error": null
        },
        "adult_non_technical": {
          "text": "Imagine you're playing a game where you have to guess a number. Each time you guess, you get closer and closer to the right answer. This is called convergence. In math, we use probability measures to describe the chances of different things happening. We looked at different ways to describe convergence in probability measures and found some general rules.",
          "error": null
        },
        "adult_technical": {
          "text": "We examine the convergence of the difference between two sequences of probability measures, {P_n} and {Q_n}, in a complete separable metric space, as n approaches infinity. The key aspect here is that these sequences are not assumed to be tight. We compare various definitions of this convergence and establish some general properties.",
          "error": null
        }
      }
    },
    {
      "id": 94,
      "title": "The young, wide and very low mass visual binary LOri167",
      "original_text": "We look for wide, faint companions around members of the 5 Myr Lambda Orionis open cluster. We used optical, near-infrared, and Spitzer/IRAC photometry. We report the discovery of a very wide very low mass visual binary, LOri167, formed by a brown dwarf and a planetary-mass candidate located at 5 arcsec, which seems to belong to the cluster. We derive Teff of 2125 and 1750 K. If they are members, comparisons with theoretical models indicate masses of 17 (20-15) Mjup and 8 (13-7) Mjup, with a projected separation of 2000 AU. Such a binary system would be difficult to explain in most models, particularly those where substellar objects form in the disks surrounding higher mass stars.",
      "generations": {
        "easy_general": {
          "text": "We are looking for small, faint objects around stars in a group called Lambda Orionis. We used a special telescope to find a pair of objects, called a binary system. One object is a brown dwarf, and the other is a planet-like object. These objects are very far away from each other, and it might be hard to explain how they formed.",
          "error": null
        },
        "adult_non_technical": {
          "text": "We're looking for faint companions around stars in a group called Lambda Orionis, which is about 5 million years old. We used different types of light to find these companions. We found a special pair called LOri167, which has a brown dwarf and a planet-like object. They're really far apart, but we think they belong to the same group. We measured their temperatures and think they might be about 17 and 8 times the size of Jupiter. They're so far apart that it's hard to explain how they formed.",
          "error": null
        },
        "adult_technical": {
          "text": "To search for faint, distant companions around members of the 5-million-year-old Lambda Orionis open cluster, we employed optical, near-infrared, and Spitzer/IRAC photometry. We report the discovery of a wide, low-mass visual binary, LOri167, consisting of a brown dwarf and a planetary-mass candidate located at 5 arcseconds. This system appears to be part of the cluster. We calculated the effective temperatures as 2125 and 1750 K. If these objects are indeed cluster members, comparisons with theoretical models suggest masses of approximately 17 (20-15) Mjup and 8 (13-7) Mjup, respectively, with a projected separation between the two objects of 2000 AU. Such a binary system poses a challenge to most models, particularly those that propose the formation of substellar objects in the disks surrounding higher-mass stars.",
          "error": null
        }
      }
    },
    {
      "id": 95,
      "title": "WACA: A Hierarchical Weighted Clustering Algorithm optimized for Mobile Hybrid Networks",
      "original_text": "Clustering techniques create hierarchal network structures, called clusters, on an otherwise flat network. In a dynamic environment-in terms of node mobility as well as in terms of steadily changing device parameters-the clusterhead election process has to be re-invoked according to a suitable update policy. Cluster re-organization causes additional message exchanges and computational complexity and it execution has to be optimized. Our investigations focus on the problem of minimizing clusterhead re-elections by considering stability criteria. These criteria are based on topological characteristics as well as on device parameters. This paper presents a weighted clustering algorithm optimized to avoid needless clusterhead re-elections for stable clusters in mobile ad-hoc networks. The proposed localized algorithm deals with mobility, but does not require geographical, speed or distances information.",
      "generations": {
        "easy_general": {
          "text": "Imagine a big party with lots of people moving around. To make things easier, we divide the party into smaller groups, called clusters. Sometimes, when people move or change their behavior, we need to reorganize these groups. However, this can be complicated and take a lot of time. To make it simpler, we created a system that helps us decide when to reorganize the groups. This system focuses on the movement and behavior of the people.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Imagine a network of devices that are organized into smaller groups called clusters. These clusters need to be updated when devices move around or when their parameters change. When the clusters are reorganized, the devices need to communicate with each other. Researchers are trying to find a way to make this process more efficient. They have developed a new algorithm that minimizes the need for re-organization when the clusters are stable. This algorithm can handle moving devices without needing information about geographical locations, speeds or distances.",
          "error": null
        },
        "adult_technical": {
          "text": "Clustering techniques establish hierarchical network structures, known as clusters, on an otherwise flat network. In a dynamic environment, characterized by node mobility and steadily changing device parameters, the clusterhead election process must be re-invoked using a suitable update policy. Cluster re-organization results in additional message exchanges and computational complexity, necessitating optimization. Our research focuses on minimizing clusterhead re-elections by considering stability criteria based on topological characteristics and device parameters. This paper introduces a weighted clustering algorithm optimized to avoid unnecessary clusterhead re-elections for stable clusters in mobile ad-hoc networks. The proposed localized algorithm addresses mobility without requiring geographical, speed, or distance information.",
          "error": null
        }
      }
    },
    {
      "id": 96,
      "title": "Integral group ring of the Mathieu simple group M24",
      "original_text": "We consider the Zassenhaus conjecture for the normalized unit group of the integral group ring of the Mathieu sporadic group $M_{24}$. As a consequence, for this group we confirm Kimmerle's conjecture on prime graphs.",
      "generations": {
        "easy_general": {
          "text": "Imagine you have a special set of numbers called a \"group.\" This group is like a puzzle where each piece fits together in a unique way. Now, let's look at this group called $M_{24}$. It's a",
          "error": null
        },
        "adult_non_technical": {
          "text": "We look at a special part of math called the Zassenhaus conjecture. This is related to a special group of numbers called the Mathieu sporadic group $M_{24}$. By doing this, we also prove Kimmerle's idea about prime numbers.",
          "error": null
        },
        "adult_technical": {
          "text": "We examine the Zassenhaus conjecture in the context of the normalized unit group of the integral group ring of the Mathieu sporadic group $M_{24}$. As a result, we validate Kimmerle's conjecture on prime graphs for this specific group.",
          "error": null
        }
      }
    },
    {
      "id": 97,
      "title": "Bethe algebra and algebra of functions on the space of differential operators of order two with polynomial solutions",
      "original_text": "We show that the following two algebras are isomorphic. The first is the algebra $A_P$ of functions on the scheme of monic linear second-order differential operators on $\\C$ with prescribed regular singular points at $z_1,..., z_n, \\infty$, prescribed exponents $\\La^{(1)}, ..., \\La^{(n)}, \\La^{(\\infty)}$ at the singular points, and having the kernel consisting of polynomials only. The second is the Bethe algebra of commuting linear operators, acting on the vector space $\\Sing L_{\\La^{(1)}} \\otimes ... \\otimes L_{\\La^{(n)}}[\\La^{(\\infty)}]$ of singular vectors of weight $\\La^{(\\infty)}$ in the tensor product of finite dimensional polynomial $gl_2$-modules with highest weights $\\La^{(1)},..., \\La^{(n)}$.",
      "generations": {
        "easy_general": {
          "text": "We show that two types of mathematical structures are the same. The first one is an algebra of functions $A_P$ that works on a set of special equations called \"monic linear second-order differential operators.\" These equations have special points at numbers $z_1, z_2, ..., z_n$ and at infinity, and they have specific values called $\\La^{(1)}, \\La^{(2)}, ..., \\La^{(n)}, \\La^{(\\infty)}$ at these points. The algebra $A_P$ only works with polynomials.\n\nThe second structure is the Bethe algebra, which is a set of special operators called \"commuting linear operators.\" These operators are used on a set of vectors called $\\Sing L_{\\La^{(1)}} \\otimes ... \\otimes L_{\\La^{(n)}}[\\La^{(\\infty)}]$. These vectors have a special weight $\\La^{(\\infty)}$ and are made up of polynomials.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this article, we explore two types of mathematical structures called algebras and show that they are essentially the same. The first type of algebra, called $A_P$, is made up of functions on a specific set of mathematical objects called monic linear second-order differential operators. These operators have certain properties, such as having regular singular points at $z_1, ..., z_n, \\infty$ and prescribed exponents $\\La^{(1)}, ..., \\La^{(n)}, \\La^{(\\infty)}$ at these points. The second type of algebra, called the Bethe algebra, is made up of commuting linear operators that act on a specific vector space of singular vectors of weight $\\La^{(\\infty)}$ in the tensor product of finite dimensional polynomial $gl_2$-modules with highest weights $\\La^{(1)}, ..., \\La^{(n)}$.",
          "error": null
        },
        "adult_technical": {
          "text": "We demonstrate the isomorphism between algebras $A_P$ and the Bethe algebra. The algebra $A_P$ consists of functions on the scheme of monic linear second-order differential operators on the complex plane $\\C$, with prescribed regular singular points at $z_1, ..., z_n, \\infty$, and prescribed exponents $\\La^{(1)}, ..., \\La^{(n)}, \\La^{(\\infty)}$ at these singular points. The kernel of these operators is composed solely of polynomials. The Bethe algebra consists of commuting linear operators acting on the vector space $\\Sing L_{\\La^{(1)}} \\otimes ... \\otimes L_{\\La^{(n)}}[\\La^{(\\infty)}]$, which consists of singular vectors of weight $\\La^{(\\infty)}$ in the tensor product of finite-dimensional polynomial $gl_2$-modules with highest weights $\\La^{(1)}, ..., \\La^{(n)}$.",
          "error": null
        }
      }
    },
    {
      "id": 98,
      "title": "Rich methane premixed laminar flames doped by light unsaturated hydrocarbons - Part I : allene and propyne",
      "original_text": "The structure of three laminar premixed rich flames has been investigated: a pure methane flame and two methane flames doped by allene and propyne, respectively. The gases of the three flames contain 20.9% (molar) of methane and 33.4% of oxygen, corresponding to an equivalence ratio of 1.25 for the pure methane flame. In both doped flames, 2.49% of C3H4 was added, corresponding to a ratio C3H4/CH4 of 12% and an equivalence ratio of 1.55. The three flames have been stabilized on a burner at a pressure of 6.7 kPa using argon as dilutant, with a gas velocity at the burner of 36 cm/s at 333 K. The concentration profiles of stable species were measured by gas chromatography after sampling with a quartz microprobe. Quantified species included carbon monoxide and dioxide, methane, oxygen, hydrogen, ethane, ethylene, acetylene, propyne, allene, propene, propane, 1,2-butadiene, 1,3-butadiene, 1-butene, isobutene, 1-butyne, vinylacetylene, and benzene. The temperature was measured using a PtRh (6%)-PtRh (30%) thermocouple settled inside the enclosure and ranged from 700 K close to the burner up to 1850 K. In order to model these new results, some improvements have been made to a mechanism previously developed in our laboratory for the reactions of C3-C4 unsaturated hydrocarbons. The main reaction pathways of consumption of allene and propyne and of formation of C6 aromatic species have been derived from flow rate analyses.",
      "generations": {
        "easy_general": {
          "text": "Scientists looked at three different types of flames: one made of pure methane, and two others that had methane mixed with other chemicals called allene and propyne. The flames had the same amount of methane and oxygen, but the doped flames had extra allene and propyne. The scientists used special tools to measure the temperature and different chemicals in the flames.",
          "error": null
        },
        "adult_non_technical": {
          "text": "Scientists have studied three types of flames: one made of pure methane, and two others that have extra chemicals called allene and propyne. All the flames have a specific mix of methane and oxygen. The pure methane flame has 20.9% methane and 33.4% oxygen, while the doped flames have 2.49% of C3H4 added. The scientists used a special burner to keep the flames steady. They measured the amounts of different chemicals, like carbon monoxide and dioxide, methane, oxygen, and hydrogen, ethane, acetylene, and propyne, allene, and propene, propane, and some other chemicals, using a special machine. Then, they measured the temperature of the flames, which ranged from 700 to 1850 degrees. Finally, they used this information to improve a model of how these chemicals react with each other.",
          "error": null
        },
        "adult_technical": {
          "text": "The structure of three types of laminar premixed rich flames has been investigated: a pure methane flame and two methane flames enriched with allene and propyne, respectively. The composition of the flames includes 20.9% methane and 33.4% oxygen, corresponding to an equivalence ratio of 1.25 for the pure methane flame. In the enriched flames, 2.49% of C3H4 was added, resulting in a C3H4/CH4 ratio of 12% and an equivalence ratio of 1.55. The flames were stabilized on a burner at a pressure of 6.7 kPa using argon as a diluent, with a gas velocity at the burner of 36 cm/s at 333 K. The concentration profiles of stable species were measured using gas chromatography after sampling with a quartz microprobe. Quantified species included carbon monoxide and dioxide, methane, oxygen, hydrogen, ethane, ethylene, acetylene, propyne, allene, propene, propane, 1,2-butadiene, 1,3-butadiene, 1-butene, isobutene, 1-butyne, vinylacetylene, and benzene. The temperature was measured using a PtRh (6%)-PtRh (30%) thermocouple inside the enclosure, ranging from 700 K near the burner to 1850 K. To model these new results, improvements have been made to a previously developed mechanism for the reactions of C3-C4 unsaturated hydrocarbons. The main reaction pathways for the consumption of allene and propyne and the formation of C6 aromatic species have been derived from flow rate analyses.",
          "error": null
        }
      }
    },
    {
      "id": 99,
      "title": "Multiple Parton Scattering in Nuclei: Quark-quark Scattering",
      "original_text": "Modifications to quark and antiquark fragmentation functions due to quark-quark (antiquark) double scattering in nuclear medium are studied systematically up to order \\cal{O}(\\alpha_{s}^2)$ in deeply inelastic scattering (DIS) off nuclear targets. At the order $\\cal{O}(\\alpha_s^2)$, twist-four contributions from quark-quark (antiquark) rescattering also exhibit the Landau-Pomeranchuck-Midgal (LPM) interference feature similar to gluon bremsstrahlung induced by multiple parton scattering. Compared to quark-gluon scattering, the modification, which is dominated by $t$-channel quark-quark (antiquark) scattering, is only smaller by a factor of $C_F/C_A=4/9$ times the ratio of quark and gluon distributions in the medium. Such a modification is not negligible for realistic kinematics and finite medium size. The modifications to quark (antiquark) fragmentation functions from quark-antiquark annihilation processes are shown to be determined by the antiquark (quark) distribution density in the medium. The asymmetry in quark and antiquark distributions in nuclei will lead to different modifications of quark and antiquark fragmentation functions inside a nucleus, which qualitatively explains the experimentally observed flavor dependence of the leading hadron suppression in semi-inclusive DIS off nuclear targets. The quark-antiquark annihilation processes also mix quark and gluon fragmentation functions in the large fractional momentum region, leading to a flavor dependence of jet quenching in heavy-ion collisions.",
      "generations": {
        "easy_general": {
          "text": "In this study, we explored the changes in quark and antiquark fragmentation functions due to quark-quark double scattering and quark-antiquark annihilation processes in deeply inelastic scattering (DIS) off nuclear targets. We found that the modifications from quark-quark double scattering are similar to those from gluon bremsstrahlung, which is a result of multiple parton scattering. The modifications from quark-quark double scattering are smaller than those from quark-gluon scattering, but they are not negligible for realistic kinematics and finite medium size. The modifications from quark-antiquark annihilation processes are determined by the distribution of antiquarks and quarks in the medium. The asymmetry in quark and antiquark distributions in nuclei leads to different modifications of quark and antiquark fragmentation functions inside a nucleus, which explains the experimentally observed flavor dependence of the leading hadron suppression in semi-inclusive DIS off nuclear targets. The quark-antiquark annihilation processes also mix quark and gluon fragmentation functions in the large fractional momentum region, leading to a flavor dependence of jet quenching in heavy-ion collisions.",
          "error": null
        },
        "adult_non_technical": {
          "text": "In this study, we investigate the changes to quark and antiquark fragmentation functions due to quark-quark (antiquark) double scattering in nuclear medium in deeply inelastic scattering (DIS) off nuclear targets. At the order $\\cal{O}(\\alpha_s^2)$, twist-four contributions from quark-quark (antiquark) rescattering also exhibit the Landau-Pomeranchuck-Midgal (LPM) interference feature similar to gluon bremsstrahlung induced by multiple parton scattering. Compared to quark-gluon scattering, the modification, which is dominated by $t$-channel quark-quark (antiquark) scattering, is only smaller by a factor of $C_F/C_A=4/9$ times the ratio of quark and gluon distributions in the medium. Such a modification is not negligible for realistic kinematics and finite medium size. The modifications to quark (antiquark) fragmentation functions from quark-antiquark annihilation processes are shown to be determined by the antiquark (quark) distribution density in the medium. The asymmetry in quark and antiquark distributions in nuclei will lead to different modifications of quark and antiquark fragmentation functions inside a nucleus, which qualitatively explains the experimentally observed flavor dependence of the leading hadron suppression in semi-inclusive DIS off nuclear targets. The quark-antiquark annihilation processes also mix quark and gluon fragmentation functions in the large fractional momentum region, leading to a flavor dependence of jet quenching in heavy-ion collisions.\n\nIn simpler terms, this study examines the changes to quark and antiquark fragmentation functions due to quark-quark (antiquark) double scattering in nuclear medium in deeply inelastic scattering (DIS) off nuclear targets. The changes are related to the Landau-Pomeranchuck-Midgal (LPM) interference feature, which is similar to gluon bremsstrahlung induced by multiple parton scattering. The modification is dominated by $t$-channel quark-quark (antiquark) scattering and is only smaller by a factor of $C_F/C_A=4/9$ times the ratio of quark and gluon distributions in the medium. The asymmetry in quark and antiquark distributions in nuclei will lead to different modifications of quark and antiquark fragmentation functions inside a nucleus, which qualitatively explains the experimentally observed flavor dependence of the leading hadron suppression in heavy-ion collisions.",
          "error": null
        },
        "adult_technical": {
          "text": "The effects of quark-quark (antiquark) double scattering in nuclear medium on quark and antiquark fragmentation functions are systematically studied in deeply inelastic scattering (DIS) off nuclear targets. At the order $\\cal{O}(\\alpha_s^2)$, quark-quark (antiquark) rescattering contributions exhibit the Landau-Pomeranchuk-Midgal (LPM) interference feature, similar to gluon bremsstrahlung induced by multiple parton scattering. This modification, dominated by $t$-channel quark-quark (antiquark) scattering, is smaller than quark-gluon scattering by a factor of $C_F/C_A=4/9$ times the ratio of quark and gluon distributions in the medium. This modification is not negligible for realistic kinematics and finite medium size. The modifications to quark (antiquark) fragmentation functions from quark-antiquark annihilation processes are determined by the antiquark (quark) distribution density in the medium. The asymmetry in quark and antiquark distributions in nuclei leads to different modifications of quark and antiquark fragmentation functions inside a nucleus, which qualitatively explains the experimentally observed flavor dependence of the leading hadron suppression in semi-inclusive DIS off nuclear targets. The quark-antiquark annihilation processes also mix quark and gluon fragmentation functions in the large fractional momentum region, leading to a flavor dependence of jet quenching in heavy-ion collisions.",
          "error": null
        }
      }
    }
  ]
}